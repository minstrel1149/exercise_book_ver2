{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.FloatTensor([i * 0.1 + 0.1 for i in range(9)]).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand_like(target)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0540, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.mse_loss(x, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Loss: 0.04266321659088135\n",
      "tensor([[0.2232, 0.2896, 0.1212],\n",
      "        [0.5963, 0.6197, 0.6330],\n",
      "        [0.7647, 0.2841, 0.8325]], requires_grad=True)\n",
      "2-th Loss: 0.03370920196175575\n",
      "tensor([[0.2096, 0.2796, 0.1411],\n",
      "        [0.5745, 0.6064, 0.6293],\n",
      "        [0.7575, 0.3415, 0.8400]], requires_grad=True)\n",
      "3-th Loss: 0.02663443237543106\n",
      "tensor([[0.1974, 0.2708, 0.1588],\n",
      "        [0.5551, 0.5946, 0.6261],\n",
      "        [0.7511, 0.3924, 0.8467]], requires_grad=True)\n",
      "4-th Loss: 0.02104448899626732\n",
      "tensor([[0.1866, 0.2629, 0.1744],\n",
      "        [0.5379, 0.5841, 0.6232],\n",
      "        [0.7454, 0.4377, 0.8526]], requires_grad=True)\n",
      "5-th Loss: 0.01662774197757244\n",
      "tensor([[0.1769, 0.2559, 0.1884],\n",
      "        [0.5226, 0.5747, 0.6206],\n",
      "        [0.7404, 0.4780, 0.8579]], requires_grad=True)\n",
      "6-th Loss: 0.013137970119714737\n",
      "tensor([[0.1684, 0.2497, 0.2008],\n",
      "        [0.5089, 0.5664, 0.6183],\n",
      "        [0.7359, 0.5137, 0.8625]], requires_grad=True)\n",
      "7-th Loss: 0.010380617342889309\n",
      "tensor([[0.1608, 0.2442, 0.2118],\n",
      "        [0.4968, 0.5590, 0.6163],\n",
      "        [0.7319, 0.5455, 0.8667]], requires_grad=True)\n",
      "8-th Loss: 0.008201967924833298\n",
      "tensor([[0.1540, 0.2393, 0.2216],\n",
      "        [0.4861, 0.5525, 0.6145],\n",
      "        [0.7284, 0.5738, 0.8704]], requires_grad=True)\n",
      "9-th Loss: 0.006480569019913673\n",
      "tensor([[0.1480, 0.2349, 0.2303],\n",
      "        [0.4765, 0.5466, 0.6129],\n",
      "        [0.7252, 0.5989, 0.8737]], requires_grad=True)\n",
      "10-th Loss: 0.005120450165122747\n",
      "tensor([[0.1427, 0.2310, 0.2381],\n",
      "        [0.4680, 0.5415, 0.6114],\n",
      "        [0.7224, 0.6213, 0.8766]], requires_grad=True)\n",
      "11-th Loss: 0.004045786801725626\n",
      "tensor([[0.1380, 0.2276, 0.2449],\n",
      "        [0.4605, 0.5369, 0.6102],\n",
      "        [0.7199, 0.6411, 0.8792]], requires_grad=True)\n",
      "12-th Loss: 0.00319667044095695\n",
      "tensor([[0.1337, 0.2245, 0.2511],\n",
      "        [0.4537, 0.5328, 0.6090],\n",
      "        [0.7177, 0.6588, 0.8815]], requires_grad=True)\n",
      "13-th Loss: 0.0025257638189941645\n",
      "tensor([[0.1300, 0.2218, 0.2565],\n",
      "        [0.4478, 0.5291, 0.6080],\n",
      "        [0.7157, 0.6745, 0.8836]], requires_grad=True)\n",
      "14-th Loss: 0.001995664555579424\n",
      "tensor([[0.1267, 0.2194, 0.2613],\n",
      "        [0.4425, 0.5259, 0.6071],\n",
      "        [0.7140, 0.6884, 0.8854]], requires_grad=True)\n",
      "15-th Loss: 0.001576821319758892\n",
      "tensor([[0.1237, 0.2172, 0.2656],\n",
      "        [0.4377, 0.5230, 0.6063],\n",
      "        [0.7124, 0.7008, 0.8870]], requires_grad=True)\n",
      "16-th Loss: 0.001245883759111166\n",
      "tensor([[0.1211, 0.2153, 0.2695],\n",
      "        [0.4335, 0.5205, 0.6056],\n",
      "        [0.7111, 0.7118, 0.8885]], requires_grad=True)\n",
      "17-th Loss: 0.000984402373433113\n",
      "tensor([[0.1187, 0.2136, 0.2728],\n",
      "        [0.4298, 0.5182, 0.6050],\n",
      "        [0.7098, 0.7216, 0.8897]], requires_grad=True)\n",
      "18-th Loss: 0.0007777998107485473\n",
      "tensor([[0.1166, 0.2121, 0.2759],\n",
      "        [0.4265, 0.5162, 0.6045],\n",
      "        [0.7087, 0.7303, 0.8909]], requires_grad=True)\n",
      "19-th Loss: 0.0006145582883618772\n",
      "tensor([[0.1148, 0.2108, 0.2785],\n",
      "        [0.4236, 0.5144, 0.6040],\n",
      "        [0.7078, 0.7381, 0.8919]], requires_grad=True)\n",
      "20-th Loss: 0.00048557683476246893\n",
      "tensor([[0.1131, 0.2096, 0.2809],\n",
      "        [0.4209, 0.5128, 0.6035],\n",
      "        [0.7069, 0.7450, 0.8928]], requires_grad=True)\n",
      "21-th Loss: 0.0003836657269857824\n",
      "tensor([[0.1117, 0.2085, 0.2830],\n",
      "        [0.4186, 0.5113, 0.6031],\n",
      "        [0.7061, 0.7511, 0.8936]], requires_grad=True)\n",
      "22-th Loss: 0.00030314340256154537\n",
      "tensor([[0.1104, 0.2076, 0.2849],\n",
      "        [0.4165, 0.5101, 0.6028],\n",
      "        [0.7055, 0.7565, 0.8943]], requires_grad=True)\n",
      "23-th Loss: 0.00023952069750521332\n",
      "tensor([[0.1092, 0.2067, 0.2866],\n",
      "        [0.4147, 0.5090, 0.6025],\n",
      "        [0.7048, 0.7613, 0.8949]], requires_grad=True)\n",
      "24-th Loss: 0.00018925107724498957\n",
      "tensor([[0.1082, 0.2060, 0.2881],\n",
      "        [0.4131, 0.5080, 0.6022],\n",
      "        [0.7043, 0.7656, 0.8955]], requires_grad=True)\n",
      "25-th Loss: 0.00014953191566746682\n",
      "tensor([[0.1073, 0.2053, 0.2894],\n",
      "        [0.4116, 0.5071, 0.6020],\n",
      "        [0.7038, 0.7695, 0.8960]], requires_grad=True)\n",
      "26-th Loss: 0.00011814879690064117\n",
      "tensor([[0.1065, 0.2047, 0.2906],\n",
      "        [0.4103, 0.5063, 0.6017],\n",
      "        [0.7034, 0.7729, 0.8964]], requires_grad=True)\n",
      "27-th Loss: 9.335195500170812e-05\n",
      "tensor([[0.1058, 0.2042, 0.2916],\n",
      "        [0.4092, 0.5056, 0.6015],\n",
      "        [0.7030, 0.7759, 0.8968]], requires_grad=True)\n",
      "28-th Loss: 7.37595182727091e-05\n",
      "tensor([[0.1051, 0.2037, 0.2926],\n",
      "        [0.4082, 0.5050, 0.6014],\n",
      "        [0.7027, 0.7786, 0.8972]], requires_grad=True)\n",
      "29-th Loss: 5.827909990330227e-05\n",
      "tensor([[0.1046, 0.2033, 0.2934],\n",
      "        [0.4073, 0.5044, 0.6012],\n",
      "        [0.7024, 0.7809, 0.8975]], requires_grad=True)\n",
      "30-th Loss: 4.604771675076336e-05\n",
      "tensor([[0.1040, 0.2029, 0.2941],\n",
      "        [0.4064, 0.5039, 0.6011],\n",
      "        [0.7021, 0.7831, 0.8978]], requires_grad=True)\n",
      "31-th Loss: 3.638340422185138e-05\n",
      "tensor([[0.1036, 0.2026, 0.2948],\n",
      "        [0.4057, 0.5035, 0.6010],\n",
      "        [0.7019, 0.7849, 0.8980]], requires_grad=True)\n",
      "32-th Loss: 2.8747404940077104e-05\n",
      "tensor([[0.1032, 0.2023, 0.2954],\n",
      "        [0.4051, 0.5031, 0.6009],\n",
      "        [0.7017, 0.7866, 0.8982]], requires_grad=True)\n",
      "33-th Loss: 2.2713958969688974e-05\n",
      "tensor([[0.1028, 0.2021, 0.2959],\n",
      "        [0.4045, 0.5028, 0.6008],\n",
      "        [0.7015, 0.7881, 0.8984]], requires_grad=True)\n",
      "34-th Loss: 1.7946844309335575e-05\n",
      "tensor([[0.1025, 0.2018, 0.2963],\n",
      "        [0.4040, 0.5025, 0.6007],\n",
      "        [0.7013, 0.7894, 0.8986]], requires_grad=True)\n",
      "35-th Loss: 1.4180184734868817e-05\n",
      "tensor([[0.1022, 0.2016, 0.2967],\n",
      "        [0.4036, 0.5022, 0.6006],\n",
      "        [0.7012, 0.7906, 0.8988]], requires_grad=True)\n",
      "36-th Loss: 1.1204151633137371e-05\n",
      "tensor([[0.1020, 0.2015, 0.2971],\n",
      "        [0.4032, 0.5019, 0.6005],\n",
      "        [0.7010, 0.7916, 0.8989]], requires_grad=True)\n",
      "37-th Loss: 8.85262488736771e-06\n",
      "tensor([[0.1018, 0.2013, 0.2974],\n",
      "        [0.4028, 0.5017, 0.6005],\n",
      "        [0.7009, 0.7926, 0.8990]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "thres = 1e-5\n",
    "learning_rate = 0.5\n",
    "iter_cnt = 0\n",
    "\n",
    "while loss > thres:\n",
    "    iter_cnt += 1\n",
    "    loss.backward()\n",
    "    x = x - learning_rate * x.grad\n",
    "\n",
    "    x.detach_()\n",
    "    x.requires_grad_(True)\n",
    "\n",
    "    loss = F.mse_loss(x, target)\n",
    "\n",
    "    print(f'{iter_cnt}-th Loss: {loss}')\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([i + 1 for i in range(4)]).reshape(2, 2).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x + 2\n",
    "x2 = x - 2\n",
    "x3 = x1 * x2\n",
    "y = x3.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
