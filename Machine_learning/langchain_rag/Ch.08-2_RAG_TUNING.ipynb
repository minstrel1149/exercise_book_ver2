{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25517f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import gc\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e043397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mrc_question', 'paraphrased_question', 'no_answer', 'mrc_question_with_1_to_4_negative', 'synthetic_question'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('iamjoon/klue-mrc-ko-rag-dataset', split='train')\n",
    "print(set(dataset['type']))\n",
    "dataset = dataset.class_encode_column('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d393ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast_column 메서드 활용도 가능\n",
    "type_name_dict = {1:'mrc_question_with_1_to_4_negative', 3:'paraphrased_question', 2:'no_answer', 4:'synthetic_question', 0:'mrc_question'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6574d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''\n",
    "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
    "\n",
    "다음의 지시사항을 따르십시오.\n",
    "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
    "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
    "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
    "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
    "5. 예를 들어 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]라고 기재하십시오.\n",
    "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
    "\n",
    "검색 결과:\n",
    "----------\n",
    "{search_result}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953fc6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터의 type 분포:\n",
      "mrc_question: 491\n",
      "mrc_question_with_1_to_4_negative: 296\n",
      "no_answer: 404\n",
      "paraphrased_question: 196\n",
      "synthetic_question: 497\n"
     ]
    }
   ],
   "source": [
    "print('원본 데이터의 type 분포:')\n",
    "for type_name in set(dataset['type']):\n",
    "    print(f'{type_name_dict[type_name]}: {dataset['type'].count(type_name)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31da997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.5, stratify_by_column='type')\n",
    "train_dataset_format = split_dataset['train']\n",
    "test_dataset_format = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe428c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample):\n",
    "    search_result = '\\n------\\n'.join(f'문서{idx+1}: {result}' for idx, result in enumerate(sample['search_result']))\n",
    "\n",
    "    return {\n",
    "        'messages':[{'role':'system', 'content':system_message.format(search_result=search_result)},\n",
    "                    {'role':'user', 'content':sample['question']},\n",
    "                    {'role':'assistant', 'content':sample['answer']}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ceb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [format_data(train_data) for train_data in train_dataset_format]\n",
    "test_dataset = [format_data(test_data) for test_data in test_dataset_format]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b3d485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 데이터 분할 결과: Train 942개, Test 942개\n",
      "----------------------------------------\n",
      "\n",
      "학습 데이터의 type 분포:\n",
      "mrc_question: 245\n",
      "mrc_question_with_1_to_4_negative: 148\n",
      "no_answer: 202\n",
      "paraphrased_question: 98\n",
      "synthetic_question: 249\n",
      "\n",
      "테스트 데이터의 type 분포:\n",
      "mrc_question: 246\n",
      "mrc_question_with_1_to_4_negative: 148\n",
      "no_answer: 202\n",
      "paraphrased_question: 98\n",
      "synthetic_question: 248\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n전체 데이터 분할 결과: Train {len(train_dataset)}개, Test {len(test_dataset)}개')\n",
    "print('--'*20)\n",
    "print('\\n학습 데이터의 type 분포:')\n",
    "for type_name in set(dataset['type']):\n",
    "    print(f'{type_name_dict[type_name]}: {train_dataset_format['type'].count(type_name)}')\n",
    "print('\\n테스트 데이터의 type 분포:')\n",
    "for type_name in set(dataset['type']):\n",
    "    print(f'{type_name_dict[type_name]}: {test_dataset_format['type'].count(type_name)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "068cfade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\\n\\n다음의 지시사항을 따르십시오.\\n1. 질문과 검색 결과를 바탕으로 답변하십시오.\\n2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\\n3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문에 대한 내용이 없습니다.\" 라고 답변하십시오.\\n4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\\n5. 예를 들어 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]라고 기재하십시오.\\n6. 최대한 다수의 문서를 인용하여 답변하십시오.\\n\\n검색 결과:\\n----------\\n문서1: 경남지역에서 운수업에 종사하는 A씨는 작년 상반기 교통사고를 당했다. 문제는 상대방이 자동차보험에 가입하지 않았다는 것이었다. 그는 사고를 낸 상대방을 보험에 가입한 지인으로 바꿔치기 했다. A씨는 병원에서 후유장애 판정을 받아 총 3억원의 보험금을 수령했다. 묻힐 뻔했던 이 보험사기는 A씨 주변인의 신고로 들통났다. 보험사는 A씨 사건을 경찰에 통보하는 한편 신고자에게 3073만원을 포상금으로 지급했다. 주부인 B씨는 고혈압을 앓고 있다는 사실을 속이고 2000년 보장성 보험에 가입했다. 2002년 가벼운 뇌경색으로 진단받아 수년간 입·통원 치료를 반복해 총 1억원의 보험금을 타냈다. 이 과정에서 환자 관리가 허술한 병원만 골라 다녔다. 제보자는 B씨의 혈색이 좋은데도 장기 입원하는 점이 의심스러워 보험범죄 신고센터에 알렸다. 보험사는 B씨가 병력을 속이고 보험에 가입했다는 이유로 경찰에 알렸고 제보자에게는 100만원의 포상금을 줬다. 보험사기가 많아지면서 제보자에게 지급하는 포상금도 급증하고 있다. 금융감독원은 지난해 보험범죄 신고자에게 총 17억1883만원(생명보험 3030만원, 손해보험 16억8853만원)을 포상했다고 15일 발표했다. 전년(7억5815만원) 대비 2.3배 늘어난 수치다. 1인당 평균 포상금은 약 61만원이었다. 500만원 이상 고액 지급 건수도 22건에 달했다.\\n------\\n문서2: 외제차로 고의 사고를 낸 보험사기범들이 부당하게 타간 보험금이 1인당 평균 1억4000만원으로, 1억원을 훌쩍 넘어선 것으로 나타났다. 한 사람당 평균 범행 횟수도 22차례에 달하는 등 외제차 보험사기가 대형화·상습화하고 있다.금융감독원은 외제차를 이용해 686건의 고의 사고를 낸 뒤 총 41억9000여만원의 보험금을 부당하게 수령한 사기 혐의자 30명을 적발, 검찰에 통보했다. 2011년 1월부터 올해 4월까지 자동차 대물사고 17만여건 중 외제차량을 집중 조사해 밝혀낸 결과다. 김동하 금감원 보험조사국 팀장은 “검찰에 넘긴 사기 혐의자 가운데는 28건의 사고로 2억8000여만원을 받아간 사람도 포함돼 있다”고 말했다.사기 혐의자들은 미수선수리비 제도로 보험금을 타냈다. 미수선수리비란 사고차량의 수리비, 부품 교체비용 등을 추정해 그 가격만큼 현금으로 주는 보험금이다. 보험사기꾼들은 주로 법규 위반 차량에 근접해 사고를 유발하는 수법을 사용했다. 불법 좌회전을 하는 자동차를 들이받아 접촉사고를 내는 식이다.\\n------\\n문서3: 종신보험 등 생명보험 가입자가 사망했을 때 유족에게 지급되는 보험금이 1인당 평균 3000만원 정도에 그치는 것으로 집계됐다. 이마저도 생명보험에 가입하지 않은 사람이 전체 사망자의 80%에 달했다. 5명 중 1명만 유족에게 사망보험금이 지급됐다는 뜻이다. 전문가들은 가족 수나 연소득 등의 변화를 감안해 주기적으로 위험보장액을 높여나가야 한다고 주문했다.○사망률 높은 고령층 ‘사각지대’1일 보험개발원에 따르면 가입자(피보험자) 사망에 따라 유족에게 지급된 보험금은 1인당 평균 3029만원(2011년 기준)이다. 한 해 전의 3195만원보다 5.2% 줄었다. 사망보험금은 보험개발원이 통계를 내기 시작한 2007년 이후 매년 증가하다 2011년 들어 처음 꺾였다. 사망보험금을 지급하는 상품은 종신보험 정기보험 치명적질병(CI)보험 등 여러 종류지만 이 중 종신보험 비중이 가장 높다. 보험개발원 관계자는 “보험사 간 경쟁이 과열되면서 저가형 상품이 많이 팔린 탓”이라며 “평균 생계비 등을 따져볼 때 위험보장액이 충분하지 않다”고 평가했다. 전체 사망자 25만7000명 중 사망보험금을 지급받은 비율도 19.9%에 그쳤다. 특히 사망률이 높아지는 60대 이상 노년층은 대부분 보험에 가입하지 않은 것으로 나타났다. 노년층 사망자의 유족에게 보험금이 지급된 비율은 13%로 가장 낮았다. 금융계 관계자는 “보험사들이 타깃층이 젊을 때는 적극적으로 상품을 권유하다가 나이가 들면 이런저런 이유로 가입을 거절하거나 보험료를 너무 높게 책정하기 때문”이라고 지적했다. 김기홍 한화생명 강남FA센터장은 “가장이 종신보험에 가입할 때는 연소득 대비 2~3배 이상의 사망보험금을 책정해야 안전하다”고 조언했다. ○암환자 셋 중 한 명은 진단금 수령다만 암환자 중 보험사에서 수천만원의 진단자금을 수령하는 사람은 급증세다. 수년 전부터 암보험 가입자가 크게 늘어난 때문으로 풀이된다. 2010년 우리나라에서 암이 발병한 사람은 20만2000명이었고, 이 중 보험사에서 암 진단자금을 수령한 사람은 7만3000명으로 36%에 달했다. 암 환자 세 명 중 한 명꼴이다. 암 진단금은 병원 치료비와는 별개로 암환자나 가족이 생활비로 쓸 수 있는 돈이다. 암환자에게 지급된 진단자금은 한 사람당 2849만원으로 집계됐다. 특히 40대 암환자는 65%가 암 진단자금을 받은 것으로 조사됐다. 다음으로 30대(63%), 50대(57%), 10대 이하(51%) 등의 순이었다. 60대 이상 암 환자 중 진단자금을 수령한 사람은 14%였다. 정태윤 보험개발원 통계서비스실장은 “생명보험 측면에서 노년층의 위험 대비가 매우 취약해 이들만을 위한 신상품 개발 등이 필요하다”고 말했다.\\n------\\n문서4: 금융감독원이 20일 발표한 새로운 자동차보험료 할인·할증 제도는 자동차보험료를 결정할 때 지금처럼 교통사고 규모가 크고 작은지를 따지지 않는다. 대신 사고 건수를 기준으로 한다. 사고를 많이 내면 보험료가 오르고 사고가 없으면 보험료가 떨어진다. 이는 사고의 ‘크기’보다는 사고 ‘건수’가 장래 사고 위험을 더 정확하게 반영한다는 보험감독원의 분석에 따른 결과다. 금감원은 사고 건수로 보험료를 결정하면 일부러 사고를 내서 보험금을 타내는 보험사기도 줄일 수 있을 것으로 기대하고 있다.2018년부터 시행되는 새로운 제도는 사고를 처음 내면 보험료 등급이 두 단계 오르고, 두 번째 사고부터는 세 단계씩 상향 조정되도록 하고 있다. 첫 번째 사고가 인명 피해 없이 50만원 이하 소액 사고라면 1등급만 오른다. 한 해에 최대 9등급까지 올라갈 수 있으며 1등급 올라갈 때마다 보험료는 평균 6.8% 정도 오른다. 보험료는 모두 26개 등급으로 분류돼 할인과 할증이 이뤄진다. 보험에 처음 가입하면 11등급을 받는다.첫 사고 금액이 50만원 이하일 경우는 다음해 보험료가 6.8%(한 등급), 50만원 이상일 때는 13.6%(두 등급) 오른다. 두 번째 사고부터는 무조건 3개 등급을 할증하기 때문에 2회 사고를 낸 사람의 보험료는 27.2~34.0% 상승하게 된다.사고를 자주 내는 운전자는 보험료 부담이 크게 늘어나는 방식이다. 지금까지는 사고마다 크기를 따져 0.5~4등급을 떨어뜨렸고 인명 피해와 물적 피해가 함께 발생한 복합사고의 경우 최대 6등급의 할증이 이뤄졌다. 금감원은 전체 보험 가입자의 10% 정도에서 보험료가 오를 것으로 전망했다.반면 무사고 운전자의 보험료 부담은 줄어든다. 제도 변경으로 2300억원의 보험료 할증이 발생하는데 이 돈을 무사고 운전자에게 나눠주도록 할 예정이기 때문이다. 금감원은 제도 변경으로 무사고 운전자는 1인당 평균 2.6%의 보험료 인하 효과가 발생할 것이라고 밝혔다. 보험료가 할인되는 무사고 기간도 3년에서 1년으로 줄어든다. 새로운 제도는 2018년부터 도입되지만 실제 영향은 이르면 2016년 10월부터 발생한다. 2018년 1월1일에 계약하려면 3개월 전에 보험사가 가입자에게 재계약 안내문을 보내야 한다. 이때 과거 1년의 사고 경력을 기준으로 하기 때문이다.허창언 금감원 부원장보는 “할증보험료가 증가한 만큼 무사고자의 보험료를 인하해 보험회사의 보험료 수입은 동일한 수준이 되도록 조정했다”고 말했다.\\n------\\n문서5: 경찰은 경기 파주에서 자동차 공업사를 운영하는 천모씨(50)를 올해 초 구속했다. 동네 선후배를 가해자와 피해자로 역할 분담시켜 교통사고를 조작하는 방법으로 보험금을 받아낸 혐의다. 천씨는 이런 수법으로 6년 동안 총 49회에 걸쳐 8개 보험사에서 13억원의 보험금을 받았다.보험사기가 늘고 있다. 10대와 60~70대의 가담이 급증하는 등 연령대도 넓어지고 있다. 수법도 조직화·지능화하고 있다. 이 추세라면 올해 보험사기범이 10만명을 돌파해 총 5조원가량이 이들의 주머니로 들어갈 것으로 추산된다. ▶관련기사 A4면9일 금융감독원과 서울중앙지방검찰청에 따르면 지난해 적발된 보험사기범은 8만3181명으로 전년(7만2333명)보다 15% 늘었다. 올 들어서도 증가세는 가파르다. 지난 상반기 중 금감원이 ‘사기 혐의가 짙다’며 검찰에 수사를 의뢰한 보험사기 금액은 991억원으로 전년 동기(577억원)에 비해 71% 급증했다. 매년 30% 안팎에 달하던 보험사기 증가율은 2011년 4.5%로 주춤하다 작년부터 큰 폭 증가세로 돌아섰다. 올해도 20% 이상 늘어나 10만명 이상에 달할 것이라는 게 금융당국의 추산이다. 500명당 1명이 보험사기에 관여하는 셈이다. 범죄 연령대도 10대와 노년층으로 넓어지고 있다. 작년에 보험사기로 붙잡힌 10대는 1562명으로 한 해 전(952명)보다 64.1% 늘었다. 연령대별 증가율에서도 최고다. 10대 증가율은 2011년에도 62.5%에 달해 2년 연속 급증세다. 노인들의 가세도 새로운 현상이다. 70대 이상 노년층의 보험사기 증가율은 지난해 28.1%로 10대에 이어 2위다. 60대 증가율이 20.2%로 그 뒤를 잇고 있다.조직화·흉포화 양상도 뚜렷하다. 정부 합동 보험범죄 전담대책반 조사 결과 지난해 20명 이상이 연루된 보험사기 건수는 전체의 4%에 달했다. 허창언 금감원 부원장보는 “10대와 고령층의 가세는 보험사기가 사회 전반으로 확산 중임을 뜻한다”고 우려했다.보험사기로 인해 새나가는 보험금도 올해 5조원에 육박할 것으로 추정된다. 국민 1인당 약 10만원, 가구당 27만원의 추가 부담이 발생한다는 의미다. 김규복 생명보험협회장은 “보험사기를 막으면 내는 보험료가 적어질 뿐만 아니라 적자가 쌓이고 있는 건강보험 재정을 튼튼히 해 복지 재원 누수를 막을 수 있다”고 말했다.'},\n",
       " {'role': 'user', 'content': '교통사고를 당한 A씨가 받은 보험금 액수'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'A씨는 교통사고를 당한 후 병원에서 후유장애 판정을 받아 총 3억원의 보험금을 수령했습니다. 그러나 A씨는 사고를 낸 상대방을 보험에 가입한 지인으로 바꿔치기하는 보험사기를 저질렀고, 이 사실은 주변인의 신고로 밝혀졌습니다 [[ref1]].'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[345]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff82218",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e42d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c35164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4ec5482e0c4998abf2a4d3a679442d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44e06dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias='none',\n",
    "    target_modules=['q_proj', 'v_proj'],\n",
    "    task_type='CAUSAL_LM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8744fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir='qwen_2.5-3b_rag-ko',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim='adamw_torch_fused',\n",
    "    logging_steps=10,\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    learning_rate=1e-4,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type='constant',\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None,\n",
    "    completion_only_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3a6067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ac44735acd41d89350b9db469a8a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/942 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889b4f349f4b48629dbaeb93f541df25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/942 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9c65bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "c:\\Coding\\Local\\exercise_book_ver2\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='236' max='236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [236/236 21:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.257100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.770300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.597700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.591800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.564500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.601900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.582400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.536600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.566500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.542900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.537800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.514400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.560900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.558300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.501800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Coding\\Local\\exercise_book_ver2\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Coding\\Local\\exercise_book_ver2\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed2ada3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97beabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "label_list = []\n",
    "\n",
    "for prompt in test_dataset['messages']:\n",
    "    text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=False)\n",
    "    \n",
    "    input = text.split('<|im_start|>assistant')[0] + '<|im_start|>assistant'\n",
    "    label = text.split('<|im_start|>assistant')[1]\n",
    "\n",
    "    prompt_list.append(input)\n",
    "    label_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b627a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 예를 들어 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]라고 기재하십시오.\n",
      "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
      "\n",
      "검색 결과:\n",
      "----------\n",
      "문서1: 2009년 8월 관객 수 1000만명을 넘어 흥행 질주하던 영화 ‘해운대’가 갑자기 중국 온라인에서 불법복제돼 나돌기 시작했다. 투자배급사인 CJ E&M은 이를 차단하기 위해 파트너사인 베이징문전세기문화전매유한공사 측에 알렸다. 유한공사 측은 단속에 나서기 전에 영화의 저작권자가 누구인지 한국저작권위원회에 문의했다. 위원회가 저작권자는 CJ라는 인증서를 전달하자 유한공사는 이를 근거로 불법복제물을 단속했다. 한국저작권위원회는 국내외에서 콘텐츠 거래를 활성화하기 위해 저작권인증서비스를 시행하고 있다. 공신력 있는 인증기관이 저작물의 권리자가 누구인지 확인해주는 서비스다. 외국인 입장에서는 한국 영화와 드라마 등을 구입하려고 해도 저작권자가 누구인지 몰라 사지 못하는 사례가 많다. 저작권자를 사칭한 사기꾼들에게 피해를 보는 경우도 많다. 중국에서는 한국저작권위원회가 국가판권국(한국의 문화체육관광부에 해당)의 정식 허가를 받고 중국 내에서 유통되는 한국 저작물의 권리관계를 확인해주고 있다. 국내 저작물을 중국에 수출하려면 중국 판권국 산하기관인 중국판권보호중심으로부터 등록번호를 취득해야 한다.\n",
      "------\n",
      "문서2: 공주사대부고 학생 5명이 해병대 체험캠프 도중 숨진 사고는 각종 청소년 여름캠프가 제대로 관리되지 못한 데 따른 인재(人災)였다. 우후죽순처럼 난립하는 각종 여름캠프는 정부의 관리를 받지 않는 사각지대에 방치됐고, 사설업체들은 최소한의 안전조치도 없이 돈벌이에만 매달리는 등 총체적 부실이 드러났다.○‘부실 덩어리’ 청소년 캠프19일 여성가족부에 따르면 이번에 사고가 난 해병대 체험캠프는 한국청소년활동진흥원이 인증한 청소년 체험활동 시설이 아닌 것으로 드러났다. 청소년활동진흥원은 학부모와 학생들에게 관련 정보를 제공하고 관련 인력을 제대로 갖췄는지 심사하기 위해 2006년부터 청소년 캠프를 대상으로 인증제도를 시행하고 있다. 19일 기준으로 인증받은 청소년 캠프는 1497개에 달하지만 이 중 공식 인증을 받은 해병대 캠프는 포항에 있는 한 곳에 불과했다.더구나 캠프를 실제로 운영한 곳은 청소년 수련시설과 수상레저사업자 등록증을 보유한 현지 유스호스텔이 아닌 경기 성남시 분당의 작은 여행사였다. 유스호스텔이 여행사에 하도급을 준 것. 해양경찰청은 이 여행사가 학생 단체 여행객을 모집해 해병대 체험 프로그램을 진행한 것으로 보고 있다.현장에 있던 김모씨(30)와 이모씨(37) 등 교관 2명은 모두 인명구조사 자격증이 없는 임시직이었다. 김봉호 여가부 청소년활동진흥과장은 “인증제도 역시 의무사항이 아니라 해당 단체의 신청에 따라 심사하는 것”이라며 “인증받지 않고 활동하는 청소년 캠프는 수없이 많을 것”이라고 지적했다. 업계는 인가받지 못한 사설 캠프를 합치면 5000개를 넘어설 것으로 추정하고 있다.○11월 시행법도 허가제 아닌 신고제이전에도 여름캠프에서는 해마다 사고가 끊이지 않았다. 지난해 7월에는 경남 김해의 대안학교에서 무인도 체험을 갔던 학생 2명이 실종된 지 닷새 만에 숨진 채 발견됐고 국토대장정에 참가한 10대 청소년들이 폭행과 성추행을 당하기도 했다. 이에 따라 국회는 지난 3월 ‘청소년활동진흥법’을 개정해 ‘이동·숙박형 청소년 활동’은 지방자치단체장에게 미리 계획서를 제출하고 허가를 받도록 했지만 이 개정안은 오는 11월 발효된다.그러나 11월부터 시행되는 이 개정안마저도 ‘허가제’가 아닌 ‘신고제’라는 점에서 여전히 허점이 있다는 지적이 많다. 해당 단체가 캠프 활동을 각 지자체 산하 청소년활동센터에 신청만 하면 승인을 받을 수 있기 때문이다. 대부분의 캠프가 여름철에 집중되는 가운데 지자체 센터 담당직원들이 일일이 수십개에 달하는 청소년 캠프를 제대로 심사할 수 없을 것이란 지적이 나온다. ○청소년캠프업계 잇단 악재에 곤혹사고 이후 각종 청소년캠프에는 학부모 문의가 빗발치고 일부는 프로그램 참가를 취소하는 등 ‘후폭풍’이 이어지고 있다. 한 해병대 체험캠프 관계자는 “인명구조사 등 자격증을 갖춘 강사가 있는지 묻는 학부모 전화가 계속 걸려오고 있다”고 말했다.국토순례 등 다른 청소년캠프도 어려움을 겪고 있다. 국토대장정 캠프를 운영하는 오길산 한국청소년그린캠프봉사단 총대장은 “지난해 한 국토순례 캠프에서 참가 학생들에게 가혹행위를 하는 사건이 있었고 이번 해병대 캠프 사고까지 겹쳐 캠프업계 사정이 굉장히 안 좋아졌다”고 전했다. 최광남 청소년자연탐험연맹 대표는 “올해 참가자는 지난해의 3분의 1 수준”이라고 말했다.한편 이날 사고현장에서는 오전부터 항공기 4대와 수중수색요원 42명 등 800명이 동원돼 장모군 등 공주사대부고 학생 시신 5구를 모두 인양했다. 해경은 사고 현장에 있던 교관 2명과 훈련본부장 이모씨(44) 등 3명에 대해 과실치사 혐의로 구속영장을 신청했다. 태안=임호범/강경민/양병훈 기자\n",
      "------\n",
      "문서3: 공정거래위원회는 보험사가 부과받은 제재금을 대리점이나 설계사에게 떠넘길 수 있도록 한 불공정 약관을 시정토록 했다고 14일 밝혔다. 제재금은 행정처분에 의한 과징금과는 별개로 민간협회가 자율협약을 위반한 회원사에 부과하는 사적 제재 수단으로 협회가 관리한다.대상 보험사는 삼성, 동부, 현대, LIG, 메리츠, 한화, 흥국, 롯데, 농협, 그린, AIG, 더케이, 서울보증보험, 페더럴인슈런스컴퍼니 한국영업소 등 14개 손해보험사다.이들 보험사는 공정한 경쟁질서를 유지하기 위해 영업활동 중 금지사항을 규정, 위반 시 제재금을 부과하는 내용의 ‘공정경쟁 질서 유지에 관한 상호협정’을 1983년 체결했다. 협정에 참여한 20개 손보사 중 14개는 대리점이나 설계사와 계약을 체결할 때 이 제재금을 떠넘길 수 있는 조항을 마련했다. ‘대리점·설계사의 고의나 과실로 상호협정을 위반해 회사에 경제적 손실을 초래하면 회사는 대리점·설계사가 지급받을 수수료에서 손실액을 공제할 수 있다’고 규정한 것이다. 실제로 10개 보험사는 2010~2011년 자신들이 납부한 제재금 12억300만원을 대리점이나 설계사에게 떠넘겼다.\n",
      "------\n",
      "문서4: 마이크로소프트의 창업자 빌 게이츠가 주목할 기업이라고 평가한 모뉴엘이 법정관리를 신청하자 은행들과 한국무역보험공사 간 책임공방이 일고 있다. 모뉴엘에 대출해준 은행들과 대출을 보증한 무역보험공사가 수천억원에 달하는 대출금을 회수하지 못할 것으로 보이자 책임을 떠넘기고 있는 것.모뉴엘이 시중은행들로부터 대출받은 금액은 6700억원 정도로 추정된다. 이 중 무보가 보증을 해준 금액은 약 3300억원 정도로 추산된다. 무보 관계자는 22일 “보증금액은 공식적으로 아직 밝힐 수 없다”고 말했다.모뉴엘이 무보가 발급한 보증을 담보 삼아 은행들에서 대출받은 금액을 갚지 못하면 무보가 대출금에 이자까지 더해 전액 물어줘야 한다. 무보는 이후 모뉴엘의 제품을 사간 수입 업자를 찾아 구상권을 행사하는 절차를 밟는다. 무보 측은 하지만 “이는 정상적인 상황에서 진행하는 절차이고, 지금과 같은 상황에서는 먼저 책임 소재를 가려야 한다”는 입장이다.은행들은 수출거래 내역을 제대로 파악하지 않고 보증을 해준 무보의 책임이 크다고 주장하고 있다. 모뉴엘 채권은행 관계자들은 “은행은 수출 관련 심사를 서류상으로 확인하는 것일 뿐 현장에선 하기 힘들다”며 “그건 보증을 해준 무보의 역할”이라고 했다.반면 무보 관계자는 “무보는 은행들로부터 받은 수출실적 증명서와 수출 대금이 오간 은행들의 통장을 받아 보증 심사를 한다”고 맞받았다. “수출 대금이 실제로 오간 통장 내역은 은행들이 알고 있다”며 “은행들은 이 기업에 신용대출 등 다른 거래도 하고 있어 은행들이 현장을 확인해야 할 사항”이라고 주장했다.모뉴엘이 지난 20일 법정관리를 신청했지만 이날까지도 은행들이 무보에 사고통지를 하지 않은 것을 두고도 주장이 엇갈렸다. 무보 측은 “은행들로부터 사고통지를 받아야 조사에 정식으로 착수하는데, 아직까지 은행들이 공식적인 사고통지를 하지 않고 있다”며 “이는 은행들이 담보 등을 확보하며 손실을 최대한 줄인 뒤 무보에 알리겠다는 것으로밖에 생각되지 않는다”고 비난했다. 하지만 은행들은 “사고통지는 한 달 이내에만 하면 되는 것”이라고 주장했다.\n",
      "------\n",
      "문서5: 한국만화영상진흥원(원장 신종철, 이하 진흥원)이 만화예술인 및 예비 만화인을 위한 만화인 헬프데스크 권익보호 교육에 나선다. ‘만화인 헬프데스크(이하 헬프데스크)’는 불공정 계약으로 인한 고충을 해소하고 공정한 만화계 환경조성을 위한 제도적 기반 마련을 위해 만화분야 창작자 및 기업의 법률, 세무·회계 등 창작활동과 관련된 각종 법리적 문제해결을 돕는 무료 권익보호 프로그램이다. <만화인 헬프데스크 권익보호 교육>은 만화가 및 만화종사자들의 권익보호 향상을 위해 유용한 법률, 세무 등의 전문지식 및 심리 등 다양한 커리큘럼을 알기 쉽게 전달할 수 있도록 제작한 온라인 영상으로 총 4종으로 구성됐다. 권익보호 교육의 주요 내용은 만화인 헬프데스크 이용가이드 영상을 비롯해 각 분야별 전문가들이 참여해 저작권법, 상표법, 종합소득세 등 만화인들의 권익보호에 실질적인 도움을 주는 교육 영상이다. 교육 영상은 강의 및 패러디를 활용해 설명을 쉽고 재미있게 풀어내면서 개념 이해도를 높이고 교육의 효율성을 극대화할 예정이다. ‘만화인 헬프데스크 이용 가이드’ 영상은 헬프데스크 소개, 헬프데스크 자문 종류, 신청 절차 및 유의사항 등 헬프데스크 이용 방법을 소개하면서 보다 쉽게 상담을 신청할 수 있도록 유도한다. ‘5분 만에 이해하는 저작권법’ 영상은 헬프데스크 상주 변호사와 함께 만화인들의 주된 법적 애로사항으로 손꼽히는 저작권의 개념, 만화·애니메이션·웹툰 등 콘텐츠 별 저작권의 특성, 저작권법 분쟁사례, 저작권법 관련 각종 이슈 등을 집중 조명한다. ‘5분 만에 이해하는 상표법’ 영상은 상주 변호사와 함께 상표의 개념, 저작권과 상표의 차이, 상표 등록 이유, 상표권 침해사례, 상표 등록 시 유의사항 등을 설명하고, ‘5분 만에 이해하는 종합소득세’ 영상은 헬프데스크 자문위원 윤장우 회계사와 함께 종합소득세 개념, 사업소득 신고유형 등을 교육한다. 교육영상은 진흥원 공식 유튜브 채널에서 누구나 볼 수 있다. 법률, 회계, 세무, 창업, 복지 관련 기초교육이 수시로 이루어질 수 있도록 할 예정이다. ‘만화인 헬프데스크 권익보호 교육’은 영상을 통한 온라인 교육뿐 아니라 심리교육과 법률교육 등을 오프라인 교육으로도 진행한다. 윤유정 심리강사와 신재욱 심리강사가 함께 하는 ‘2020 만화인 권익보호 교육 『심리 교육 “괜찮아, 나는 만화인이야”』를 진행하고, ’2020 만화인 권익보호 상담 『찾아가는 법률 상담』을 통해 1:1 법률상담을 운영한다. 콘텐츠 거래 및 이용, 저작권, 계약서 검토, 법령 해석, 만화IP양도 및 사업화 추진 관리 등 다양한 법률 자문을 받을 수 있다. 한국만화영상진흥원 신종철 원장은 “K-Comics의 지속적인 성장을 위해 창작자의 권익보호가 무엇보다 중요한 시점에서 무료로 진행되는 만화인 헬프데스크 권익보호 교육은 만화가 및 예비만화가에게 불공정 계약 등으로 인한 폐해를 미연에 방지하고, 공정한 창작생태계 구축을 위한 좋은 기회가 될 것이다.”면서 “권익보호 교육 외에도 현재 표준계약, 국비 만화 지원 사업 등 온라인 플랫폼을 통한 다양한 교육프로그램을 운영 중이며, 교육범위를 점차 확대할 계획이다.”라고 말했다.<|im_end|>\n",
      "<|im_start|>user\n",
      "청소년활동진흥법 초안 작성을 담당한 국회의원은 누구입니까?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(prompt_list[34])\n",
    "print('--'*30)\n",
    "print('--'*30)\n",
    "print('--'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c74f4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "검색 결과에는 청소년활동진흥법 초안 작성을 담당한 국회의원을 찾을 수 없습니다.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(label_list[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e91bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb738ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaa4588820b47ba9243f5b82210ac89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 예측:\n",
      "검색 결과에서는 해당 정보가 명시되어 있지 않습니다. 이 문제에 대한 답변을 드릴 수 없습니다. [[ref1]], [[ref2]], [[ref3]], [[ref4]], [[ref5]]에서 해당 정보를 찾을 수 없습니다.\n",
      "정답:\n",
      "\n",
      "검색 결과에는 청소년활동진흥법 초안 작성을 담당한 국회의원을 찾을 수 없습니다.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model_id = 'Qwen/Qwen2.5-3B-Instruct'\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map='auto', dtype=torch.bfloat16, quantization_config=bnb_config)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "pipe = pipeline('text-generation', model=base_model, tokenizer=base_tokenizer)\n",
    "eos_token = base_tokenizer('<|im_end|>', add_special_tokens=False)['input_ids'][0]\n",
    "\n",
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens=1024, eos_token_id=eos_token, do_sample=False)\n",
    "    \n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()\n",
    "\n",
    "prompt = prompt_list[34]\n",
    "label = label_list[34]\n",
    "pred = test_inference(pipe, prompt)\n",
    "\n",
    "print(f'모델의 예측:\\n{pred}')\n",
    "print(f'정답:\\n{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "444da6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "del base_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a0d6ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36daff9fafc64e00bc4abcb7ae57e265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 예측:\n",
      "현재로서는 해당 정보를 찾을 수 없습니다 ([[ref1]])\n",
      "정답:\n",
      "\n",
      "검색 결과에는 청소년활동진흥법 초안 작성을 담당한 국회의원을 찾을 수 없습니다.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peft_model_id = 'qwen_2.5-3b_rag-ko/checkpoint-236'\n",
    "peft_model = AutoPeftModelForCausalLM.from_pretrained(peft_model_id, device_map='auto', dtype=torch.bfloat16, quantization_config=bnb_config)\n",
    "pipe = pipeline('text-generation', model=peft_model, tokenizer=base_tokenizer)\n",
    "\n",
    "prompt = prompt_list[34]\n",
    "label = label_list[34]\n",
    "pred = test_inference(pipe, prompt)\n",
    "\n",
    "print(f'모델의 예측:\\n{pred}')\n",
    "print(f'정답:\\n{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bd06bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del peft_model\n",
    "del base_tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dae9d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU 메모리 점유 중인 텐서 목록 ===\n",
      "Shape: torch.Size([151936, 2048]), Size: 593.50 MB, Type: torch.bfloat16\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([11272192, 1]), Size: 10.75 MB, Type: torch.uint8\n",
      "Shape: torch.Size([352256]), Size: 1.34 MB, Type: torch.float32\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "Shape: torch.Size([2097152, 1]), Size: 2.00 MB, Type: torch.uint8\n",
      "--- 총 발견된 텐서 개수: 1083\n",
      "--- 총 추정 메모리 사용량: 2.04 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Coding\\Local\\exercise_book_ver2\\.venv\\Lib\\site-packages\\torch\\__init__.py:1136: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2420\\2414447976.py:10: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
      "c:\\Coding\\Local\\exercise_book_ver2\\.venv\\Lib\\site-packages\\torch\\_inductor\\ops_handler.py:745: UserWarning: undefined OpHandler.data, please add missing op schema\n",
      "  warnings.warn(f\"undefined OpHandler.{name}, please add missing op schema\")\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_memory_leaks():\n",
    "    print(\"=== GPU 메모리 점유 중인 텐서 목록 ===\")\n",
    "    count = 0\n",
    "    total_mem = 0\n",
    "    \n",
    "    # 가비지 컬렉터가 관리하는 모든 객체를 스캔\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            # 텐서 객체인지 확인 (파라미터 포함)\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                \n",
    "                # GPU(cuda)에 있는지 확인\n",
    "                if obj.is_cuda:\n",
    "                    # 텐서 크기 계산\n",
    "                    mem = obj.element_size() * obj.nelement()\n",
    "                    total_mem += mem\n",
    "                    \n",
    "                    # 너무 작은 건 생략하고 큰 것만 출력 (예: 1MB 이상)\n",
    "                    if mem > 1024 * 1024: \n",
    "                        print(f\"Shape: {obj.shape}, Size: {mem/1024**2:.2f} MB, Type: {obj.dtype}\")\n",
    "                        # 어떤 변수가 잡고 있는지는 알기 어렵지만, shape를 보면 뭔지 짐작 가능\n",
    "                        # 예: (32000, 4096) -> 이건 모델의 임베딩 레이어구나!\n",
    "                    \n",
    "                    count += 1\n",
    "        except:\n",
    "            pass # 접근 불가능한 객체는 패스\n",
    "            \n",
    "    print(f\"--- 총 발견된 텐서 개수: {count}\")\n",
    "    print(f\"--- 총 추정 메모리 사용량: {total_mem / 1024**3:.2f} GB\")\n",
    "\n",
    "# 실행\n",
    "check_gpu_memory_leaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e059b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
