{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45fe5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ccbab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://docs.langchain.com/oss/python/langchain/overview#langchain-expression-language-lcel\"\n",
    "\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url,\n",
    "    max_depth=10,\n",
    "    extractor=lambda x: BS(x, 'html.parser').text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26f35ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_11592\\3603591358.py:6: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  extractor=lambda x: BS(x, 'html.parser').text\n",
      "c:\\Coding\\Local\\exercise_book_ver2\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\recursive_url_loader.py:44: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = BeautifulSoup(raw_html, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs_sorted = sorted(docs, key=lambda x: x.metadata['source'])[:70]\n",
    "concatenated_content = '\\n\\n\\n ------- \\n\\n\\n'.join(doc.page_content for doc in docs_sorted)\n",
    "print(len(docs_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cacb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gen = ChatOpenAI(model='gpt-5-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b56ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''\n",
    "당신은 LCEL(Langchain Expression Language) 전문가인 코딩 어시스턴트입니다.\n",
    "다음은 필요한 LCEL 문서 전문입니다.:\n",
    "-------------------\n",
    "{context}\n",
    "-------------------\n",
    "위에 제공된 문서를 기반으로 사용자 질문에 답변하세요.\n",
    "제공하는 코드는 실행 가능해야 하며, 필요한 모든 import문과 변수들이 정의되어 있어야 합니다.\n",
    "답변을 다음과 같은 구조로 작성하세요.:\n",
    "1. prefix: 문제와 접근 방식에 대한 설명\n",
    "2. imports: 코드 블록 import문\n",
    "3. code: import문을 제외한 코드 블록\n",
    "4. description: 질문에 대한 코드 스키마\n",
    "\n",
    "다음은 사용자의 질문입니다.:\n",
    "'''\n",
    "\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system),\n",
    "     ('placeholder', '{messages}')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffcf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Code(BaseModel):\n",
    "    prefix: str = Field(description='문제와 접근 방식에 대한 설명')\n",
    "    imports: str = Field(description='코드 블록 import문')\n",
    "    code: str = Field(description='import문을 제외한 코드 블록')\n",
    "    description: str = Field(description='질문에 대한 코드 스키마')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c116bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_gen_chain = code_gen_prompt | llm_gen.with_structured_output(Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5975ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제와 접근 방식 설명:\n",
      "사용자는 LCEL(LangChain Expression Language)로 RAG(검색 기반 생성, Retrieval-Augmented Generation) 체인을 만드는 방법을 물었습니다. 아래 예시는 두 부분으로 제공합니다:\n",
      "\n",
      "1) LCEL 예제 스니펫(간단한 선언형 문법) — 실제 LCEL 문법의 핵심 아이디어를 보여줍니다.  \n",
      "2) 실행 가능한 파이썬 코드 — 실제로 동작하는 간단한 RAG 파이프라인을 구축하는 코드입니다.  \n",
      "\n",
      "실행 코드는 외부 LLM/임베딩 API 키 없이도 동작하도록 TF-IDF 기반의 로컬 retriever와 Dummy LLM(샘플 응답 생성기)을 사용합니다. 이것은 LCEL 선언을 파싱해 RAG 체인을 빌드하는 간단한 인터프리터 역할을 하며, 실제 환경에서는 OpenAI/Anthropic 임베딩 + FAISS, 그리고 실제 LLM으로 쉽게 교체하면 됩니다.\n",
      "from dataclasses import dataclass\n",
      "from typing import List, Dict, Any, Tuple\n",
      "import re\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "import numpy as np\n",
      "\n",
      "# (주의) scikit-learn이 없으면 `pip install scikit-learn` 필요합니다.\n",
      "@dataclass\n",
      "class Document:\n",
      "    page_content: str\n",
      "    metadata: Dict[str, Any]\n",
      "\n",
      "\n",
      "class TfidfRetriever:\n",
      "    \"\"\"간단한 TF-IDF 기반 검색기: query와 문서 간 코사인 유사도로 상위 k개 문서 반환.\"\"\"\n",
      "    def __init__(self, docs: List[Document], k: int = 3):\n",
      "        self.docs = docs\n",
      "        self.k = k\n",
      "        self.texts = [d.page_content for d in docs]\n",
      "        self.vectorizer = TfidfVectorizer()\n",
      "        if len(self.texts) > 0:\n",
      "            self.doc_matrix = self.vectorizer.fit_transform(self.texts)\n",
      "        else:\n",
      "            self.doc_matrix = None\n",
      "\n",
      "    def get_relevant(self, query: str) -> List[Document]:\n",
      "        if self.doc_matrix is None:\n",
      "            return []\n",
      "        q_vec = self.vectorizer.transform([query])\n",
      "        sims = (self.doc_matrix @ q_vec.T).toarray().ravel()\n",
      "        idxs = np.argsort(-sims)[: self.k]\n",
      "        # 유사도 0인 문서는 제외\n",
      "        results = [self.docs[i] for i in idxs if sims[i] > 0]\n",
      "        return results\n",
      "\n",
      "\n",
      "class DummyLLM:\n",
      "    \"\"\"샘플 LLM: 단순히 상위 문서를 컨텍스트로 포함해 모사 답변을 생성합니다.\"\"\"\n",
      "\n",
      "    def __init__(self, name: str = \"dummy-llm\"):\n",
      "        self.name = name\n",
      "\n",
      "    def generate(self, query: str, context_docs: List[Document]) -> str:\n",
      "        if not context_docs:\n",
      "            return f\"(Dummy LLM) 질의: {query}\\n-> 관련 문서가 없어 기본 답변을 반환합니다.\"\n",
      "        context = \"\\n\\n---\\n\\n\".join(f\"- {d.page_content}\" for d in context_docs)\n",
      "        return (\n",
      "            f\"(Dummy LLM) 질의: {query}\\n\\n\" f\"사용된 문서(상위 {len(context_docs)}개):\\n{context}\\n\\n요약/응답: 이 문서들을 기반으로 한 예시 답변입니다.\"\n",
      "        )\n",
      "\n",
      "\n",
      "# 간단한 LCEL 파서: 매우 제한된 문법을 지원 (key = value 또는 function-like)\n",
      "# 예시 LCEL 문법 (아래처럼 사용):\n",
      "# embeddings = dummy\n",
      "# retriever = tfidf(k=3)\n",
      "# llm = dummy\n",
      "# chain = rag(retriever=retriever, llm=llm)\n",
      "\n",
      "def parse_lcel(text: str) -> Dict[str, str]:\n",
      "    conf: Dict[str, str] = {}\n",
      "    lines = [ln.strip() for ln in text.splitlines()]\n",
      "    for ln in lines:\n",
      "        if not ln or ln.startswith(\"#\"):\n",
      "            continue\n",
      "        if \"=\" in ln:\n",
      "            k, v = [s.strip() for s in ln.split(\"=\", 1)]\n",
      "            conf[k] = v\n",
      "    return conf\n",
      "\n",
      "\n",
      "def build_rag_from_lcel(lcel: str, docs: List[Document]):\n",
      "    cfg = parse_lcel(lcel)\n",
      "\n",
      "    # retriever 파싱 (tfidf(k=N) 형태만 지원)\n",
      "    retr_str = cfg.get(\"retriever\", \"tfidf(k=3)\")\n",
      "    m = re.match(r\"tfidf\\s*\\(\\s*k\\s*=\\s*(\\d+)\\s*\\)\", retr_str)\n",
      "    k = int(m.group(1)) if m else 3\n",
      "    retriever = TfidfRetriever(docs, k=k)\n",
      "\n",
      "    # llm 생성 (dummy 만 지원)\n",
      "    llm_key = cfg.get(\"llm\", \"dummy\").lower()\n",
      "    if llm_key.startswith(\"dummy\"):\n",
      "        llm = DummyLLM()\n",
      "    else:\n",
      "        # 실제 LLM(예: OpenAI)을 사용하려면 여기에 분기 추가\n",
      "        llm = DummyLLM()\n",
      "\n",
      "    # 간단한 RAG 체인: retriever로 컨텍스트를 얻어 LLM에 전달\n",
      "    def rag_chain(query: str) -> Dict[str, Any]:\n",
      "        context_docs = retriever.get_relevant(query)\n",
      "        answer = llm.generate(query, context_docs)\n",
      "        return {\n",
      "            \"query\": query,\n",
      "            \"answer\": answer,\n",
      "            \"retrieved\": [d.page_content for d in context_docs],\n",
      "        }\n",
      "\n",
      "    return rag_chain, retriever, llm\n",
      "\n",
      "\n",
      "# 샘플 문서들\n",
      "SAMPLE_DOCS = [\n",
      "    Document(page_content=\"San Francisco is known for the Golden Gate Bridge and cool foggy weather.\", metadata={\"source\": \"doc1\"}),\n",
      "    Document(page_content=\"New York is famous for Times Square and hot summers.\", metadata={\"source\": \"doc2\"}),\n",
      "    Document(page_content=\"Los Angeles has Hollywood and warm beaches year-round.\", metadata={\"source\": \"doc3\"}),\n",
      "    Document(page_content=\"Seattle is rainy and home to many coffee shops.\", metadata={\"source\": \"doc4\"}),\n",
      "]\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # LCEL 예시 (간단한 선언형)\n",
      "    lcel_example = \"\"\"\n",
      "    # LCEL RAG 예제: retriever로 TF-IDF(top k=2) 사용, llm은 dummy\n",
      "    embeddings = dummy\n",
      "    retriever = tfidf(k=2)\n",
      "    llm = dummy\n",
      "    chain = rag(retriever=retriever, llm=llm)\n",
      "    \"\"\"\n",
      "\n",
      "    chain, retriever, llm = build_rag_from_lcel(lcel_example, SAMPLE_DOCS)\n",
      "\n",
      "    queries = [\n",
      "        \"What is famous in San Francisco?\",\n",
      "        \"Which city is rainy and known for coffee?\",\n",
      "        \"Tell me about beaches and Hollywood.\",\n",
      "    ]\n",
      "\n",
      "    for q in queries:\n",
      "        out = chain(q)\n",
      "        print(\"\\n=== QUERY ===\")\n",
      "        print(q)\n",
      "        print(\"\\n--- ANSWER ---\\n\")\n",
      "        print(out[\"answer\"])\n",
      "        print(\"\\n--- RETRIEVED DOCS ---\")\n",
      "        for i, d in enumerate(out[\"retrieved\"], 1):\n",
      "            print(f\"[{i}] {d}\")\n",
      "\n",
      "    # 실제 환경으로 확장하려면:\n",
      "    # - embeddings = OpenAIEmbeddings(...) 또는 HuggingFace 임베딩을 사용\n",
      "    # - vectorstore = FAISS.from_documents(docs, embeddings)\n",
      "    # - retriever = vectorstore.as_retriever(search_kwargs={\"k\": N})\n",
      "    # - llm = OpenAI(...) 또는 Anthropic 모델\n",
      "    # - chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
      "    # 위 구현을 parse_lcel와 build_rag_from_lcel에 추가하면 LCEL으로 실환경 RAG 자동 구성 가능\n",
      "\n",
      "이 코드는 다음 스키마로 동작합니다:\n",
      "\n",
      "- LCEL 예시: 간단한 선언형(embeddings, retriever, llm, chain) 문법을 문자열로 작성합니다.\n",
      "- parse_lcel: LCEL 텍스트에서 key=value 형식을 파싱해 설정 딕셔너리를 반환합니다.\n",
      "- build_rag_from_lcel: 파싱 결과와 문서 리스트를 받아 retriever와 llm을 생성하고 rag_chain(질의 입력 -> 답변 + 검색문서 목록 반환) 함수를 리턴합니다.\n",
      "- TfidfRetriever: 로컬 TF-IDF 벡터화 및 코사인 유사도로 상위 k개 문서를 반환합니다.\n",
      "- DummyLLM: 검색된 문서를 컨텍스트로 사용하여 모사된 답변을 생성합니다.\n",
      "\n",
      "실환경에서는 DummyLLM과 TF-IDF를 OpenAI/Anthropic LLM, 임베딩(예: OpenAIEmbeddings, HuggingFace), FAISS(또는 다른 vector store)로 바꿔 동일한 LCEL 선언으로 RAG 체인을 구성할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "question = 'LCEL로 RAG 체인을 어떻게 만들어?'\n",
    "\n",
    "solution = code_gen_chain.invoke(\n",
    "    {'context':concatenated_content, 'messages':[('user', question)]}\n",
    ")\n",
    "\n",
    "print(solution.prefix)\n",
    "print(solution.imports)\n",
    "print(solution.code)\n",
    "print(solution.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4497f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    error: str\n",
    "    messages: List\n",
    "    generation: str\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fce3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    print('--- generate ---')\n",
    "\n",
    "    messages = state['messages']\n",
    "    iterations = state['iterations']\n",
    "    error = state.get('error', 'no')\n",
    "\n",
    "    if error == 'yes':\n",
    "        messages += [\n",
    "            ('user', '다시 시도해보세요. 출력 결과를 prefix, imports, code block으로 구조화하기 위해 코드 도구를 호출하세요.:')\n",
    "        ]\n",
    "    code_solution = code_gen_chain.invoke(\n",
    "        {'context':concatenated_content, 'messages':messages}\n",
    "    )\n",
    "    messages += [\n",
    "        ('assistant', f'{code_solution.prefix} \\nImports: {code_solution.imports} \\nCode: {code_solution.code}')\n",
    "    ]\n",
    "    iterations += 1\n",
    "    \n",
    "    return {'messages':messages, 'generation': code_solution, 'iterations':iterations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50c174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_check(state):\n",
    "    print('--- code check ---')\n",
    "\n",
    "    messages = state['messages']\n",
    "    code_solution = state['generation']\n",
    "    iterations = state['iterations']\n",
    "\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print('--import check: Failure--')\n",
    "        error_message = [('user', f'당신의 코드는 import 테스트를 실패했습니다.: {e}')]\n",
    "        messages += error_message\n",
    "\n",
    "        return {'messages':messages, 'generation':code_solution, 'iterations':iterations, 'error':'yes'}\n",
    "    \n",
    "    try:\n",
    "        exec(imports + '\\n\\n' + code)\n",
    "    except Exception as e:\n",
    "        print('--code block check: Failure')\n",
    "        error_message = [('user', f'당신의 코드는 실행 테스트를 실패했습니다.: {e}')]\n",
    "        messages += error_message\n",
    "\n",
    "        return {'messages':messages, 'generation':code_solution, 'iterations':iterations, 'error':'yes'}\n",
    "    \n",
    "    print('--success--')\n",
    "\n",
    "    return {'messages':messages, 'generation':code_solution, 'iterations':iterations, 'error':'no'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f087836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect(state):\n",
    "    print('--- generate code solution ---')\n",
    "\n",
    "    messages = state['messages']\n",
    "    iterations = state['iterations']\n",
    "    code_solution = state['generation']\n",
    "\n",
    "    reflections = code_gen_chain.invoke(\n",
    "        {'context':concatenated_content, 'messages':messages}\n",
    "    )\n",
    "    messages += [('assistant', f'여기 오류를 반영한 코드입니다: {reflections}')]\n",
    "\n",
    "    return {'messages':messages, 'generation':code_solution, 'iterations':iterations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20704557",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 'do not reflect'\n",
    "\n",
    "def decide_to_finish(state):\n",
    "    error = state['error']\n",
    "    iterations = state['iterations']\n",
    "\n",
    "    if error == 'no' or iterations == 3:\n",
    "        print('--finish--')\n",
    "        return 'end'\n",
    "    else:\n",
    "        print('--retry--')\n",
    "        if flag is True:\n",
    "            return 'reflect'\n",
    "        else:\n",
    "            return 'generate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08cf5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node('generate', generate)\n",
    "workflow.add_node('code_check', code_check)\n",
    "workflow.add_node('reflect', reflect)\n",
    "\n",
    "workflow.set_entry_point('generate')\n",
    "workflow.add_edge('generate', 'code_check')\n",
    "workflow.add_conditional_edges(\n",
    "    'code_check',\n",
    "    decide_to_finish,\n",
    "    {'end':END, 'reflect':'reflect', 'generate':'generate'}\n",
    ")\n",
    "workflow.add_edge('reflect', 'generate')\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de482360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- generate ---\n",
      "--- code check ---\n",
      "--code block check: Failure\n",
      "--retry--\n",
      "--- generate ---\n",
      "--- code check ---\n",
      "--code block check: Failure\n",
      "--retry--\n",
      "--- generate ---\n",
      "--- code check ---\n",
      "--code block check: Failure\n",
      "--finish--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'error': 'yes',\n",
       " 'messages': [('user',\n",
       "   '문자열을 runnable 객체에 직접 전달하고, 이를 사용하여 내 프롬프트에 필요한 입력을 구성하려면 어떻게 해야 하나요?'),\n",
       "  ('assistant',\n",
       "   '문제와 접근 방식에 대한 설명\\n\\n요약: 사용자가 입력한 \"문자열\"을 직접 runnable 객체(LLM 또는 툴 호출을 래핑한 객체)에 전달하고, 그 문자열을 프롬프트 템플릿에 주입해 최종 입력으로 만드는 패턴을 보여드립니다. 접근 방식은 어댑터(Adapter) 패턴을 사용하여 raw 문자열을 받아 프롬프트를 구성하고 내부 runnable의 run 메서드에 전달하는 것입니다. 예제는 실제 LLM 호출 대신 Mock LLM을 사용해 완전히 실행 가능한 형태로 제공합니다. 실제 LangChain / LangGraph의 Runnable 인터페이스로 교체하는 방법도 주석으로 안내합니다. \\nImports: import asyncio\\nfrom dataclasses import dataclass\\nfrom typing import Any, Callable, Optional\\n\\n# (선택) 실제 LangChain Runnable을 쓰려면 아래 import를 사용하세요.\\n# from langchain.schema import Runnable  # 예시 (버전/패키지에 따라 경로가 다를 수 있음) \\nCode: @dataclass\\nclass MockLLM:\\n    \"\"\"간단한 mock LLM runnable. 실제 LLM 클라이언트(예: OpenAI, Anthropic 등)의 run/ainvoke 메서드 대신 사용합니다.\"\"\"\\n    name: str = \"mock-llm\"\\n\\n    async def run(self, prompt: str) -> str:\\n        # 실제 환경에서는 여기에 API 호출을 넣습니다 (비동기 예시)\\n        await asyncio.sleep(0.05)\\n        return f\"[{self.name}] 응답: {prompt[:200]}\"  # 응답 요약\\n\\n\\nclass StringToRunnableAdapter:\\n    \"\"\"문자열을 받아서 prompt_template에 주입한 뒤 내부 runnable.run(prompt)를 호출합니다.\\n\\n    - runnable: run(prompt: str) -> str 또는 async def run(prompt: str) -> str 를 제공해야 합니다.\\n    - prompt_template: Python format string, {input} 플레이스홀더 사용.\\n    \"\"\"\\n\\n    def __init__(self, runnable: Any, prompt_template: str = \"{input}\"):\\n        self.runnable = runnable\\n        self.prompt_template = prompt_template\\n\\n    async def run(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"비동기 호출 인터페이스.\\n\\n        raw_input: 사용자가 전달한 문자열\\n        kwargs: 프롬프트를 보다 동적으로 생성하려면 추가 키워드 인자를 사용할 수 있음\\n        \"\"\"\\n        # 1) 안전하게 템플릿에 주입\\n        prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n\\n        # 2) 내부 runnable이 비동기 run을 제공하면 await, 아니면 동기 호출\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        # 비동기 함수인지 검사\\n        if asyncio.iscoroutinefunction(run_fn):\\n            return await run_fn(prompt)\\n        else:\\n            # 동기 함수라면 스레드화 등 고려 가능하지만 여기선 바로 호출\\n            return run_fn(prompt)\\n\\n    def run_sync(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"동기 호출 래퍼. 내부 runnable이 동기라면 바로 호출, 비동기라면 asyncio.run으로 실행합니다.\"\"\"\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        if asyncio.iscoroutinefunction(run_fn):\\n            # 주의: 이미 이벤트 루프가 돌고 있으면 오류가 납니다. (예: Jupyter)\\n            return asyncio.run(self.run(raw_input, **kwargs))\\n        else:\\n            prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n            return run_fn(prompt)\\n\\n\\n# 예제 사용법\\nasync def main_async_example():\\n    # 1) 실제 LLM 대신 MockLLM 사용 (실제 LLM으로 교체 가능)\\n    llm = MockLLM(name=\"gpt-mock\")\\n\\n    # 2) 어댑터를 만들 때 프롬프트 템플릿을 정의합니다.\\n    template = (\\n        \"You are an assistant.\\\\n\"\\n        \"User input:\\\\n{input}\\\\n\\\\n\"\\n        \"Please provide a short summary and 3 bullet points.\"\\n    )\\n    adapter = StringToRunnableAdapter(llm, prompt_template=template)\\n\\n    # 3) 사용자가 보낸 문자열을 직접 전달\\n    user_string = (\\n        \"LangChain은 LLM을 중심으로 하는 애플리케이션 개발을 단순화하는 프레임워크입니다.\"\\n        \" 에이전트, 체인, 도구 통합 등을 제공합니다.\"\\n    )\\n\\n    output = await adapter.run(user_string)\\n    print(\"--- 비동기 실행 결과 ---\")\\n    print(output)\\n\\n\\ndef main_sync_example():\\n    # 동기 runnable (예시로 동기 run을 가진 간단 객체 사용)\\n    class SyncEcho:\\n        def run(self, prompt: str) -> str:\\n            return f\"[sync-echo] 받은 프롬프트 길이={len(prompt)}\"\\n\\n    sync_runnable = SyncEcho()\\n    adapter = StringToRunnableAdapter(sync_runnable, prompt_template=\"Echoing: {input}\")\\n\\n    result = adapter.run_sync(\"동기 문자열 테스트\")\\n    print(\"--- 동기 실행 결과 ---\")\\n    print(result)\\n\\n\\nif __name__ == \"__main__\":\\n    # 비동기 예제 실행\\n    asyncio.run(main_async_example())\\n\\n    # 동기 예제 실행\\n    main_sync_example()\\n\\n# 실제 LangChain의 Runnable 인터페이스를 사용하는 경우(설치/버전 고려):\\n# from langchain.schema import Runnable\\n# class MyAdapter(Runnable[str, str]):\\n#     def __init__(self, runnable: Runnable):\\n#         self.runnable = runnable\\n#     def invoke(self, input: str) -> str:\\n#         prompt = ...\\n#         return self.runnable.invoke(prompt)\\n'),\n",
       "  ('user', \"당신의 코드는 실행 테스트를 실패했습니다.: name 'Any' is not defined\"),\n",
       "  ('user',\n",
       "   '다시 시도해보세요. 출력 결과를 prefix, imports, code block으로 구조화하기 위해 코드 도구를 호출하세요.:'),\n",
       "  ('assistant',\n",
       "   '문제 및 접근 방식 설명:\\n이전 코드에서 \\'Any\\'가 정의되지 않아 실행 오류가 발생했습니다. 해결 방법은 typing에서 Any를 명시적으로 import하는 것입니다. 아래 코드는 사용자가 제공한 문자열을 runnable 객체(동기 또는 비동기 run 메서드를 가진 객체)에 직접 전달하여 프롬프트 템플릿에 주입한 뒤 내부 runnable의 run을 호출하는 어댑터 패턴을 구현합니다. 예제에는 비동기 MockLLM과 동기 SyncEcho를 포함하여 바로 실행 가능한 예제를 제공합니다. \\nImports: import asyncio\\nfrom dataclasses import dataclass\\nfrom typing import Any, Callable, Optional \\nCode: @dataclass\\nclass MockLLM:\\n    \"\"\"간단한 mock LLM runnable. 실제 LLM 클라이언트의 run/ainvoke 메서드 대신 사용합니다.\"\"\"\\n    name: str = \"mock-llm\"\\n\\n    async def run(self, prompt: str) -> str:\\n        # 실제 환경에서는 여기에 API 호출을 넣습니다 (비동기 예시)\\n        await asyncio.sleep(0.05)\\n        return f\"[{self.name}] 응답: {prompt[:200]}\"\\n\\n\\nclass StringToRunnableAdapter:\\n    \"\"\"문자열을 받아서 prompt_template에 주입한 뒤 내부 runnable.run(prompt)를 호출합니다.\\n\\n    - runnable: run(prompt: str) -> str 또는 async def run(prompt: str) -> str 를 제공해야 합니다.\\n    - prompt_template: Python format string, {input} 플레이스홀더 사용.\\n    \"\"\"\\n\\n    def __init__(self, runnable: Any, prompt_template: str = \"{input}\"):\\n        self.runnable = runnable\\n        self.prompt_template = prompt_template\\n\\n    async def run(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"비동기 호출 인터페이스.\\n\\n        raw_input: 사용자가 전달한 문자열\\n        kwargs: 프롬프트를 보다 동적으로 생성하려면 추가 키워드 인자를 사용할 수 있음\\n        \"\"\"\\n        # 1) 안전하게 템플릿에 주입\\n        prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n\\n        # 2) 내부 runnable이 비동기 run을 제공하면 await, 아니면 동기 호출\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        # 비동기 함수인지 검사\\n        if asyncio.iscoroutinefunction(run_fn):\\n            return await run_fn(prompt)\\n        else:\\n            # 동기 함수라면 바로 호출\\n            return run_fn(prompt)\\n\\n    def run_sync(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"동기 호출 래퍼. 내부 runnable이 동기라면 바로 호출, 비동기라면 asyncio.run으로 실행합니다.\"\"\"\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        if asyncio.iscoroutinefunction(run_fn):\\n            # 주의: 이미 이벤트 루프가 돌고 있으면 오류가 발생할 수 있음\\n            return asyncio.run(self.run(raw_input, **kwargs))\\n        else:\\n            prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n            return run_fn(prompt)\\n\\n\\n# 예제 사용법\\nasync def main_async_example():\\n    # 1) 실제 LLM 대신 MockLLM 사용 (실제 LLM으로 교체 가능)\\n    llm = MockLLM(name=\"gpt-mock\")\\n\\n    # 2) 어댑터를 만들 때 프롬프트 템플릿을 정의합니다.\\n    template = (\\n        \"You are an assistant.\\\\n\"\\n        \"User input:\\\\n{input}\\\\n\\\\n\"\\n        \"Please provide a short summary and 3 bullet points.\"\\n    )\\n    adapter = StringToRunnableAdapter(llm, prompt_template=template)\\n\\n    # 3) 사용자가 보낸 문자열을 직접 전달\\n    user_string = (\\n        \"LangChain은 LLM을 중심으로 하는 애플리케이션 개발을 단순화하는 프레임워크입니다.\"\\n        \" 에이전트, 체인, 도구 통합 등을 제공합니다.\"\\n    )\\n\\n    output = await adapter.run(user_string)\\n    print(\"--- 비동기 실행 결과 ---\")\\n    print(output)\\n\\n\\ndef main_sync_example():\\n    # 동기 runnable (예시로 동기 run을 가진 간단 객체 사용)\\n    class SyncEcho:\\n        def run(self, prompt: str) -> str:\\n            return f\"[sync-echo] 받은 프롬프트 길이={len(prompt)}\"\\n\\n    sync_runnable = SyncEcho()\\n    adapter = StringToRunnableAdapter(sync_runnable, prompt_template=\"Echoing: {input}\")\\n\\n    result = adapter.run_sync(\"동기 문자열 테스트\")\\n    print(\"--- 동기 실행 결과 ---\")\\n    print(result)\\n\\n\\nif __name__ == \"__main__\":\\n    # 비동기 예제 실행\\n    asyncio.run(main_async_example())\\n\\n    # 동기 예제 실행\\n    main_sync_example()\\n\\n# 실제 LangChain의 Runnable 인터페이스를 사용하는 경우(설치/버전 고려):\\n# from langchain.schema import Runnable\\n# class MyAdapter(Runnable[str, str]):\\n#     def __init__(self, runnable: Runnable):\\n#         self.runnable = runnable\\n#     def invoke(self, input: str) -> str:\\n#         prompt = ...\\n#         return self.runnable.invoke(prompt)\\n'),\n",
       "  ('user', \"당신의 코드는 실행 테스트를 실패했습니다.: name 'Any' is not defined\"),\n",
       "  ('user',\n",
       "   '다시 시도해보세요. 출력 결과를 prefix, imports, code block으로 구조화하기 위해 코드 도구를 호출하세요.:'),\n",
       "  ('assistant',\n",
       "   '문제와 접근 방식 설명:\\n이전 실행 실패 원인은 typing.Any를 import하지 않아 발생했습니다. 아래 코드는 Any를 포함한 필요한 import를 추가하고, 사용자가 제공한 문자열을 Runnable 객체(동기/비동기 run 메서드 제공)에 직접 전달하여 프롬프트 템플릿에 주입한 뒤 내부 runnable.run(prompt)를 호출하는 어댑터 패턴을 구현합니다. 비동기 MockLLM과 동기 SyncEcho 예제를 포함해 바로 실행 가능한 형태입니다. 이벤트 루프가 이미 실행 중인 환경에서는 run_sync 호출이 실패할 수 있으니, 그 경우 async로 adapter.run(...)을 호출하세요. \\nImports: import asyncio\\nfrom dataclasses import dataclass\\nfrom typing import Any\\n\\n \\nCode: @dataclass\\nclass MockLLM:\\n    \"\"\"간단한 mock LLM runnable. 실제 LLM 클라이언트의 비동기 run 메서드 대신 사용합니다.\"\"\"\\n    name: str = \"mock-llm\"\\n\\n    async def run(self, prompt: str) -> str:\\n        # 실제 환경에서는 여기에 API 호출을 넣습니다 (비동기 예시)\\n        await asyncio.sleep(0.05)\\n        return f\"[{self.name}] 응답: {prompt[:200]}\"\\n\\n\\nclass StringToRunnableAdapter:\\n    \"\"\"문자열을 받아 prompt_template에 주입한 뒤 내부 runnable.run(prompt)를 호출합니다.\\n\\n    - runnable: run(prompt: str) -> str 또는 async def run(prompt: str) -> str 를 제공해야 합니다.\\n    - prompt_template: Python format string, {input} 플레이스홀더 사용.\\n    \"\"\"\\n\\n    def __init__(self, runnable: Any, prompt_template: str = \"{input}\"):\\n        self.runnable = runnable\\n        self.prompt_template = prompt_template\\n\\n    async def run(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"비동기 호출 인터페이스.\\n\\n        raw_input: 사용자가 전달한 문자열\\n        kwargs: 프롬프트를 보다 동적으로 생성하려면 추가 키워드 인자를 사용할 수 있음\\n        \"\"\"\\n        # 안전하게 템플릿에 주입\\n        prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n\\n        # 내부 runnable의 run 메서드 가져오기\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        # 비동기 함수인지 검사\\n        if asyncio.iscoroutinefunction(run_fn):\\n            return await run_fn(prompt)\\n        else:\\n            return run_fn(prompt)\\n\\n    def run_sync(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"동기 호출 래퍼. 내부 runnable이 동기라면 바로 호출, 비동기라면 asyncio.run으로 실행합니다.\\n\\n        주의: 이미 이벤트 루프가 돌고 있는 환경(Jupyter 등)에서는 asyncio.run이 실패합니다.\\n        \"\"\"\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        if asyncio.iscoroutinefunction(run_fn):\\n            try:\\n                return asyncio.run(self.run(raw_input, **kwargs))\\n            except RuntimeError:\\n                # 이미 이벤트 루프가 실행 중인 경우\\n                raise RuntimeError(\\n                    \"현재 이벤트 루프가 실행 중입니다. 동기 호출을 지원하지 않습니다. 대신 `await adapter.run(...)`을 사용하세요.\"\\n                )\\n        else:\\n            prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n            return run_fn(prompt)\\n\\n\\n# 예제 사용법\\nasync def main_async_example():\\n    # 1) 실제 LLM 대신 MockLLM 사용 (실제 LLM으로 교체 가능)\\n    llm = MockLLM(name=\"gpt-mock\")\\n\\n    # 2) 어댑터를 만들 때 프롬프트 템플릿을 정의합니다.\\n    template = (\\n        \"You are an assistant.\\\\n\"\\n        \"User input:\\\\n{input}\\\\n\\\\n\"\\n        \"Please provide a short summary and 3 bullet points.\"\\n    )\\n    adapter = StringToRunnableAdapter(llm, prompt_template=template)\\n\\n    # 3) 사용자가 보낸 문자열을 직접 전달\\n    user_string = (\\n        \"LangChain은 LLM을 중심으로 하는 애플리케이션 개발을 단순화하는 프레임워크입니다.\"\\n        \" 에이전트, 체인, 도구 통합 등을 제공합니다.\"\\n    )\\n\\n    output = await adapter.run(user_string)\\n    print(\"--- 비동기 실행 결과 ---\")\\n    print(output)\\n\\n\\ndef main_sync_example():\\n    # 동기 runnable (예시로 동기 run을 가진 간단 객체 사용)\\n    class SyncEcho:\\n        def run(self, prompt: str) -> str:\\n            return f\"[sync-echo] 받은 프롬프트 길이={len(prompt)}\"\\n\\n    sync_runnable = SyncEcho()\\n    adapter = StringToRunnableAdapter(sync_runnable, prompt_template=\"Echoing: {input}\")\\n\\n    result = adapter.run_sync(\"동기 문자열 테스트\")\\n    print(\"--- 동기 실행 결과 ---\")\\n    print(result)\\n\\n\\nif __name__ == \"__main__\":\\n    # 비동기 예제 실행\\n    try:\\n        asyncio.run(main_async_example())\\n    except RuntimeError:\\n        # 이미 이벤트 루프가 실행 중인 환경에서는 예외가 발생할 수 있음.\\n        print(\"메인에서 asyncio.run 실패: 이미 이벤트 루프가 실행 중일 수 있습니다. 대안으로 비동기 컨텍스트에서 main_async_example를 직접 호출하세요.\")\\n\\n    # 동기 예제 실행\\n    try:\\n        main_sync_example()\\n    except RuntimeError as e:\\n        print(\"동기 예제 실행 중 오류:\", e)\\n'),\n",
       "  ('user', \"당신의 코드는 실행 테스트를 실패했습니다.: name 'Any' is not defined\")],\n",
       " 'generation': Code(prefix='문제와 접근 방식 설명:\\n이전 실행 실패 원인은 typing.Any를 import하지 않아 발생했습니다. 아래 코드는 Any를 포함한 필요한 import를 추가하고, 사용자가 제공한 문자열을 Runnable 객체(동기/비동기 run 메서드 제공)에 직접 전달하여 프롬프트 템플릿에 주입한 뒤 내부 runnable.run(prompt)를 호출하는 어댑터 패턴을 구현합니다. 비동기 MockLLM과 동기 SyncEcho 예제를 포함해 바로 실행 가능한 형태입니다. 이벤트 루프가 이미 실행 중인 환경에서는 run_sync 호출이 실패할 수 있으니, 그 경우 async로 adapter.run(...)을 호출하세요.', imports='import asyncio\\nfrom dataclasses import dataclass\\nfrom typing import Any\\n\\n', code='@dataclass\\nclass MockLLM:\\n    \"\"\"간단한 mock LLM runnable. 실제 LLM 클라이언트의 비동기 run 메서드 대신 사용합니다.\"\"\"\\n    name: str = \"mock-llm\"\\n\\n    async def run(self, prompt: str) -> str:\\n        # 실제 환경에서는 여기에 API 호출을 넣습니다 (비동기 예시)\\n        await asyncio.sleep(0.05)\\n        return f\"[{self.name}] 응답: {prompt[:200]}\"\\n\\n\\nclass StringToRunnableAdapter:\\n    \"\"\"문자열을 받아 prompt_template에 주입한 뒤 내부 runnable.run(prompt)를 호출합니다.\\n\\n    - runnable: run(prompt: str) -> str 또는 async def run(prompt: str) -> str 를 제공해야 합니다.\\n    - prompt_template: Python format string, {input} 플레이스홀더 사용.\\n    \"\"\"\\n\\n    def __init__(self, runnable: Any, prompt_template: str = \"{input}\"):\\n        self.runnable = runnable\\n        self.prompt_template = prompt_template\\n\\n    async def run(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"비동기 호출 인터페이스.\\n\\n        raw_input: 사용자가 전달한 문자열\\n        kwargs: 프롬프트를 보다 동적으로 생성하려면 추가 키워드 인자를 사용할 수 있음\\n        \"\"\"\\n        # 안전하게 템플릿에 주입\\n        prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n\\n        # 내부 runnable의 run 메서드 가져오기\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        # 비동기 함수인지 검사\\n        if asyncio.iscoroutinefunction(run_fn):\\n            return await run_fn(prompt)\\n        else:\\n            return run_fn(prompt)\\n\\n    def run_sync(self, raw_input: str, **kwargs) -> str:\\n        \"\"\"동기 호출 래퍼. 내부 runnable이 동기라면 바로 호출, 비동기라면 asyncio.run으로 실행합니다.\\n\\n        주의: 이미 이벤트 루프가 돌고 있는 환경(Jupyter 등)에서는 asyncio.run이 실패합니다.\\n        \"\"\"\\n        run_fn = getattr(self.runnable, \"run\", None)\\n        if run_fn is None:\\n            raise AttributeError(\"runnable 객체에 run 메서드가 없습니다.\")\\n\\n        if asyncio.iscoroutinefunction(run_fn):\\n            try:\\n                return asyncio.run(self.run(raw_input, **kwargs))\\n            except RuntimeError:\\n                # 이미 이벤트 루프가 실행 중인 경우\\n                raise RuntimeError(\\n                    \"현재 이벤트 루프가 실행 중입니다. 동기 호출을 지원하지 않습니다. 대신 `await adapter.run(...)`을 사용하세요.\"\\n                )\\n        else:\\n            prompt = self.prompt_template.format(input=raw_input, **kwargs)\\n            return run_fn(prompt)\\n\\n\\n# 예제 사용법\\nasync def main_async_example():\\n    # 1) 실제 LLM 대신 MockLLM 사용 (실제 LLM으로 교체 가능)\\n    llm = MockLLM(name=\"gpt-mock\")\\n\\n    # 2) 어댑터를 만들 때 프롬프트 템플릿을 정의합니다.\\n    template = (\\n        \"You are an assistant.\\\\n\"\\n        \"User input:\\\\n{input}\\\\n\\\\n\"\\n        \"Please provide a short summary and 3 bullet points.\"\\n    )\\n    adapter = StringToRunnableAdapter(llm, prompt_template=template)\\n\\n    # 3) 사용자가 보낸 문자열을 직접 전달\\n    user_string = (\\n        \"LangChain은 LLM을 중심으로 하는 애플리케이션 개발을 단순화하는 프레임워크입니다.\"\\n        \" 에이전트, 체인, 도구 통합 등을 제공합니다.\"\\n    )\\n\\n    output = await adapter.run(user_string)\\n    print(\"--- 비동기 실행 결과 ---\")\\n    print(output)\\n\\n\\ndef main_sync_example():\\n    # 동기 runnable (예시로 동기 run을 가진 간단 객체 사용)\\n    class SyncEcho:\\n        def run(self, prompt: str) -> str:\\n            return f\"[sync-echo] 받은 프롬프트 길이={len(prompt)}\"\\n\\n    sync_runnable = SyncEcho()\\n    adapter = StringToRunnableAdapter(sync_runnable, prompt_template=\"Echoing: {input}\")\\n\\n    result = adapter.run_sync(\"동기 문자열 테스트\")\\n    print(\"--- 동기 실행 결과 ---\")\\n    print(result)\\n\\n\\nif __name__ == \"__main__\":\\n    # 비동기 예제 실행\\n    try:\\n        asyncio.run(main_async_example())\\n    except RuntimeError:\\n        # 이미 이벤트 루프가 실행 중인 환경에서는 예외가 발생할 수 있음.\\n        print(\"메인에서 asyncio.run 실패: 이미 이벤트 루프가 실행 중일 수 있습니다. 대안으로 비동기 컨텍스트에서 main_async_example를 직접 호출하세요.\")\\n\\n    # 동기 예제 실행\\n    try:\\n        main_sync_example()\\n    except RuntimeError as e:\\n        print(\"동기 예제 실행 중 오류:\", e)\\n', description='코드 스키마 설명:\\n- MockLLM: 비동기 run(prompt: str) -> str 메서드를 가진 모의 LLM 클래스입니다.\\n- StringToRunnableAdapter: Any 타입의 runnable(동기/비동기 run 메서드 보유)을 받아, prompt_template에 raw_input을 주입하고 내부 runnable.run을 호출합니다.\\n  - run(raw_input: str, **kwargs): 비동기 호출. 내부 runnable이 비동기이면 await, 아니면 동기 호출을 수행합니다.\\n  - run_sync(raw_input: str, **kwargs): 동기 호출 래퍼. 내부 runnable이 비동기일 경우 asyncio.run을 사용하지만, 이미 이벤트 루프가 실행 중이면 RuntimeError를 발생시킵니다.\\n- main_async_example: MockLLM과 어댑터를 사용한 비동기 실행 예제.\\n- main_sync_example: 동기 runnable 예제.\\n사용법 요약:\\n1) 실제 LLM을 사용할 경우 MockLLM을 해당 LLM 클라이언트로 교체하십시오(비동기 run 메서드 제공).\\n2) 사용자 문자열을 adapter.run(...) (비동기) 또는 adapter.run_sync(...) (동기)로 전달하여 템플릿이 적용된 프롬프트로 실행합니다.'),\n",
       " 'iterations': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '문자열을 runnable 객체에 직접 전달하고, 이를 사용하여 내 프롬프트에 필요한 입력을 구성하려면 어떻게 해야 하나요?'\n",
    "\n",
    "app.invoke({'messages':[('user', question)], 'iterations':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5687a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
