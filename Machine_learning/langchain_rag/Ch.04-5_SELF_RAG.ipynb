{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb64bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List, Dict, Any, Tuple\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_classic.retrievers import ContextualCompressionRetriever\n",
    "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75492466",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('./data/투자설명서.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c52eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model='BAAI/bge-m3', model_kwargs={'device':'cuda'}, encode_kwargs={'batch_size':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067ae1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "full_text = '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "text_splitter = SemanticChunker(embeddings=embeddings)\n",
    "docs = text_splitter.create_documents([full_text])\n",
    "for doc in docs:\n",
    "    doc.metadata['source'] = '투자설명서.pdf'\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a481fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4134e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_store = FAISS.from_documents(docs, embedding=embeddings)\n",
    "persist_dir = './data/faiss_index_dense'\n",
    "faiss_store.save_local(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17adb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x267107a1e50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = FAISS.load_local(persist_dir, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bace0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f01deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_eval = ChatOpenAI(model='gpt-5-nano', temperature=0)\n",
    "llm_gen = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a472fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = HuggingFaceCrossEncoder(model_name='Dongjin-kr/ko-reranker', model_kwargs={'device':'cuda'})\n",
    "reranker = CrossEncoderReranker(model=cross_encoder, top_n=3)\n",
    "base_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7690a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=base_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c530487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    print('---Retrieve---')\n",
    "    \n",
    "    question = state['question']\n",
    "    documents = compression_retriever.invoke(question)\n",
    "\n",
    "    return {'documents':documents, 'question':question, 'retry_count':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0d52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    print('---Check Relevance---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    class Grade(BaseModel):\n",
    "        binary_score: str = Field(description='문서가 질문과 관련이 있으면 \"yes\", 아니면 \"no\"')\n",
    "    \n",
    "    structured_llm_grader = llm_eval.with_structured_output(Grade)\n",
    "\n",
    "    system = '''당신은 제공된 연관 문서가 주어진 질문과 관련이 있는지, 그리고 질문에 답하는 데 유용한 정보를 제공하는지 판단하는 것입니다.\n",
    "    철저하게 검증하여 문서가 질문의 키워드나 의미를 포함하고 있다면 \"yes\"를, 아니라면 \"no\"를 출력하세요.'''\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('system', system), ('human', '질문: {question}\\n\\n문서: {document}')]\n",
    "    )\n",
    "    retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "    filtered_docs = []\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke({'question':question, 'document':doc.page_content})\n",
    "        if score.binary_score == 'yes':\n",
    "            print(f' -- 문서 채택: (관련성 있음)')\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(f' -- 문서 기각: (관련성 없음)')\n",
    "    \n",
    "    return {'documents':filtered_docs, 'question':question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e754964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    print('---Transform Query---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    retry_count = state.get('retry_count', 0) + 1\n",
    "\n",
    "    system = '''당신은 사용자의 질문을 검색에 더 최적화된 형태로 다듬는 전문가입니다.\n",
    "    원래 질문의 의도를 유지하면서, 더 좋은 문서를 찾을 수 있도록 질문을 수정하세요.'''\n",
    "    retry_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('system', system), ('human', '원본 질문: {question}')]\n",
    "    )\n",
    "    question_rewriter = retry_prompt | llm_eval | StrOutputParser()\n",
    "\n",
    "    better_question = question_rewriter.invoke({'question':question})\n",
    "\n",
    "    print(f' -- 수정된 질문: {better_question}')\n",
    "\n",
    "    return {'documents':documents, 'question':better_question, 'retry_count':retry_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04847f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    print('---Generate---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        '''다음 문서들을 바탕으로 질문에 답변하세요.\n",
    "        문서: {context}\n",
    "        질문: {question}\n",
    "        답변:'''\n",
    "    )\n",
    "\n",
    "    context = '\\n\\n'.join(doc.page_content for doc in documents)\n",
    "    rag_chain = prompt | llm_gen | StrOutputParser()\n",
    "\n",
    "    generation = rag_chain.invoke({'context':context, 'question':question})\n",
    "\n",
    "    return {'documents':documents, 'question':question, 'generation':generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b9661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
