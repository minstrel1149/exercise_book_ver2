{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605cb4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from typing import List, TypedDict\n",
    "from pprint import pprint\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, HTMLHeaderTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b536cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model='BAAI/bge-m3', model_kwargs={'device':'cuda'}, encode_kwargs={'batch_size':8})\n",
    "llm_eval = ChatOpenAI(model='gpt-5-nano', temperature=0)\n",
    "llm_gen = ChatOpenAI(model='gpt-5-mini', temperature=0.1)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7726a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://google.github.io/styleguide/pyguide.html\",\n",
    "    \"https://google.github.io/styleguide/javaguide.html\",\n",
    "    \"https://google.github.io/styleguide/jsguide.html\"\n",
    "]\n",
    "\n",
    "headers_to_split_on = [\n",
    "    ('h1', 'Header 1'),\n",
    "    ('h2', 'Header 2'),\n",
    "    ('h3', 'Header 3')\n",
    "]\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = []\n",
    "for url in urls:\n",
    "    splits = html_splitter.split_text_from_url(url)\n",
    "    html_header_splits.extend(splits)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=50)\n",
    "doc_splits = text_splitter.split_documents(html_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481d410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name='rag-chroma-2',\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59fcc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Preview: AUTHORS:\n",
      "Prefer only GitHub-flavored Markdown in e...\n",
      "Metadata: {}\n",
      "--------------------\n",
      "Content Preview: Google Python Style Guide...\n",
      "Metadata: {'Header 1': 'Google Python Style Guide'}\n",
      "--------------------\n",
      "Content Preview: Table of Contents  \n",
      "1 Background  \n",
      "2 Python Langua...\n",
      "Metadata: {'Header 1': 'Google Python Style Guide'}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc_splits[:3]: # 앞부분 3개만 확인\n",
    "    print(f\"Content Preview: {chunk.page_content[:50]}...\")\n",
    "    print(f\"Metadata: {chunk.metadata}\") \n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description='문서와 질문의 연관성 여부. (yes or no)')\n",
    "\n",
    "structured_llm_grader = llm_eval.with_structured_output(GradeDocuments)\n",
    "system = '''\n",
    "당신은 사용자의 질문에 대해 검색된 문서의 관련성을 평가하는 전문가입니다.\n",
    "문서에 질문과 관련된 키워드나 의미가 담겨 있으면, 해당 문서를 \"관련 있음\"으로 평가하세요.\n",
    "문서가 질문과 관련이 있는지 여부를 \"yes\" 또는 \"no\"로 표시해주세요.'''\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system),\n",
    "     ('human', '검색된 문서: \\n\\n {document} \\n\\n사용자 질문: {question}')]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7bc8246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "question = '파이썬 코드 작성 가이드'\n",
    "\n",
    "test = retriever.invoke(question)\n",
    "test_txt = test[0].page_content\n",
    "print(retrieval_grader.invoke({'question':question, 'document':test_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d2ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''\n",
    "당신은 질문에 답변하는 업무를 돕는 도우미입니다.\n",
    "제공된 문맥을 바탕으로 질문에 답변하세요. 만약 답을 모른다면 모른다고 말하세요.\n",
    "세 문장을 넘지 않도록 답변을 간결하게 작성하세요.\n",
    "'''\n",
    "gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system),\n",
    "     ('human', '질문: {question} \\n문맥: {context} \\n답변:')]\n",
    ")\n",
    "\n",
    "rag_chain = gen_prompt | llm_gen | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95f0492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 가이드: pylint로 린트하고(부적절한 경고는 이유를 붙여 좁은 범위로 억제), 기본 라인 길이는 80자(예외: 긴 import/URL 등), 들여쓰기는 4칸, import는 모듈/패키지 전체 경로로(상대 import 금지), 네이밍은 함수/변수 snake_case, 클래스 UpperCamelCase, 상수 ALL_CAPS.  \n",
      "문서화/문자열/로깅: 공개 API엔 3중 따옴표 docstring(요약문 + 필요시 Args/Returns/Raises), 문자열은 f-string/format/% 사용, 로깅은 패턴 문자열 리터널과 인자를 따로 전달(예: logger.info('msg %s', val)).  \n",
      "기타 중요 규칙: 가변 기본값 금지(대신 None 처리), 파일/소켓 등은 with로 명시적 종료, 구체적 예외 사용·범용 except 금지·try/except 범위 최소화, 프로퍼티·데코레이터·고급 기능은 꼭 필요할 때만, 타입 애노테이션(pytype 등) 권장.\n"
     ]
    }
   ],
   "source": [
    "generation = rag_chain.invoke(\n",
    "    {'context':format_docs(doc_splits), 'question':question}\n",
    ")\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dbb3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''\n",
    "당신은 입력된 질문을 변형하여 웹 검색에 최적화된 형태로 만드는 질문 생성기입니다.\n",
    "입력된 질문을 보고 그 이면에 있는 의미나 의도를 파악해주세요.\n",
    "'''\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system),\n",
    "     ('human', '질문: \\n\\n {question} \\n더 나은 질문으로 바꿔주세요. 단 최적의 질문 하나만 골라서 출력해주세요.')]\n",
    ")\n",
    "\n",
    "question_rewriter = rewrite_prompt | llm_gen | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2f10483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C++ 코드를 더 깔끔하고 유지보수하기 쉽게 작성하려면 어떤 모범 사례(스타일 가이드, 모던 C++ 기법, 디자인 원칙)와 도구(예: clang-format, clang-tidy), 리팩토링 기법을 사용해야 하나요?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'C++ 깔끔하게 짜고 싶다.'\n",
    "question_rewriter.invoke({'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d2ef349",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearch(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e88ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
