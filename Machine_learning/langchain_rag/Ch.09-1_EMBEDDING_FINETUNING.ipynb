{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153feb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer, losses, InputExample, SentenceTransformerTrainingArguments, SentenceTransformerTrainer\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.finetuning import generate_qa_embedding_pairs, EmbeddingQAFinetuneDataset\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a48bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 76\n",
      "42 38\n"
     ]
    }
   ],
   "source": [
    "usa_documents = SimpleDirectoryReader(input_files=['data/ict_usa_2024.pdf']).load_data()\n",
    "japan_documents = SimpleDirectoryReader(input_files=['data/ict_japan_2024.pdf']).load_data()\n",
    "node_parser = SentenceSplitter(chunk_size=512)\n",
    "nodes_train = node_parser.get_nodes_from_documents(usa_documents)\n",
    "nodes_valid = node_parser.get_nodes_from_documents(japan_documents)\n",
    "print(len(nodes_train), len(nodes_valid))\n",
    "\n",
    "sample_weight = 0.5\n",
    "if len(nodes_train) > 50:\n",
    "    selected_nodes_train = random.sample(nodes_train, int(len(nodes_train) * sample_weight))\n",
    "else:\n",
    "    selected_nodes_train = nodes_train\n",
    "\n",
    "if len(nodes_valid) > 50:\n",
    "    selected_nodes_valid = random.sample(nodes_valid, int(len(nodes_valid) * sample_weight))\n",
    "else:\n",
    "    selected_nodes_valid = nodes_valid\n",
    "print(len(selected_nodes_train), len(selected_nodes_valid))\n",
    "\n",
    "llm = OpenAI(model=\"gpt-5-nano\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85254e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 저장된 데이터셋이 있습니다. 'data/usa_train_dataset.json'를 로드합니다...\n",
      "데이터 준비 완료: 쿼리 84개\n",
      "{'b3c2606c-0943-41ee-b08a-d79feebfb14d': 'What is the numeric value provided in the context information?', '51429fb0-516a-4a7d-a035-6984f7d236b2': 'Describe the formatting of the context block around the numeric value, including any separators used.', '38a5a9f9-3307-4ce4-8122-6a3294fcf867': '객관식: 다음 중 본 문서에서 무선 허가자들에게 인센티브를 제공하는 주된 목적은 무엇인가?', 'dae4fd20-ae84-41eb-bbfe-164c215208bf': 'A) 도시 지역의 서비스 확대', '9ff4a22d-763e-4d85-8239-594e55e05f27': '문서에 제시된 두 가지 주요 목표를 각각 간단히 설명하시오. (예: AI가 생성한 콘텐츠를 탐지하고 공식 콘텐츠를 인증하기 위한 표준과 모범사례 확립; 중요 소프트웨어의 취약점을 찾아 수정할 수 있는 AI 툴 개발을 위한 프로그램 수립.)', 'ab4a35c3-b515-4896-91f8-3415bfa7fa7a': '다음 중 미국 연방 차원의 개인정보보호 정책에서 우선시되는 조치로 올바른 것을 고르시오.', 'eaf8eb0e-9291-4cb2-9f9d-07deba2e8af5': '- Q1 (다지선다형): 아래 중 문서의 목표에 포함되지 않는 것은 무엇인가?', 'f75dd53a-296b-4aeb-bea5-22c354b8dae8': 'A) AI 관련 의료 분야 위험 보고 체계 수립과 AI 지원 교육 도구 배포 지원', 'da98e0d4-d0c2-49e2-9aea-d8b41044dbc0': '객관식(다지선다형): 다음 중 이 자금의 보조금을 배분할 계획을 발표한 미국 부처는 어디인가?', 'eb9354e3-9ba5-4e58-b485-0da5ff03f7cb': 'A) 에너지부', '7823496a-eca4-4a2f-9790-02803c5b0e3e': '본문에 따르면 디지털 트윈 기술은 전투 수행에서 어떤 변혁적 잠재력을 인정받고 있으며, 이를 통해 공급망 관리 및 전장 능력 향상에 어떤 영향을 미칠 수 있는지 두 가지 측면으로 설명하시오.', '5b6847b5-fc21-4871-8b9f-99059a5bd716': '다음 중 본문에 명시된 내용을 정확히 반영하는 선택지를 고르시오.', '3934c613-791b-4cab-869d-fafba77fa4c3': '- Q1(객관식): 다음 중 이 원고의 발행기관과 발행일을 올바르게 매칭한 것은 무엇인가?', '943ce69e-dfb1-4089-bc1f-9be61a38174b': 'A) 발행기관: 정보통신산업진흥원, 발행일: 2024.03.08', '61b593cb-5a82-44c0-a896-092cce4a0cc1': '질문 1', 'be428685-4eea-4903-ab1a-4efc5c02c826': '다음 문단에 명시된 국가 사이버보안을 강화하기 위한 핵심 전략 요소를 모두 나열하고, 각 요소가 서로 어떻게 보완하는지 간략히 설명하시오.', 'c8991089-7218-4825-a107-9f46425f35c2': '문서에 명시된 협력 주체인 산업계, 국제 파트너, 및 기타 비 연방기관과의 협력이 촉진하려는 바는 무엇인가?', '504c2007-3382-4934-bbf9-1149fe4919d3': 'AI 연구 분야의 국제 협력에 대한 원칙적이고 조율된 접근 방식의 필요성을 설명하고, 환경적 지속가능성, 의료, 제조 등 글로벌 과제를 해결하기 위해 국제 협력을 우선시하는 이유를 논하시오. 또한 국제 가이드라인 및 표준의 개발과 이행을 어떻게 지원해야 하는지 구체적으로 서술하시오.', 'af36cebb-0fe4-4935-aa8f-c3d7a7b76632': '다지선다형', 'ae82e4ab-b3e7-412f-87e9-6c38bab01ba7': 'MOVEit 파일 공유 소프트웨어의 취약점을 이용한 해킹에 대해 미국 연방기관이 받는 영향 파악과 시의적절한 조치를 지원하는 주체는 누구인가?', 'af66c07c-fd53-4704-a075-9e61aeb5ad12': '질문 1', '4ab9ddc1-1f04-4fb4-8aa4-aab80fc6ed0c': '다음 문단에서 AWS와의 협력을 통해 달성한 목표와 그로 인한 효과를 서술하시오. 특히 궤도 내 데이터 처리 및 분석의 실현, 가장 유용한 이미지만 다운링크하는 방식의 의미, 데이터 전송 대역폭의 절감 및 위성 운영의 효율성 향상, 지구 도달 전 불필요한 데이터의 필터링이 가져오는 시사점을 중심으로 설명하시오.', '0ba1c99f-2b1c-427a-8317-e258aee9fba6': '다음 중 본문에서 제시된 AI 프라이버시 및 시민권 지침의 목표에 해당하지 않는 것은 무엇입니까?', '9740bcc2-b0cc-46ae-bdaa-a663aec63481': 'A) 연방급여 프로그램 및 연방 계약자에 대해 AI가 처벌을 유도하지 않도록 명확한 지침을 제공', '1ef27f55-708d-417d-a4d3-33b43a0d57cc': '다음 중 Walmart의 DFW 지역 드론 배송 서비스에 대한 설명으로 옳은 것은 무엇입니까?', '304cc47d-15ea-4924-8842-464140f3fd93': 'A) DFW 인구의 60%를 대상으로 하며 약 15,000,000가구를 서비스한다.', 'd5c4fc6f-b08e-4d25-b3f1-4f0809e9b566': '질문 1. 2022–2023년 반도체 분야의 정규직 채용에 지원한 학생 수가 증가한 비율은 얼마입니까?', '222cf99c-408f-44db-9039-0215cf354c23': '질문 2. 11억 달러 규모의 R&D 자금이 투자하는 세 가지 구체 프로그램을 모두 나열하시오: (1) 계측 프로그램 (2) 국립 고급 포장 제조 프로그램 (3) 최대 3개의 신규 Manufacturing USA 연구소.', '6996bede-e241-4c9e-a248-96e60ae138eb': '- Translate the term \"미국\" into English as used in the document.', '68e6e800-d7c9-4d1e-b1c4-c348b0c17154': \"- The document's context centers on which country?\", '8aa2f8f0-9aed-4be3-b3b8-841f53465d6d': '백악관의 AI 안전 서약에 명시된 3가지 원칙의 이름을 나열하고, 각 원칙에 대해 텍스트에 제시된 하나의 세부 조항을 간략히 설명하시오.', '2a6ec816-9382-426f-b899-8167699d985a': '위 서약에서 제시된 각 원칙의 목표가 서로 어떻게 보완되는지 분석하고, 기업이 실제로 취해야 할 구체적 조치 두 가지 이상을 사례와 함께 서술하시오.', '625a9768-82f0-45ae-8d2a-16a0d7c89dd9': 'Q1. 다음 파트너십을 식별하고, 각 파트너십의 핵심 목표를 간단히 서술하시오.', '31a37ef4-4fa2-4cbb-8bde-8d9b4f52986d': '- Google-Starlink: 구글 데이터 센터 내 지상 스테이션 설치를 통해 무엇을 실현하려 하는가?', 'dc89c197-0e6f-4aff-88a4-9dbd7b1dbb7f': '- Question 1: How many digits are in the decimal representation of the number 17?', '2c87ae69-72e9-4b3e-9dea-abbf6b30a0bd': '- Question 2: Is the number 17 odd or even? Provide a brief justification.', '888a71b0-79b7-4179-b29f-9569493e592f': '미국의 2023년 3월 발표된 국가 사이버 보안 전략의 5대 핵심 목표 중, 아래 보기에서 포함되지 않는 항목을 고르시오.', 'b86a38b5-f35a-41eb-a318-04ca660ff320': '- A) 핵심 기반 시설 방어', '79a2b5ce-0d23-4ff5-a36f-feabae961e14': 'AI 안전 서약의 발표 배경과 목적을 간단히 설명하고, 제시된 3가지 원칙이 무엇인지 서술하시오.', '872fdd77-1dde-401f-afc5-1ddae0129aae': '다음 중 AI 안전 서약에 동의한 주요 기업에 속하지 않는 회사를 고르시오.', 'a3620ae1-833e-4e70-bf25-78b9ab1750e4': 'Question 1:', 'f0c04dc6-d67b-4854-aba1-20e7abb0b5bd': 'From the 참고 사이트 section, list three items that are US federal government domains (provide the domain names).', '5768d6b8-d7df-4aea-a07d-a8d032751d34': 'Multiple Choice: Which real-time updates does the ERAdvisor app provide during pediatric emergency visits?', 'a198bb63-2b2e-4e97-80cc-5a2cdfb4e2fa': 'A) Wait times', '80caed2e-d888-498d-b048-6ebcdea14e8b': '다지선다형: 히로시마 회담에서 미국-일본 양국 정상은 주로 어떤 분야의 협력 강화를 강조했는가?', 'a41a2f3a-cf4b-4509-bc10-355e17b5d926': 'A. 양자컴퓨팅, 반도체, 인공지능', '8851aef7-577b-45a6-9caf-68af79034efc': 'Q1. 본문에 나타난 기업의 약속을 4가지로 요약하고, 각 약속이 AI의 사회적 위험 감소와 개인정보 보호에 어떻게 기여하는지 간단히 설명하시오.', '16e4da18-a1ef-4c9d-b63e-a43e87caeeb3': 'Q2. 아래 보기 중 문서의 출처로 명시된 기관은 어느 곳인가? A) 미국 백악관 B) 국제 연합 C) 세계은행 D) 유럽연합', '0560d030-b474-4217-a6e2-570f981a3ba1': 'Q1. 본문에 제시된 부문 이름을 모두 나열하시오.', 'd7ef023b-d17d-40c9-ad69-f8659cecc21e': 'Q2. 데이터의 출처로 명시된 국제기구를 모두 열거하시오.', '640935c5-8846-475b-af92-569883e00447': '질문 1', '5472d595-0a35-4717-9cfc-31c187ffec01': '2023년 글로벌 혁신지수 총점에서 어느 나라가 더 높은 점수를 기록하였나요? 선택지 중에서 정답을 고르시오.', 'afd04fbf-2661-468a-86dc-a9157f22f956': '항목 ④에 따라: AI 시스템의 안전과 보안 확보를 위한 신뢰할 수 있고 안전한 AI 시스템 설계 원칙과 위험 관리 전략을 제시하고, 이를 실제 시스템에 적용할 때의 주요 요소와 도전 과제를 서술하시오.', 'c6185dd3-2168-440f-954d-4410e2ecfca2': '항목 ⑤에 따라: AI 학습 및 테스트를 위한 공유 공개 데이터와 제반 환경 구축의 구성 요소를 제시하고, 데이터 품질 관리와 접근성 확대, 테스트/교육 자원의 확보를 달성하기 위한 실행 계획과 기대 효과, 그리고 잠재적 문제점을 분석하시오.', '41ef2030-7cc9-49d2-9e5f-bc6a3eb00f5c': 'Short answer: What specific FAA regulatory change is described, and what exemption does it grant to companies like Wing for drone operations?', '4f4bad74-5e8f-4fbd-888e-89bb57124138': 'Essay/Discussion: Based on the provided context, discuss how FAA regulatory relaxation and advances in drone delivery technology may enable widespread drone deliveries across the United States. Include examples from the text, such as pilot operations in multiple cities and competition with Zipline, and explain the potential environmental and efficiency benefits.', '60100f3e-670f-48df-b6d4-3826aa939b8f': 'Question 1 (Short answer):', 'ddbd8d90-8b2f-47fc-b664-55791a86b4b8': '다음 발췌에 따라, 국가 AI R&D 전략 계획의 전략 ①과 전략 ②의 핵심 내용과 목표를 각각 서술하시오. 특히 전략 ①은 어떤 중점과 기대 효과를 말하고, 전략 ②는 인간-AI 협업의 발전을 위한 구체적 방향성에 대해 무엇을 제시하는가?', '5d8cbf07-938b-4a36-a17d-1e8a0069ab80': '서술형 질문: 양자 AI 거버넌스 워킹그룹의 설립 목적과 NSF- AISG의 공동 연구 및 교육 자금 지원의 핵심 내용을 요약하고, 이 두 이니셔티브가 제시하는 “안전하고 책임 있는 AI 공유 원칙” 및 상호 기술 발전과 안전에 대한 헌신이 연구 및 교육 자금 지원에 어떤 함의를 갖는지 논하시오.', '07577b1e-df15-4509-84d3-47bbd3da0984': '객관식 질문: 제9차 EU-미국 사이버 대화에서 강화된 협력의 핵심 포인트로 옳은 것은 무엇인가?', 'ff01a229-b58c-41a1-a881-adcb62ed3245': '- Question 1 (서술형): 이 파트너십의 핵심 목표와 위성에서 AI 모델을 원클릭으로 배포하는 방식이 지상 시스템 의존도 및 통신 인프라 비용에 미치는 기대 효과를 설명하시오.', '930130f3-0040-4cc9-b559-8809f2d22308': '- Question 2 (객관식): IBM이 American Tower와의 협력을 통해 달성하려는 주요 목적은 무엇인가?', '69ddf7bb-f997-4848-9a7f-e6b664f78df0': '다음 표에 나타난 미국 주요 ICT 기업 중 시가총액이 가장 큰 회사는 어느 것인가?', '1743f680-e71b-4ce3-b123-482370e1f937': 'A. Microsoft  B. Apple  C. NVIDIA  D. Alphabet', 'a4e977fa-70b1-40a9-821e-17ee62a3c88d': 'Pillar 1에 관한 단답형 질문', 'd7433a88-1bc8-47a0-b35e-af40081c75cc': '국가 스펙트럼 전략의 Pillar 1과 그 하위 목표 1.1, 1.2, 1.3의 내용은 무엇이며, 각 하위 목표가 미국의 첨단 및 신흥 기술 분야에서 리더십 확보에 어떻게 기여하는지 간략히 설명하시오.', '1e0ae716-0056-4a43-a773-5be84aaf41f8': \"- Question 1 (Multiple choice): In the document's table of contents, which section number corresponds to ICT 주요 법령 및 규제?\", '4077694f-07cc-4614-8e18-849264fc9a9a': 'A) 1', '732470f1-e43e-497d-b3b5-0af1ebce6916': '객관식: 다음 산업 중 AI 챗봇의 더 정확하고 효율적인 솔루션으로 혜택을 받을 것으로 언급된 산업은 어느 것들인가?', '8368dd01-f73a-47c5-9ba1-f309cd3fea1d': '- a) 고객 서비스', 'fe7bd2f7-f705-425c-8213-da97bcaba817': '객관식', '13768bd7-972a-4b28-bcac-573fd3ee0d43': '다음 중 본문에 따라 디지털 트윈이 군사 작전을 계획하고 실행하는 데 기대되는 역할은 무엇인가?', '7c9faa9d-9c94-43f1-bfe9-67d8a302764b': 'Question 1 (Multiple Choice):', '863904bf-4b3b-4ee4-a5eb-9ed981331424': \"Which of the following is described as part of the Department of Commerce's plan to create a job and talent pipeline for the semiconductor industry?\", '945312a0-128f-45ce-9d95-1fd94c2fba42': '다음 두 문제를 제출하십시오.', '45d40276-9d8e-4e28-84b3-4e9f5bc55ed9': 'NTIA의 정식 명칭과 소속 기관은 무엇이며, 이 기관의 주요 역할은 무엇인가? 특히 대통령에게 자문을 제공하는 책임에 대해 서술하시오.', '56407032-e0dd-4255-8427-8d35fbdb469d': '다지선다형: 미국의 통합 글로벌 6G 표준 개발에 적극적으로 노력하는 조직은 무엇인가?', '05f254df-3de3-41bd-8756-0af0d86cfb40': '- A) IEEE', 'b87644ce-8ab8-4843-88db-f2ee89729359': 'Zipline은 어떤 지역에서 이미 성공적인 배송을 수행해 왔으며, 미국 내 확장을 어떤 방향으로 계획하고 있는가? (간단히 서술)', '36d941fb-3f63-467c-8613-9694a843a6fe': 'Wing의 자동화된 드론 배송 네트워크는 드론을 어떻게 배치하는지 설명하고, 미국 내 확장의 주요 목표인 배송 시간 단축과 환경 영향 감소를 포함하여 요약하시오.', '4261d372-a7b2-4eb8-8b03-eb080b63a27c': 'Approximately how much is the initial NSTC investment, and what core role is NSTC expected to play in the nation’s semiconductor R&D efforts?', '460a861d-bf27-484d-97f7-aeeebc6b0a32': 'Name the two CHIPS Act R&D programs mentioned and explain how they are designed to address core aspects of semiconductor manufacturing—from advanced packaging to digital twin technology—and why this supports a broader strategy for maintaining U.S. leadership in the industry.', '8a658469-f774-4c9f-adff-6bef5d7e211d': '문제 1 (서술형)', 'f61af39c-17ab-455a-afa8-60cd4ce8be85': \"문서의 3장에 해당하는 '기술 개발을 통한 전례 없는 스펙트럼 혁신, 접근 및 관리' 부분의 세부 항목 3.1, 3.2, 3.3를 각각 간략히 요약하고, 이 세 가지가 스펙트럼 정책의 공통 목표인 혁신적 활용 확대, 총체적 이해 증진, 접근성 확대에 어떻게 기여하는지 설명하시오.\"}\n",
      "{'b3c2606c-0943-41ee-b08a-d79feebfb14d': ['69db4a2f-46a3-4db6-9a36-fc2f506a41ce'], '51429fb0-516a-4a7d-a035-6984f7d236b2': ['69db4a2f-46a3-4db6-9a36-fc2f506a41ce'], '38a5a9f9-3307-4ce4-8122-6a3294fcf867': ['553dcf19-20a0-4f5a-ae65-b5a67f7dfbc1'], 'dae4fd20-ae84-41eb-bbfe-164c215208bf': ['553dcf19-20a0-4f5a-ae65-b5a67f7dfbc1'], '9ff4a22d-763e-4d85-8239-594e55e05f27': ['e46dbc1b-fbeb-48bd-9d7d-491cad4d6402'], 'ab4a35c3-b515-4896-91f8-3415bfa7fa7a': ['e46dbc1b-fbeb-48bd-9d7d-491cad4d6402'], 'eaf8eb0e-9291-4cb2-9f9d-07deba2e8af5': ['987a5ce8-467f-4096-97b6-d50d0beed5b9'], 'f75dd53a-296b-4aeb-bea5-22c354b8dae8': ['987a5ce8-467f-4096-97b6-d50d0beed5b9'], 'da98e0d4-d0c2-49e2-9aea-d8b41044dbc0': ['3a53f459-81b5-419f-90de-169710644f19'], 'eb9354e3-9ba5-4e58-b485-0da5ff03f7cb': ['3a53f459-81b5-419f-90de-169710644f19'], '7823496a-eca4-4a2f-9790-02803c5b0e3e': ['f1e31416-85f0-498c-a531-948bba709eda'], '5b6847b5-fc21-4871-8b9f-99059a5bd716': ['f1e31416-85f0-498c-a531-948bba709eda'], '3934c613-791b-4cab-869d-fafba77fa4c3': ['b3c95e12-70c8-4038-a738-9575670c520e'], '943ce69e-dfb1-4089-bc1f-9be61a38174b': ['b3c95e12-70c8-4038-a738-9575670c520e'], '61b593cb-5a82-44c0-a896-092cce4a0cc1': ['6994870b-693b-47f5-aaf4-99a0ee0fceb8'], 'be428685-4eea-4903-ab1a-4efc5c02c826': ['6994870b-693b-47f5-aaf4-99a0ee0fceb8'], 'c8991089-7218-4825-a107-9f46425f35c2': ['e3cbe666-93f6-4d79-9fe9-36a30ab6c2df'], '504c2007-3382-4934-bbf9-1149fe4919d3': ['e3cbe666-93f6-4d79-9fe9-36a30ab6c2df'], 'af36cebb-0fe4-4935-aa8f-c3d7a7b76632': ['ecbdc197-27df-41f0-b8be-a8fdf2767cf4'], 'ae82e4ab-b3e7-412f-87e9-6c38bab01ba7': ['ecbdc197-27df-41f0-b8be-a8fdf2767cf4'], 'af66c07c-fd53-4704-a075-9e61aeb5ad12': ['ac13f339-e077-4835-8eed-f363a7078293'], '4ab9ddc1-1f04-4fb4-8aa4-aab80fc6ed0c': ['ac13f339-e077-4835-8eed-f363a7078293'], '0ba1c99f-2b1c-427a-8317-e258aee9fba6': ['35e24ac0-4869-4a51-a060-75cc08ca3bd6'], '9740bcc2-b0cc-46ae-bdaa-a663aec63481': ['35e24ac0-4869-4a51-a060-75cc08ca3bd6'], '1ef27f55-708d-417d-a4d3-33b43a0d57cc': ['798ad9fd-61ec-4efb-a048-bc3c185968b6'], '304cc47d-15ea-4924-8842-464140f3fd93': ['798ad9fd-61ec-4efb-a048-bc3c185968b6'], 'd5c4fc6f-b08e-4d25-b3f1-4f0809e9b566': ['1101237d-9eab-45c0-a655-ba619a882322'], '222cf99c-408f-44db-9039-0215cf354c23': ['1101237d-9eab-45c0-a655-ba619a882322'], '6996bede-e241-4c9e-a248-96e60ae138eb': ['99e80918-fac0-4a22-bb42-b9d87d8505b0'], '68e6e800-d7c9-4d1e-b1c4-c348b0c17154': ['99e80918-fac0-4a22-bb42-b9d87d8505b0'], '8aa2f8f0-9aed-4be3-b3b8-841f53465d6d': ['1e29e1e5-089e-4703-a6ac-95e6a2584435'], '2a6ec816-9382-426f-b899-8167699d985a': ['1e29e1e5-089e-4703-a6ac-95e6a2584435'], '625a9768-82f0-45ae-8d2a-16a0d7c89dd9': ['67a9e33e-5f42-4bf6-86f5-a5509dcf9033'], '31a37ef4-4fa2-4cbb-8bde-8d9b4f52986d': ['67a9e33e-5f42-4bf6-86f5-a5509dcf9033'], 'dc89c197-0e6f-4aff-88a4-9dbd7b1dbb7f': ['19ef3369-ef4e-413f-b0a3-f1ddec2a8b6e'], '2c87ae69-72e9-4b3e-9dea-abbf6b30a0bd': ['19ef3369-ef4e-413f-b0a3-f1ddec2a8b6e'], '888a71b0-79b7-4179-b29f-9569493e592f': ['67a11feb-e62c-4821-8fbc-c97cc7df6e4a'], 'b86a38b5-f35a-41eb-a318-04ca660ff320': ['67a11feb-e62c-4821-8fbc-c97cc7df6e4a'], '79a2b5ce-0d23-4ff5-a36f-feabae961e14': ['80b5de65-d555-4194-90d8-18f499516714'], '872fdd77-1dde-401f-afc5-1ddae0129aae': ['80b5de65-d555-4194-90d8-18f499516714'], 'a3620ae1-833e-4e70-bf25-78b9ab1750e4': ['a21fff63-441e-4cb3-8295-119d0308d2a4'], 'f0c04dc6-d67b-4854-aba1-20e7abb0b5bd': ['a21fff63-441e-4cb3-8295-119d0308d2a4'], '5768d6b8-d7df-4aea-a07d-a8d032751d34': ['df5bc443-f027-4ea5-8ab2-6aa26ab5f469'], 'a198bb63-2b2e-4e97-80cc-5a2cdfb4e2fa': ['df5bc443-f027-4ea5-8ab2-6aa26ab5f469'], '80caed2e-d888-498d-b048-6ebcdea14e8b': ['0157601f-ca05-439b-9bc6-83869ba59d26'], 'a41a2f3a-cf4b-4509-bc10-355e17b5d926': ['0157601f-ca05-439b-9bc6-83869ba59d26'], '8851aef7-577b-45a6-9caf-68af79034efc': ['3f68bb77-8421-4cc2-bfb1-fe5a2d5d96dd'], '16e4da18-a1ef-4c9d-b63e-a43e87caeeb3': ['3f68bb77-8421-4cc2-bfb1-fe5a2d5d96dd'], '0560d030-b474-4217-a6e2-570f981a3ba1': ['869f4f6b-e0a1-40c8-bdef-d8fca1f283f9'], 'd7ef023b-d17d-40c9-ad69-f8659cecc21e': ['869f4f6b-e0a1-40c8-bdef-d8fca1f283f9'], '640935c5-8846-475b-af92-569883e00447': ['358c6d47-5743-4799-834b-c6b4b65643c7'], '5472d595-0a35-4717-9cfc-31c187ffec01': ['358c6d47-5743-4799-834b-c6b4b65643c7'], 'afd04fbf-2661-468a-86dc-a9157f22f956': ['8b180cec-b912-44c5-8348-836b38e56ee8'], 'c6185dd3-2168-440f-954d-4410e2ecfca2': ['8b180cec-b912-44c5-8348-836b38e56ee8'], '41ef2030-7cc9-49d2-9e5f-bc6a3eb00f5c': ['5ef01885-7b58-4752-bd00-5f13f6dd95c4'], '4f4bad74-5e8f-4fbd-888e-89bb57124138': ['5ef01885-7b58-4752-bd00-5f13f6dd95c4'], '60100f3e-670f-48df-b6d4-3826aa939b8f': ['7fdb00aa-4150-4a60-9104-3a6955215b2c'], 'ddbd8d90-8b2f-47fc-b664-55791a86b4b8': ['7fdb00aa-4150-4a60-9104-3a6955215b2c'], '5d8cbf07-938b-4a36-a17d-1e8a0069ab80': ['2068b7d4-9960-4fdd-839c-8b819ee3f008'], '07577b1e-df15-4509-84d3-47bbd3da0984': ['2068b7d4-9960-4fdd-839c-8b819ee3f008'], 'ff01a229-b58c-41a1-a881-adcb62ed3245': ['b26d8e44-ebe7-4877-b02e-62fb71caa5c3'], '930130f3-0040-4cc9-b559-8809f2d22308': ['b26d8e44-ebe7-4877-b02e-62fb71caa5c3'], '69ddf7bb-f997-4848-9a7f-e6b664f78df0': ['27d448f7-b1fd-4aff-8c4d-10ecd13d76c8'], '1743f680-e71b-4ce3-b123-482370e1f937': ['27d448f7-b1fd-4aff-8c4d-10ecd13d76c8'], 'a4e977fa-70b1-40a9-821e-17ee62a3c88d': ['a34a0907-4d89-4f7f-a48a-99541d908ab9'], 'd7433a88-1bc8-47a0-b35e-af40081c75cc': ['a34a0907-4d89-4f7f-a48a-99541d908ab9'], '1e0ae716-0056-4a43-a773-5be84aaf41f8': ['76ec358d-ea7d-4809-8f41-e9b7af405d55'], '4077694f-07cc-4614-8e18-849264fc9a9a': ['76ec358d-ea7d-4809-8f41-e9b7af405d55'], '732470f1-e43e-497d-b3b5-0af1ebce6916': ['979d1acd-6fb1-4cf7-818c-ac37e53491ac'], '8368dd01-f73a-47c5-9ba1-f309cd3fea1d': ['979d1acd-6fb1-4cf7-818c-ac37e53491ac'], 'fe7bd2f7-f705-425c-8213-da97bcaba817': ['e613a3cc-e9db-4dc2-b550-106085052a4f'], '13768bd7-972a-4b28-bcac-573fd3ee0d43': ['e613a3cc-e9db-4dc2-b550-106085052a4f'], '7c9faa9d-9c94-43f1-bfe9-67d8a302764b': ['507f88d8-89f1-4b21-ad4c-629909adbb56'], '863904bf-4b3b-4ee4-a5eb-9ed981331424': ['507f88d8-89f1-4b21-ad4c-629909adbb56'], '945312a0-128f-45ce-9d95-1fd94c2fba42': ['66971a38-fce0-44f2-90b7-b7aef6db4f30'], '45d40276-9d8e-4e28-84b3-4e9f5bc55ed9': ['66971a38-fce0-44f2-90b7-b7aef6db4f30'], '56407032-e0dd-4255-8427-8d35fbdb469d': ['2cea9d57-42c0-4ab4-9355-a70ddc5b91b6'], '05f254df-3de3-41bd-8756-0af0d86cfb40': ['2cea9d57-42c0-4ab4-9355-a70ddc5b91b6'], 'b87644ce-8ab8-4843-88db-f2ee89729359': ['d998a04d-c777-43fa-9562-561130a9a3cb'], '36d941fb-3f63-467c-8613-9694a843a6fe': ['d998a04d-c777-43fa-9562-561130a9a3cb'], '4261d372-a7b2-4eb8-8b03-eb080b63a27c': ['b94e3a73-e60d-4460-af7c-a639af6f349e'], '460a861d-bf27-484d-97f7-aeeebc6b0a32': ['b94e3a73-e60d-4460-af7c-a639af6f349e'], '8a658469-f774-4c9f-adff-6bef5d7e211d': ['e731ecb4-ae82-4c83-a30f-9655a26867c8'], 'f61af39c-17ab-455a-afa8-60cd4ce8be85': ['e731ecb4-ae82-4c83-a30f-9655a26867c8']}\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH_TRAIN = \"data/usa_train_dataset.json\"\n",
    "\n",
    "if os.path.exists(DATASET_PATH_TRAIN):\n",
    "    print(f\"이미 저장된 데이터셋이 있습니다. '{DATASET_PATH_TRAIN}'를 로드합니다...\")\n",
    "    train_dataset = EmbeddingQAFinetuneDataset.from_json(DATASET_PATH_TRAIN)\n",
    "    \n",
    "else:\n",
    "    print(\"저장된 데이터셋이 없습니다. 생성을 시작합니다... (시간 소요됨)\")\n",
    "    \n",
    "    train_dataset = generate_qa_embedding_pairs(\n",
    "        nodes=selected_nodes_train,\n",
    "        llm=llm,\n",
    "        num_questions_per_chunk=2,\n",
    "        output_path=DATASET_PATH_TRAIN\n",
    "    )\n",
    "    print(\"생성 및 저장 완료!\")\n",
    "\n",
    "print(f\"데이터 준비 완료: 쿼리 {len(train_dataset.queries)}개\")\n",
    "\n",
    "print(train_dataset.queries)\n",
    "print(train_dataset.relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0956a352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85db292e6154f94a834b1e92676f139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'BAAI/bge-m3'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def model_tokenizer(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "corpus_ids = list(train_dataset.corpus.keys())\n",
    "corpus_texts = list(train_dataset.corpus.values())\n",
    "\n",
    "tokenized_corpus = [model_tokenizer(doc) for doc in tqdm(corpus_texts, desc='Tokenizing')]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f872e0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a166106e691d4926a5a7326f3b64003f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mining:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_examples = []\n",
    "mining_success_count = 0\n",
    "\n",
    "for query_id, query_text in tqdm(train_dataset.queries.items(), desc='Mining'):\n",
    "    pos_doc_ids = train_dataset.relevant_docs[query_id]\n",
    "    pos_doc_texts = [train_dataset.corpus[p_id] for p_id in pos_doc_ids]\n",
    "\n",
    "    query_tokens = model_tokenizer(query_text)\n",
    "\n",
    "    top_n_texts = bm25.get_top_n(query_tokens, corpus_texts, n=15)\n",
    "\n",
    "    hard_neg_text = None\n",
    "    for candidate_text in top_n_texts:\n",
    "        if candidate_text not in pos_doc_texts:\n",
    "            hard_neg_text = candidate_text\n",
    "            break\n",
    "    \n",
    "    for pos_text in pos_doc_texts:\n",
    "        if hard_neg_text:\n",
    "            train_examples.append({'anchor':query_text, 'positive':pos_text, 'negative':hard_neg_text})\n",
    "            mining_success_count += 1\n",
    "        else:\n",
    "            train_examples.append({'anchor':query_text, 'positive':pos_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817619ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_hf = Dataset.from_list(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a04a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 저장된 데이터셋이 있습니다. 'data/japan_valid_dataset.json'를 로드합니다...\n",
      "데이터 준비 완료: 쿼리 76개\n",
      "{'2d5608a7-bd91-471b-b446-93bf7f270c21': 'Identify the three nations cited as sources of cyber threats in the document. Then describe the two real-world incidents referenced (SolarWinds hack and Colonial Pipeline ransomware) and summarize their impacts on data security and critical infrastructure.', '2fc72960-f28f-4907-8c56-b1395b91fc05': 'Explain the policy development announced by Japan in June 2023 requiring government contractors to comply with U.S. cybersecurity guidelines. Include who is affected (e.g., think tanks, telecoms, and the 1,000+ firms) and what changes are being made by the Government Cybersecurity Strategy Office and central ministries to strengthen information security for external partners.', 'fdc1aa68-9cab-46e3-83f0-71c5541c1b4e': '아래의 참고 자료 중 AI 정책 및 데이터 보호에 관련된 일본 정부 기관 두 곳과 각 기관의 참고 자료 제목을 매칭하시오.', 'c92dc7dc-2139-4f71-8399-e3d3aa4a449d': '- 個人情報保護委員会 — 「生成AIサービスの利⽤に関する注意喚起等」', '7bf2ae23-ed1e-4a10-8311-a1cfaf167901': '2023년 ‘반도체·디지털 산업전략’이 개정된 주된 동인과, 저출산·고령화 사회에서 디지털 기반 구축을 통해 달성하고자 하는 핵심 사회적 목표(DX와 GX 포함)를 설명하시오.', '302c005e-878c-4279-ae31-5661a0575a84': '개정 전략은 두 가지 정책 분류로 나뉜다고 한다. 이 두 분류의 정확한 명칭을 제시하시오.', 'bea88339-95cc-460b-91d8-c6f22402673c': '질문 1', 'b81e5743-5761-485f-80dc-c41f757892d8': '다음 두 인물의 이름과 직책을 문서에 기재된 바대로 적으시오.', '7322c0bc-ae2a-4edd-b773-f30c2d9004aa': '- Question 1 (Multiple choice): According to the provided data, which country has the higher GDP in 2023?', '72f13d4d-1d25-4489-8bb0-d3bce78c9d18': 'A) Korea', '936c5323-e318-4fcd-8db8-a4b8e29d3630': '다지선다형', 'c19c7357-22a5-44e7-a2d6-e180c25de34f': '다음 중 정책상 선정된 5대 전략 분야에 속하지 않는 것은 무엇인가?', '2ec99997-0d40-47fd-910c-5ce242110313': '다지선다형', '37fd4c14-a5fd-485f-8d52-a78bef4b393e': '다음 중 문서에서 한국-일본 ICT 기업 협력 사례로 제시된 분야가 아닌 것은 무엇인가?', '8c395200-dfdd-4106-bd91-9c3f141924d7': '도도부현에 조성된 기금의 규모와 주요 용도에 대해 간단히 서술하시오.', '70f1cfd0-e407-4f8f-99b7-1e7b10df5dd3': '(힌트: 규모는 2,643억 엔이고, 5년에 걸쳐 단말기 갱신 및 예비 기기와 입출력 지원 장치를 정비하는 용도이다.)', 'fa89b5d9-0298-4764-9176-0b44ddffc364': '객관식: 다음 중 일본이 2026년 회계연도까지 예상하는 디지털 인재 부족 규모로 옳은 것은?', '5a0695d1-5770-4986-b3ee-b27942e82155': 'A) 100만 명', 'b088f2ad-099a-4776-9ed7-b11d0e8cf7aa': '- Q1. 2021년부터 협업한 프로젝트에 따라 일본에서 시작된 최초의 레벨 자율주행 모빌리티 서비스의 레벨은 무엇이며, 이 협력의 주체 부처는 무엇인가요? (선택지: A) Level 2, B) Level 3, C) Level 4, D) Level 5)', 'ec2e7ceb-0134-4b9c-a0ff-1e871f7183b0': '- Q2. 서비스 로봇의 안전한 작동을 위한 국제 표준은 어느 국제기구에서 발표되었으며, 이 표준의 제안 주체는 누구인가요?', '7191a858-8ff8-4dfc-95e7-643c94d9a8de': 'Question 1 (다지선다)', 'd2989e2c-04ff-43b6-b943-d8e3018688db': '다음 중 일본 정부가 발표한 Web3 관련 백서의 주요 목표로 올바른 것은 무엇인가?', 'ad9e963c-7186-42db-bbd6-4e7de2b9bade': 'Question 1 (Multiple Choice)', 'b96bbcb5-2af6-4308-bc0e-503781dfaa76': \"From the 표 10 list of Japan's major ICT companies, which company has the highest sales and what is its primary business field?\", 'ca0bd1d4-24b9-48cc-bf48-fd13809249d5': '다음 중 6G 연구개발 협력에 합의한 두 회사는 무엇인가요?', 'b6b8f11a-dd77-442b-a836-8c9e5722059e': 'A. NTT와 KDDI', '06085563-3fc0-43ee-9fa4-0718b55db0af': 'Q1: What is the numeric value shown in the context information block?', '71dbbcde-8bbe-4826-a9bb-ec0202393c87': 'Q2: Based on the context that the only content is the number 18, propose two different plausible interpretations of what 18 could represent in a document, and provide a one-sentence justification for each interpretation.', '000e20db-559e-4901-bc70-8b5d4e85c279': '질문 1 (간단한 요약형)', '8274de3c-9ab4-454b-b931-e309bc7456c4': '다음 내용을 바탕으로 간단히 요약하시오: (1) 정부 이용을 위한 AI 학습에 필요한 대량의 행정정보를 국외로 반출하기 어려운 이유, (2) 마이크로소프트가 해외 거점을 두고 일본에서 기술 서비스를 전개하는 맥락, (3) 일본어 데이터 축적 및 정밀도 향상 계획, (4) 이와 함께 기대되는 정부 계약의 효과.', 'f1176fb8-f852-4a5d-a389-7966dfceb3c7': '다음 중 일본어 데이터에 대해 연내 공동연구 형태로 제공 검토 중인 기관은 어디인가?', 'ca433028-2b7b-4e68-95eb-4ec321c616be': 'A) 총무성', 'fac0c2dc-1c7a-411a-b623-a35d76179374': '단답형', '16c3d1c8-b9c8-4c89-9dde-53f397726ab1': '- 일본의 건강보험증 정책 변화에 대해 설명하시오. 포함해야 할 핵심 요소: 현재 발행 중인 건강보험증의 폐지 계획의 시점, 이를 대체하는 카드의 명칭(마이 넘버 카드의 보험증으로의 활용), 유예기간의 최대 길이 등이 무엇인지.', '93775685-b8c8-4869-a357-a422659228e6': 'True/False: 해당 절전방식이 전 세계 표준이 되도록 계획하는 것이 문서의 핵심 목표이다. (참/거짓)', '69a6d54b-6f6c-4951-8593-d0f8597cd722': '단답형: 일본 자민당이 모색 중인 법률 개정의 주된 목적은 무엇인가?', '4e5ca890-007e-4b8e-be2f-18ee18b62b32': '서술형 질문', '15bd6055-9515-4145-aa1d-1cbbe3bea737': '문맥에 따라 제시된 데이터전환 프로젝트의 목적과 추진 체계에 대해 설명하시오. 구체적으로는 (a) 데이터PT 설치 및 기계 판독 가능한 데이터 전환의 정부 차원 노력의 의의, (b) 시범 결과를 바탕으로 도출된 중장기 추진 방식·체제·비용 규칙의 필요성, (c) 데이터 형식 변환의 역할과 데이터의 분류·목록화의 필요성에 대해 논하시오.', 'baf9dd04-450d-48a1-9f8d-b3ee303617be': '- Q1. \"\\'데이터의 자유로운 흐름\\' 조항과 관련하여 합의된 내용은 무엇이며, 이를 조기 서명하기 위한 절차를 가속화하기로 한 결정은 어떤 만남과 관련되어 있는가?\\'', 'b5e5854b-ba81-4244-9ac6-faa13b9f73df': '- Q2. 일본에서 시작된 최초의 레벨 4 자율주행 모빌리티 서비스에 대해 서술하고, 이 서비스를 추진한 주체와 해당 서비스가 어떤 법에 따라 자동운전 차량으로 승인되었는지 설명하시오.\"', '7094c244-4638-4b38-8f66-2059c9d3ab7c': '- Question 1: According to Research and Markets, Japan is among the top APAC data center markets next to which two countries, and what percentage of Japan’s data centers are located in Tokyo and Osaka?', '5cf2d12a-5e26-43a8-bc62-5dd9a3cba76a': '- Question 2: What policy did Japan’s METI propose in May 2023 regarding data centers in Hokkaido and Kyushu, and how do the regions’ renewable energy characteristics and the need for decentralization influence this proposal?', '1a36a65e-5a97-47b9-9711-dfe1f8cc32b7': \"상황형 서술형 질문: 개인정보 취급 사업자가 생성형 AI 서비스에 개인정보를 포함한 프롬프트를 입력할 때 반드시 확인해야 하는 '특정 이용 목적'의 범위와 그 처리 원칙에 대해 서술하시오.\", 'd55d3069-78a7-4d39-8d60-6941e32f8860': '객관식 질문: 다음 설명 중 지침에 따라 옳은 것은 무엇인가?', '3a64f0f3-5a86-43c9-8713-ff615731ed7e': '쿠시먼앤드웨이크필드의 추정에 따르면 2022년 말 도쿄 광역 지역의 데이터센터 용량은 865MW였고, 3~5년 내에 1,970MW에 이를 것으로 전망된다. 이 경우 용량 증가폭과 증가율(백분율)을 산출하시오. 필요 시 소수점 둘째 자리까지 반올림하시오.', 'd01ce05f-9160-4591-b5af-db1b89b7c36e': '본 문맥 정보를 바탕으로 도쿄가 베이징에 이어 아시아의 두 번째 데이터센터 허브로 빠르게 격차를 좁히고 있는 주요 요인을 두 가지 이상 제시하고, 이러한 추세가 국제 IT 기업의 전략에 제시하는 시사점을 논하시오.', '4719c51b-d75f-4efa-ac56-2f81fbaf86e9': '객관식: 다음 중 문서의 내용과 일치하지 않는 진술을 고르시오.', 'a2ff8237-19a5-4f41-9ba6-4b0d8b0c3704': 'A) 홋카이도와 규슈는 재생에너지 생산이 많아 데이터센터에 적합하다고 분석되었다.', 'c5fac7e7-6a14-4aab-befe-0d5a7967ec63': 'Quantitative: Using the figures provided, the Japanese data center market is projected to reach 11.44 billion USD in 2028 with a CAGR of 5.93% from 2022. Estimate the market size in 2022 (in USD, to the nearest tenth of a billion).', 'ee1a5abf-9414-46c4-8248-798e96a91a25': 'Policy/Regional: According to the document, which two regions were identified for potential subsidies by METI in May 2023 to promote data center construction in Japan?', '24cd98ae-ed8b-4694-b7db-cdf35399d212': '- Question 1 (객관식): ICT 국가 개황에서 ‘세계 혁신지수’가 13위이고, ‘인프라’ 및 ‘지식 및 기술 생산’ 지표가 상대적으로 우위이며 ‘창조적 생산’이 열위인 국가는?', 'b453d1a7-7d66-4b3d-adc3-cbd427916090': 'A) 한국  B) 일본  C) 미국  D) 독일', '3f80ecff-dc01-4792-a61b-290901089f13': '- Question 1 (다지선다): 2022년 10월에 일본 화상회의 시장 공략을 가속화하기 위해 일본 IT 위크에 참가한 회사는 무엇인가요?', '3c8cc611-1d7f-4725-a6eb-6747e3283129': 'A) 알서포트  B) 시큐아이  C) SKT  D) 로완', '568a2868-00ae-4292-9be6-d0f71aa420cd': '일본에서 문서에 따라 자율주행 배송 로봇에 대해 필수적으로 갖춰야 하는 보안·규제 조치를 모두 열거하시오. (예: 위치 확인을 위한 원격 모니터링 장비 설치, 사이버보안 조치, 운용자 등록 시스템, 로봇의 원격 제어 표시, 비상 정지 버튼 등)', '5f10a91f-2eea-4e3b-911d-65c626e652e4': '표 12에 설명된 승인된 특정 자율주행 운행 계획의 차량 구성에 대해 설명하시오. 구체적으로 다음을 포함하시오:', '7e9e19f4-a8bb-4251-a52c-e2a728f5cdb2': '문제 1 (다지선다형)', '20445a3d-40f6-4e00-9cc5-1939d66fb017': '다음 중 6G 표준 개발의 목표로 제시된 세 가지와 부합하지 않는 것은 어떤 것인가?', '6973ab43-c082-41b0-8fb6-5757ab632107': '다지선다형: 아래 중 일본 ICT 관련 기업 중 매출액 1위를 차지한 기업은 어디인가?', '94e8e932-f685-4f57-820e-3897a9ee5383': 'A) 도요타', '2c82644f-2ddb-430d-a9ca-ad5a20f72862': '다음 중 일본 디지털청이 최근 추진한 정책이 아닌 것은?', 'cf6cc663-12cc-4d5a-a8a7-f387babaea4a': 'A) 스마트폰용 전자증명서 탑재 서비스 출시', '74004abe-3fba-4cdc-ab7e-abc6a6402cec': '질문 1: 정부 사이버보안 전략실이 주관하는 두 가지 정책 변화의 핵심 내용을 요약하고, 각각의 대상(예: 독립 행정기관, 외부 공급업체 등)과 적용 시점을 제시하시오.', 'b61e3bfc-0fed-4aca-b91c-68ccc803006e': '질문 2: 일본이 2025년부터 도입하기로 한 자체 개발 소프트웨어의 목적과 주요 기능(정부 컴퓨터용 신규 시스템, 공격 정보 수집·분석)을 설명하고, 이 소프트웨어가 마이크로소프트 및 기타 기업의 기존 소프트웨어와 호환된다는 점이 계층화 방어 측면에서 가지는 의미를 논하시오.', 'da595d7b-1b2c-4fab-a592-4425b3ae2444': 'Question 1 (참/거짓):', '1ea8109f-9aaa-47ad-be1a-7cdef5921d95': '전자 처방전은 환자의 마이 넘버 보험증과 함께 활용되어 과거 복약 정보를 확인할 수 있다.', '9bb74992-3847-430f-8d57-1ca55252f179': 'Based on the context provided, what is the main topic of the document titled “2023.127.デジタル時代の⼈材政策に関する検討会, 「⽣成AI時代のDX推進に必要な⼀材・スキルの考え⽅ 」, 2023.08.07\" and on what date was it published?', '0712a983-c44a-428d-95d9-f4c7edb1910c': 'From the referenced sites list, name two Japanese government ministries or agencies that are mentioned.', 'e9c8d79f-13de-4657-bff0-84f5c7066ea7': '- Question 1 (객관식): 다음 중 일본에서 자국 AI 시스템 도입의 최초 사례로 알려진 도시는 어디인가?', '5ec8093f-e380-4437-a024-44597bf0d092': 'A) 도쿄', '789f271c-b31e-4cd0-84a7-7aa550009eda': '질문 1. 서술형', 'a28e6e27-a7bf-4167-8f3f-6af6fed6fd22': '해당 안면 인식 기술의 초기 시범 운용과 관련하여 구체적으로 위치한 장소는 어디이며, 시범 운용의 핵심 목표는 무엇인지 그리고 향후 어떤 계획으로 발전시키려 하는지 문맥에 근거하여 설명하시오.', '30b1f57c-e850-4857-b613-3f9813576051': 'Multiple Choice: Which organization is piloting a facial recognition ticketing system for train passengers, enabling payment via facial recognition at gates?', '68ffc270-f329-49cb-b2ed-1ccdb20e2b12': 'A) JR East', '0dc64088-9e57-41f4-b640-451cb0cc6461': '- Q1 (단답형): 일본의 ICT 정부기구인 디지털청의 공식 영어 명칭은 무엇인가?', '7fecac66-75f9-4a71-bb70-5c04747abdad': '- Q2 (객관식): 디지털청은 디지털 시대의 민관 인프라를 단기간에 만들어내는 것을 목표로 한다. 이 목표를 달성하기 위한 기간은 얼마인가?'}\n",
      "{'2d5608a7-bd91-471b-b446-93bf7f270c21': ['a55488ec-aeba-4f8e-8ee4-74c3a4efa42a'], '2fc72960-f28f-4907-8c56-b1395b91fc05': ['a55488ec-aeba-4f8e-8ee4-74c3a4efa42a'], 'fdc1aa68-9cab-46e3-83f0-71c5541c1b4e': ['9d69bf7c-534d-414a-8cbb-b55205207bc6'], 'c92dc7dc-2139-4f71-8399-e3d3aa4a449d': ['9d69bf7c-534d-414a-8cbb-b55205207bc6'], '7bf2ae23-ed1e-4a10-8311-a1cfaf167901': ['da24ebce-8408-431c-a7fe-f478bad4bbca'], '302c005e-878c-4279-ae31-5661a0575a84': ['da24ebce-8408-431c-a7fe-f478bad4bbca'], 'bea88339-95cc-460b-91d8-c6f22402673c': ['664450c0-c405-4527-879e-0626e3d4e18e'], 'b81e5743-5761-485f-80dc-c41f757892d8': ['664450c0-c405-4527-879e-0626e3d4e18e'], '7322c0bc-ae2a-4edd-b773-f30c2d9004aa': ['c3d6eefe-c8a3-41b5-bfb2-f48b948129bb'], '72f13d4d-1d25-4489-8bb0-d3bce78c9d18': ['c3d6eefe-c8a3-41b5-bfb2-f48b948129bb'], '936c5323-e318-4fcd-8db8-a4b8e29d3630': ['6f8530cb-39f7-470a-8acd-dbc9efe57344'], 'c19c7357-22a5-44e7-a2d6-e180c25de34f': ['6f8530cb-39f7-470a-8acd-dbc9efe57344'], '2ec99997-0d40-47fd-910c-5ce242110313': ['6197e77e-ff5d-44d0-8f21-d71e9357b5f4'], '37fd4c14-a5fd-485f-8d52-a78bef4b393e': ['6197e77e-ff5d-44d0-8f21-d71e9357b5f4'], '8c395200-dfdd-4106-bd91-9c3f141924d7': ['a51ecba3-5384-45f3-8385-5360546fce7d'], '70f1cfd0-e407-4f8f-99b7-1e7b10df5dd3': ['a51ecba3-5384-45f3-8385-5360546fce7d'], 'fa89b5d9-0298-4764-9176-0b44ddffc364': ['a4905f66-d715-45fd-a7a6-7b97cba5f5e6'], '5a0695d1-5770-4986-b3ee-b27942e82155': ['a4905f66-d715-45fd-a7a6-7b97cba5f5e6'], 'b088f2ad-099a-4776-9ed7-b11d0e8cf7aa': ['c527c848-eadd-416f-a22a-5ec5e765c5e0'], 'ec2e7ceb-0134-4b9c-a0ff-1e871f7183b0': ['c527c848-eadd-416f-a22a-5ec5e765c5e0'], '7191a858-8ff8-4dfc-95e7-643c94d9a8de': ['0e093f9b-b54e-48e4-89fa-d219e19bd8e9'], 'd2989e2c-04ff-43b6-b943-d8e3018688db': ['0e093f9b-b54e-48e4-89fa-d219e19bd8e9'], 'ad9e963c-7186-42db-bbd6-4e7de2b9bade': ['d84edab4-32cc-40bd-a050-45af1d90d21b'], 'b96bbcb5-2af6-4308-bc0e-503781dfaa76': ['d84edab4-32cc-40bd-a050-45af1d90d21b'], 'ca0bd1d4-24b9-48cc-bf48-fd13809249d5': ['ba4bea05-93f5-4e05-8c17-ac610ae94f2d'], 'b6b8f11a-dd77-442b-a836-8c9e5722059e': ['ba4bea05-93f5-4e05-8c17-ac610ae94f2d'], '06085563-3fc0-43ee-9fa4-0718b55db0af': ['39577555-d0cf-4978-9e45-3ff3934723f4'], '71dbbcde-8bbe-4826-a9bb-ec0202393c87': ['39577555-d0cf-4978-9e45-3ff3934723f4'], '000e20db-559e-4901-bc70-8b5d4e85c279': ['b942e6c0-6969-4764-9490-f862239f4b27'], '8274de3c-9ab4-454b-b931-e309bc7456c4': ['b942e6c0-6969-4764-9490-f862239f4b27'], 'f1176fb8-f852-4a5d-a389-7966dfceb3c7': ['4af91542-7564-4d08-ad80-bfdc318558ac'], 'ca433028-2b7b-4e68-95eb-4ec321c616be': ['4af91542-7564-4d08-ad80-bfdc318558ac'], 'fac0c2dc-1c7a-411a-b623-a35d76179374': ['838d9563-81cf-458f-808e-bde8c46eec87'], '16c3d1c8-b9c8-4c89-9dde-53f397726ab1': ['838d9563-81cf-458f-808e-bde8c46eec87'], '93775685-b8c8-4869-a357-a422659228e6': ['f90881c8-637a-4a0b-b399-c9440121068c'], '69a6d54b-6f6c-4951-8593-d0f8597cd722': ['f90881c8-637a-4a0b-b399-c9440121068c'], '4e5ca890-007e-4b8e-be2f-18ee18b62b32': ['a0531cb6-b97a-49ae-b01c-b050c5df6d81'], '15bd6055-9515-4145-aa1d-1cbbe3bea737': ['a0531cb6-b97a-49ae-b01c-b050c5df6d81'], 'baf9dd04-450d-48a1-9f8d-b3ee303617be': ['55839697-9306-4e58-88b9-177a3da2aad6'], 'b5e5854b-ba81-4244-9ac6-faa13b9f73df': ['55839697-9306-4e58-88b9-177a3da2aad6'], '7094c244-4638-4b38-8f66-2059c9d3ab7c': ['95dfde59-1538-487b-a2b7-2dc702c4e402'], '5cf2d12a-5e26-43a8-bc62-5dd9a3cba76a': ['95dfde59-1538-487b-a2b7-2dc702c4e402'], '1a36a65e-5a97-47b9-9711-dfe1f8cc32b7': ['55e8be52-b68a-4b11-83e5-5e923c8b454a'], 'd55d3069-78a7-4d39-8d60-6941e32f8860': ['55e8be52-b68a-4b11-83e5-5e923c8b454a'], '3a64f0f3-5a86-43c9-8713-ff615731ed7e': ['ed751da3-f65d-49d8-b208-af7eab2dedd8'], 'd01ce05f-9160-4591-b5af-db1b89b7c36e': ['ed751da3-f65d-49d8-b208-af7eab2dedd8'], '4719c51b-d75f-4efa-ac56-2f81fbaf86e9': ['e0c5ed08-57c0-4840-ac88-baa9db548a6d'], 'a2ff8237-19a5-4f41-9ba6-4b0d8b0c3704': ['e0c5ed08-57c0-4840-ac88-baa9db548a6d'], 'c5fac7e7-6a14-4aab-befe-0d5a7967ec63': ['176847fb-6d3e-4a14-a30e-aa01e4a77749'], 'ee1a5abf-9414-46c4-8248-798e96a91a25': ['176847fb-6d3e-4a14-a30e-aa01e4a77749'], '24cd98ae-ed8b-4694-b7db-cdf35399d212': ['e2e90edd-80bc-4f42-a56e-f584fcfeec15'], 'b453d1a7-7d66-4b3d-adc3-cbd427916090': ['e2e90edd-80bc-4f42-a56e-f584fcfeec15'], '3f80ecff-dc01-4792-a61b-290901089f13': ['0db7b52d-f825-487d-89e9-7012c932c370'], '3c8cc611-1d7f-4725-a6eb-6747e3283129': ['0db7b52d-f825-487d-89e9-7012c932c370'], '568a2868-00ae-4292-9be6-d0f71aa420cd': ['924def07-c2af-4363-b291-5ab725b7aab2'], '5f10a91f-2eea-4e3b-911d-65c626e652e4': ['924def07-c2af-4363-b291-5ab725b7aab2'], '7e9e19f4-a8bb-4251-a52c-e2a728f5cdb2': ['6b809a58-6f73-4f22-a22b-753b0148ddf1'], '20445a3d-40f6-4e00-9cc5-1939d66fb017': ['6b809a58-6f73-4f22-a22b-753b0148ddf1'], '6973ab43-c082-41b0-8fb6-5757ab632107': ['c388e749-5272-47b1-ad57-1dc57809995f'], '94e8e932-f685-4f57-820e-3897a9ee5383': ['c388e749-5272-47b1-ad57-1dc57809995f'], '2c82644f-2ddb-430d-a9ca-ad5a20f72862': ['d395589f-394b-4ad4-8188-f1993d335d55'], 'cf6cc663-12cc-4d5a-a8a7-f387babaea4a': ['d395589f-394b-4ad4-8188-f1993d335d55'], '74004abe-3fba-4cdc-ab7e-abc6a6402cec': ['060178a3-9511-4d81-a3ea-3b3ca301585d'], 'b61e3bfc-0fed-4aca-b91c-68ccc803006e': ['060178a3-9511-4d81-a3ea-3b3ca301585d'], 'da595d7b-1b2c-4fab-a592-4425b3ae2444': ['cb6dd988-bf3d-4877-ac14-bff0dd7e06c7'], '1ea8109f-9aaa-47ad-be1a-7cdef5921d95': ['cb6dd988-bf3d-4877-ac14-bff0dd7e06c7'], '9bb74992-3847-430f-8d57-1ca55252f179': ['0385a475-8a91-444a-9f39-19d909236d18'], '0712a983-c44a-428d-95d9-f4c7edb1910c': ['0385a475-8a91-444a-9f39-19d909236d18'], 'e9c8d79f-13de-4657-bff0-84f5c7066ea7': ['a198aa21-de51-4474-859b-f11b17247817'], '5ec8093f-e380-4437-a024-44597bf0d092': ['a198aa21-de51-4474-859b-f11b17247817'], '789f271c-b31e-4cd0-84a7-7aa550009eda': ['7a001a11-b096-47b3-933f-538f2ad64cb9'], 'a28e6e27-a7bf-4167-8f3f-6af6fed6fd22': ['7a001a11-b096-47b3-933f-538f2ad64cb9'], '30b1f57c-e850-4857-b613-3f9813576051': ['fb1c5700-ab16-45bb-9b5e-9822aef0477f'], '68ffc270-f329-49cb-b2ed-1ccdb20e2b12': ['fb1c5700-ab16-45bb-9b5e-9822aef0477f'], '0dc64088-9e57-41f4-b640-451cb0cc6461': ['9ca352c3-9931-4001-8ad7-eaf61dffd59c'], '7fecac66-75f9-4a71-bb70-5c04747abdad': ['9ca352c3-9931-4001-8ad7-eaf61dffd59c']}\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH_VALID = \"data/japan_valid_dataset.json\"\n",
    "\n",
    "if os.path.exists(DATASET_PATH_VALID):\n",
    "    print(f\"이미 저장된 데이터셋이 있습니다. '{DATASET_PATH_VALID}'를 로드합니다...\")\n",
    "    valid_dataset = EmbeddingQAFinetuneDataset.from_json(DATASET_PATH_VALID)\n",
    "    \n",
    "else:\n",
    "    print(\"저장된 데이터셋이 없습니다. 생성을 시작합니다... (시간 소요됨)\")\n",
    "    \n",
    "    valid_dataset = generate_qa_embedding_pairs(\n",
    "        nodes=selected_nodes_valid,\n",
    "        llm=llm,\n",
    "        num_questions_per_chunk=2,\n",
    "        output_path=DATASET_PATH_VALID\n",
    "    )\n",
    "    print(\"생성 및 저장 완료!\")\n",
    "\n",
    "print(f\"데이터 준비 완료: 쿼리 {len(valid_dataset.queries)}개\")\n",
    "\n",
    "print(valid_dataset.queries)\n",
    "print(valid_dataset.relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c8cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_queries = valid_dataset.queries\n",
    "val_corpus = valid_dataset.corpus\n",
    "\n",
    "val_relavant_docs = {\n",
    "    q_id:set(doc_ids) for q_id, doc_ids in valid_dataset.relevant_docs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4441a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = InformationRetrievalEvaluator(\n",
    "    queries=val_queries,\n",
    "    corpus=val_corpus,\n",
    "    relevant_docs=val_relavant_docs,\n",
    "    name='val_evaluator'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f295c944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
      "Use pytorch device_name: cuda:0\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
      "Load pretrained SentenceTransformer: BAAI/bge-m3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "loader = DataLoader(train_examples, batch_size=batch_size, shuffle=True)\n",
    "model = SentenceTransformer(model_id)\n",
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a7e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a89a7312fc54e8fa4561a5a80b08c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Val Evaluator Cosine Accuracy@1</th>\n",
       "      <th>Val Evaluator Cosine Accuracy@3</th>\n",
       "      <th>Val Evaluator Cosine Accuracy@5</th>\n",
       "      <th>Val Evaluator Cosine Accuracy@10</th>\n",
       "      <th>Val Evaluator Cosine Precision@1</th>\n",
       "      <th>Val Evaluator Cosine Precision@3</th>\n",
       "      <th>Val Evaluator Cosine Precision@5</th>\n",
       "      <th>Val Evaluator Cosine Precision@10</th>\n",
       "      <th>Val Evaluator Cosine Recall@1</th>\n",
       "      <th>Val Evaluator Cosine Recall@3</th>\n",
       "      <th>Val Evaluator Cosine Recall@5</th>\n",
       "      <th>Val Evaluator Cosine Recall@10</th>\n",
       "      <th>Val Evaluator Cosine Ndcg@10</th>\n",
       "      <th>Val Evaluator Cosine Mrr@10</th>\n",
       "      <th>Val Evaluator Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.258772</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.751489</td>\n",
       "      <td>0.721272</td>\n",
       "      <td>0.729133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.892200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.747545</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.723800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.751925</td>\n",
       "      <td>0.717763</td>\n",
       "      <td>0.724612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.751925</td>\n",
       "      <td>0.717763</td>\n",
       "      <td>0.724534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 0.47619047619047616 after 10 steps:\n",
      "Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 0.47619047619047616 after 10 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 76\n",
      "Queries: 76\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 38\n",
      "\n",
      "Corpus: 38\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 64.47%\n",
      "Accuracy@1: 64.47%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 77.63%\n",
      "Accuracy@3: 77.63%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 84.21%\n",
      "Accuracy@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 84.21%\n",
      "Accuracy@10: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 64.47%\n",
      "Precision@1: 64.47%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 25.88%\n",
      "Precision@3: 25.88%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 16.84%\n",
      "Precision@5: 16.84%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.42%\n",
      "Precision@10: 8.42%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 64.47%\n",
      "Recall@1: 64.47%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 77.63%\n",
      "Recall@3: 77.63%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 84.21%\n",
      "Recall@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 84.21%\n",
      "Recall@10: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.7213\n",
      "MRR@10: 0.7213\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.7515\n",
      "NDCG@10: 0.7515\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.7291\n",
      "MAP@100: 0.7291\n",
      "INFO:sentence_transformers.trainer:Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-10\n",
      "Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-10\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-10\n",
      "Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-10\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 0.9523809523809523 after 20 steps:\n",
      "Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 0.9523809523809523 after 20 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 76\n",
      "Queries: 76\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 38\n",
      "\n",
      "Corpus: 38\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 63.16%\n",
      "Accuracy@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 78.95%\n",
      "Accuracy@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 84.21%\n",
      "Accuracy@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 84.21%\n",
      "Accuracy@10: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 63.16%\n",
      "Precision@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 26.32%\n",
      "Precision@3: 26.32%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 16.84%\n",
      "Precision@5: 16.84%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.42%\n",
      "Precision@10: 8.42%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 63.16%\n",
      "Recall@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 78.95%\n",
      "Recall@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 84.21%\n",
      "Recall@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 84.21%\n",
      "Recall@10: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.7158\n",
      "MRR@10: 0.7158\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.7475\n",
      "NDCG@10: 0.7475\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.7238\n",
      "MAP@100: 0.7238\n",
      "INFO:sentence_transformers.trainer:Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-20\n",
      "Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-20\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-20\n",
      "Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-20\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 1.4285714285714286 after 30 steps:\n",
      "Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 1.4285714285714286 after 30 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 76\n",
      "Queries: 76\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 38\n",
      "\n",
      "Corpus: 38\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 63.16%\n",
      "Accuracy@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 78.95%\n",
      "Accuracy@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 84.21%\n",
      "Accuracy@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 85.53%\n",
      "Accuracy@10: 85.53%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 63.16%\n",
      "Precision@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 26.32%\n",
      "Precision@3: 26.32%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 16.84%\n",
      "Precision@5: 16.84%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.55%\n",
      "Precision@10: 8.55%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 63.16%\n",
      "Recall@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 78.95%\n",
      "Recall@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 84.21%\n",
      "Recall@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 85.53%\n",
      "Recall@10: 85.53%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.7178\n",
      "MRR@10: 0.7178\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.7519\n",
      "NDCG@10: 0.7519\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.7246\n",
      "MAP@100: 0.7246\n",
      "INFO:sentence_transformers.trainer:Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-30\n",
      "Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-30\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-30\n",
      "Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-30\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 1.9047619047619047 after 40 steps:\n",
      "Information Retrieval Evaluation of the model on the val_evaluator dataset in epoch 1.9047619047619047 after 40 steps:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 76\n",
      "Queries: 76\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 38\n",
      "\n",
      "Corpus: 38\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 63.16%\n",
      "Accuracy@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 78.95%\n",
      "Accuracy@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 84.21%\n",
      "Accuracy@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 85.53%\n",
      "Accuracy@10: 85.53%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 63.16%\n",
      "Precision@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 26.32%\n",
      "Precision@3: 26.32%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 16.84%\n",
      "Precision@5: 16.84%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.55%\n",
      "Precision@10: 8.55%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 63.16%\n",
      "Recall@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 78.95%\n",
      "Recall@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 84.21%\n",
      "Recall@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 85.53%\n",
      "Recall@10: 85.53%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.7178\n",
      "MRR@10: 0.7178\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.7519\n",
      "NDCG@10: 0.7519\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.7245\n",
      "MAP@100: 0.7245\n",
      "INFO:sentence_transformers.trainer:Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-40\n",
      "Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-40\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-40\n",
      "Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-40\n",
      "INFO:sentence_transformers.trainer:Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-42\n",
      "Saving model checkpoint to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-42\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-42\n",
      "Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\\checkpoint-42\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\n",
      "Save model to ../../../exercisebook_large_data/korean_sentence-embedding-model\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../../../exercisebook_large_data/korean_sentence-embedding-model'\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=10,\n",
    "    save_strategy='steps',\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset_hf,\n",
    "    loss=loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413d3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_st(model_id, name, evaluator):\n",
    "    os.makedirs('/data/embedding_finetuning_results', exist_ok=True)\n",
    "\n",
    "    model = SentenceTransformer(model_id)\n",
    "    result = evaluator(model)\n",
    "\n",
    "    result_df = pd.DataFrame([result]) if isinstance(result, dict) else result\n",
    "    output_path = f'/data/embedding_finetuning_results/Information-Retrieval-Evaluation_{name}_results.csv'\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6493d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
      "Use pytorch device_name: cuda:0\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n",
      "Load pretrained SentenceTransformer: BAAI/bge-m3\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the val_evaluator dataset:\n",
      "Information Retrieval Evaluation of the model on the val_evaluator dataset:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 76\n",
      "Queries: 76\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 38\n",
      "\n",
      "Corpus: 38\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 65.79%\n",
      "Accuracy@1: 65.79%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 77.63%\n",
      "Accuracy@3: 77.63%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 81.58%\n",
      "Accuracy@5: 81.58%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 82.89%\n",
      "Accuracy@10: 82.89%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 65.79%\n",
      "Precision@1: 65.79%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 25.88%\n",
      "Precision@3: 25.88%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 16.32%\n",
      "Precision@5: 16.32%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.29%\n",
      "Precision@10: 8.29%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 65.79%\n",
      "Recall@1: 65.79%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 77.63%\n",
      "Recall@3: 77.63%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 81.58%\n",
      "Recall@5: 81.58%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 82.89%\n",
      "Recall@10: 82.89%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.7241\n",
      "MRR@10: 0.7241\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.7503\n",
      "NDCG@10: 0.7503\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.7330\n",
      "MAP@100: 0.7330\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
      "Use pytorch device_name: cuda:0\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: ../../../exercisebook_large_data/korean_sentence-embedding-model\n",
      "Load pretrained SentenceTransformer: ../../../exercisebook_large_data/korean_sentence-embedding-model\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Information Retrieval Evaluation of the model on the val_evaluator dataset:\n",
      "Information Retrieval Evaluation of the model on the val_evaluator dataset:\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Queries: 76\n",
      "Queries: 76\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Corpus: 38\n",
      "\n",
      "Corpus: 38\n",
      "\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Score-Function: cosine\n",
      "Score-Function: cosine\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@1: 63.16%\n",
      "Accuracy@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@3: 78.95%\n",
      "Accuracy@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@5: 84.21%\n",
      "Accuracy@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Accuracy@10: 85.53%\n",
      "Accuracy@10: 85.53%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@1: 63.16%\n",
      "Precision@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@3: 26.32%\n",
      "Precision@3: 26.32%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@5: 16.84%\n",
      "Precision@5: 16.84%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Precision@10: 8.55%\n",
      "Precision@10: 8.55%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@1: 63.16%\n",
      "Recall@1: 63.16%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@3: 78.95%\n",
      "Recall@3: 78.95%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@5: 84.21%\n",
      "Recall@5: 84.21%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:Recall@10: 85.53%\n",
      "Recall@10: 85.53%\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MRR@10: 0.7178\n",
      "MRR@10: 0.7178\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:NDCG@10: 0.7519\n",
      "NDCG@10: 0.7519\n",
      "INFO:sentence_transformers.evaluation.InformationRetrievalEvaluator:MAP@100: 0.7245\n",
      "MAP@100: 0.7245\n"
     ]
    }
   ],
   "source": [
    "original_result = evaluate_st(model_id='BAAI/bge-m3', name='original', evaluator=evaluator)\n",
    "finetuned_result = evaluate_st(model_id='../../../exercisebook_large_data/korean_sentence-embedding-model', name='finetuned', evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67a2220d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_evaluator_cosine_accuracy@1</th>\n",
       "      <th>val_evaluator_cosine_accuracy@3</th>\n",
       "      <th>val_evaluator_cosine_accuracy@5</th>\n",
       "      <th>val_evaluator_cosine_accuracy@10</th>\n",
       "      <th>val_evaluator_cosine_precision@1</th>\n",
       "      <th>val_evaluator_cosine_precision@3</th>\n",
       "      <th>val_evaluator_cosine_precision@5</th>\n",
       "      <th>val_evaluator_cosine_precision@10</th>\n",
       "      <th>val_evaluator_cosine_recall@1</th>\n",
       "      <th>val_evaluator_cosine_recall@3</th>\n",
       "      <th>val_evaluator_cosine_recall@5</th>\n",
       "      <th>val_evaluator_cosine_recall@10</th>\n",
       "      <th>val_evaluator_cosine_ndcg@10</th>\n",
       "      <th>val_evaluator_cosine_mrr@10</th>\n",
       "      <th>val_evaluator_cosine_map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.258772</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>0.082895</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.750275</td>\n",
       "      <td>0.724123</td>\n",
       "      <td>0.733022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.751925</td>\n",
       "      <td>0.717763</td>\n",
       "      <td>0.724534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_evaluator_cosine_accuracy@1  val_evaluator_cosine_accuracy@3  \\\n",
       "0                         0.657895                         0.776316   \n",
       "0                         0.631579                         0.789474   \n",
       "\n",
       "   val_evaluator_cosine_accuracy@5  val_evaluator_cosine_accuracy@10  \\\n",
       "0                         0.815789                          0.828947   \n",
       "0                         0.842105                          0.855263   \n",
       "\n",
       "   val_evaluator_cosine_precision@1  val_evaluator_cosine_precision@3  \\\n",
       "0                          0.657895                          0.258772   \n",
       "0                          0.631579                          0.263158   \n",
       "\n",
       "   val_evaluator_cosine_precision@5  val_evaluator_cosine_precision@10  \\\n",
       "0                          0.163158                           0.082895   \n",
       "0                          0.168421                           0.085526   \n",
       "\n",
       "   val_evaluator_cosine_recall@1  val_evaluator_cosine_recall@3  \\\n",
       "0                       0.657895                       0.776316   \n",
       "0                       0.631579                       0.789474   \n",
       "\n",
       "   val_evaluator_cosine_recall@5  val_evaluator_cosine_recall@10  \\\n",
       "0                       0.815789                        0.828947   \n",
       "0                       0.842105                        0.855263   \n",
       "\n",
       "   val_evaluator_cosine_ndcg@10  val_evaluator_cosine_mrr@10  \\\n",
       "0                      0.750275                     0.724123   \n",
       "0                      0.751925                     0.717763   \n",
       "\n",
       "   val_evaluator_cosine_map@100  \n",
       "0                      0.733022  \n",
       "0                      0.724534  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat([pd.DataFrame([original_result]), pd.DataFrame([finetuned_result])])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba9e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del loader\n",
    "del evaluator\n",
    "del loss\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9bd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
