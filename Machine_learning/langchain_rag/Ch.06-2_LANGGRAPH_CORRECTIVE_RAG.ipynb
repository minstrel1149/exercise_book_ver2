{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ecb4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, HTMLHeaderTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25690b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model='BAAI/bge-m3', model_kwargs={'device':'cuda'}, encode_kwargs={'batch_size':8})\n",
    "\n",
    "urls = [\n",
    "    \"https://google.github.io/styleguide/pyguide.html\",\n",
    "    \"https://google.github.io/styleguide/javaguide.html\",\n",
    "    \"https://google.github.io/styleguide/jsguide.html\"\n",
    "]\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = []\n",
    "for url in urls:\n",
    "    splits = html_splitter.split_text_from_url(url)\n",
    "    html_header_splits.extend(splits)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=250, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(html_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aefcf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name='rag-chroma',\n",
    "    embedding=embeddings\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bdbd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ef709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Preview: AUTHORS:\n",
      "Prefer only GitHub-flavored Markdown in e...\n",
      "Metadata: {}\n",
      "--------------------\n",
      "Content Preview: Google Python Style Guide...\n",
      "Metadata: {'Header 1': 'Google Python Style Guide'}\n",
      "--------------------\n",
      "Content Preview: Table of Contents  \n",
      "1 Background  \n",
      "2 Python Langua...\n",
      "Metadata: {'Header 1': 'Google Python Style Guide'}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc_splits[:3]: # 앞부분 3개만 확인\n",
    "    print(f\"Content Preview: {chunk.page_content[:50]}...\")\n",
    "    print(f\"Metadata: {chunk.metadata}\") \n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3013024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description='문서와 질문의 연관성 여부를 \"yes\" 또는 \"no\"로 알려주세요.')\n",
    "\n",
    "llm_eval = ChatOpenAI(model='gpt-5-nano', temperature=0)\n",
    "structured_llm_grader = llm_eval.with_structured_output(GradeDocuments)\n",
    "\n",
    "system = '''\n",
    "당신은 사용자의 질문에 대해 검색된 문서의 관련성을 평가하는 전문가입니다.\n",
    "문서에 질문과 관련된 키워드나 의미가 담겨 있으면, 해당 문서를 \"관련 있음\"으로 평가하세요.\n",
    "문서가 질문과 관련이 있는지 여부를 \"yes\" 또는 \"no\"로 표시해주세요.'''\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system), ('human', '검색된 문서: \\n\\n {document} \\n\\n 사용자 질문: {question}')]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1c835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "question = '파이썬 코드 작성 가이드'\n",
    "\n",
    "test = retriever.invoke(question)\n",
    "test_txt = test[0].page_content\n",
    "print(retrieval_grader.invoke({'question':question, 'document':test_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31044075",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gen = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "system = '''\n",
    "당신은 질문에 답변하는 업무를 돕는 도우미입니다.\n",
    "제공된 문맥을 바탕으로 질문에 답변하세요. 만약 답을 모른다면 모른다고 말하세요.\n",
    "세 문장을 넘지 않도록 답변을 간결하게 작성하세요.\n",
    "'''\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system), ('human', '질문: {question} \\n문맥: {context} \\n답변: ')]\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = prompt | llm_gen | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682a498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 코드 작성 가이드는 Google Python Style Guide를 기반으로 하며, 코드의 가독성과 일관성을 높이기 위한 규칙들을 포함합니다. 주요 내용으로는 코드 포맷팅, 주석 작성, 예외 처리, 함수 및 클래스 정의, 타입 주석 등이 있습니다. 각 항목은 명확한 규칙과 예제를 통해 설명되어 있어, 개발자들이 쉽게 따라할 수 있도록 돕습니다.\n"
     ]
    }
   ],
   "source": [
    "generation = rag_chain.invoke(\n",
    "    {'context':format_docs(doc_splits), 'question':question}\n",
    ")\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a1145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''\n",
    "당신은 입력된 질문을 변형하여 웹 검색에 최적화된 형태로 만드는 질문 생성기입니다.\n",
    "입력된 질문을 보고 그 이면에 있는 의미나 의도를 파악해주세요.\n",
    "'''\n",
    "rewrite_prompt = ChatPromptTemplate(\n",
    "    [('system', system), ('human', '질문: \\n\\n {question} \\n 더 나은 질문으로 바꿔주세요. 단 최적의 질문 하나만 골라서 출력해주세요.')]\n",
    ")\n",
    "\n",
    "question_rewriter = rewrite_prompt | llm_eval | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "603ed7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C++에서 깔끔하고 유지보수하기 쉬운 코드 작성 방법과 베스트 프랙티스는 무엇인가?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'C++ 깔끔하게 짜고 싶다.'\n",
    "question_rewriter.invoke({'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "126073c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearch(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c69009f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "068df87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    print('---retrieve---')\n",
    "    \n",
    "    question = state['question']\n",
    "    documents = retriever.invoke(question)\n",
    "\n",
    "    return {'question':question, 'documents':documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b599dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    print('---generate---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    generation = rag_chain.invoke({'context':documents, 'question':question})\n",
    "\n",
    "    return {'question':question, 'documents':documents, 'generation':generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ed97a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    print('---grade documents---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    filtered_docs = []\n",
    "    web_search = 'no'\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {'question':question, 'document':doc.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == 'yes':\n",
    "            print('--relavant document--')\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print('--irrelavant document--')\n",
    "            web_search = 'yes'\n",
    "            continue\n",
    "    \n",
    "    return {'question':question, 'documents':filtered_docs, 'web_search':web_search}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35003069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    print('---transform query---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    better_question = question_rewriter.invoke({'question':question})\n",
    "\n",
    "    return {'question':better_question, 'documents':documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2b03ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    print('---web search---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    docs = search_tool.invoke({'query':question})\n",
    "    web_results = '\\n'.join(doc['content'] for doc in docs)\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {'question':question, 'documents':documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec0d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
