{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1425b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List, Dict, Any, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_classic.storage import InMemoryStore\n",
    "from langchain_classic.retrievers import ContextualCompressionRetriever\n",
    "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_classic.retrievers.parent_document_retriever import ParentDocumentRetriever\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0464fb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e9ea115dcd45c4af961cc1d850b9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/795 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f69c8112434c849ebbcad4b6682c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0263510c5a754482a9bb5cc46fd8142a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03589f0dffb45998247bcba849ce238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82867872267d429db34d2d26122051c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56efada4fb7c48f0af2dbf1fd19c09f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f5d7e5886948da90fd580d8501c467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model='BAAI/bge-m3', model_kwargs={'device':'cuda'}, encode_kwargs={'batch_size':8})\n",
    "model = ChatOpenAI(model='gpt-5-mini', temperature=0)\n",
    "hf_model = HuggingFaceCrossEncoder(model_name='BAAI/bge-reranker-v2-m3', model_kwargs={'device':'cuda'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc459d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('./data/투자설명서.pdf')\n",
    "docs = loader.load()\n",
    "full_text = '\\n\\n'.join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214e6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=60)\n",
    "vectorstore = Chroma(collection_name='split_parents_self_rag', embedding_function=embeddings)\n",
    "docstore = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d06bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    docstore=docstore,\n",
    "    vectorstore=vectorstore,\n",
    "    parent_splitter=parent_splitter,\n",
    "    child_splitter=child_splitter\n",
    ")\n",
    "\n",
    "docs = retriever.add_documents([Document(page_content=full_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac637e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore._collection.count())\n",
    "print(len(list(docstore.yield_keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ab0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = CrossEncoderReranker(model=hf_model, top_n=5)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a663bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[Document]\n",
    "    retry_count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac1185df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    print('--- retrieve ---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = compression_retriever.invoke(question)\n",
    "\n",
    "    return {'documents':documents, 'question':question, 'retry_count':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0828fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    print('--- check relevance ---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    class Grade(BaseModel):\n",
    "        binary_score: str = Field(description='문서와 질문이 관련이 있으면 \"yes\", 아니면 \"no\"')\n",
    "    \n",
    "    structured_llm_grader = model.with_structured_output(Grade)\n",
    "\n",
    "    system = '''당신은 제공된 연관 문서가 주어진 질문과 관련이 있는지, 그리고 질문에 답하는 데 유용한 정보를 제공하는지 판단하는 것입니다.\n",
    "    철저하게 검증하여 문서가 질문의 키워드나 의미를 포함하고 있다면 \"yes\"를, 아니라면 \"no\"를 출력하세요.'''\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('system', system),\n",
    "         ('human', '질문: {question}\\n문서: {documents}')]\n",
    "    )\n",
    "    retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "    filtered_docs = []\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke({'question':question, 'documents':doc.page_content})\n",
    "        if score.binary_score == 'yes':\n",
    "            print(f' -- 문서 채택')\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(f' -- 문서 기각')\n",
    "    \n",
    "    return {'documents':filtered_docs, 'question':question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "223f127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    print('--- transform query ---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    retry_count = state.get('retry_count', 0) + 1\n",
    "\n",
    "    system = '''당신은 사용자의 질문을 검색에 더 최적화된 형태로 다듬는 전문가입니다.\n",
    "    원래 질문의 의도를 유지하면서, 더 좋은 문서를 찾을 수 있도록 질문을 수정하세요.'''\n",
    "    retry_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('system', system),\n",
    "         ('human', '원본 질문: {question}')]\n",
    "    )\n",
    "    question_rewriter = retry_prompt | model | StrOutputParser()\n",
    "\n",
    "    better_question = question_rewriter.invoke({'question':question})\n",
    "    print(f' -- 수정된 질문: {better_question}')\n",
    "\n",
    "    return {'documents':documents, 'question':better_question, 'retry_count':retry_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9bc9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    print('--- generate ---')\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    context = '\\n\\n'.join(doc.page_content for doc in documents)\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        '''다음 문서들을 바탕으로 질문에 답변하세요.\n",
    "        문서: {context}\n",
    "        질문: {question}\n",
    "        답변:'''\n",
    "    )\n",
    "    rag_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    generation = rag_chain.invoke({'context':context, 'question':question})\n",
    "\n",
    "    return {'documents':documents, 'question':question, 'generation':generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672b3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
