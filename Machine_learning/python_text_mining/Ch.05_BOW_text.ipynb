{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,\n",
       " 1353,\n",
       " ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc'],\n",
       " {0, 1, 2, 3})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data), len(newsgroups_test.data), newsgroups_train.target_names, set(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "comp.graphics\n",
      "The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available.\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])\n",
    "print(newsgroups_train.target_names[newsgroups_train.target[0]])\n",
    "print(newsgroups_test.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 5000) (1353, 5000)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=5000, min_df=5, max_df=0.5, stop_words='english')\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "print(X_train_cv.shape, X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8913470993117011 0.7738359201773836\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_cv, y_train)\n",
    "print(nb_clf.score(X_train_cv, y_train), nb_clf.score(X_test_cv, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 5000) (1353, 5000)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train_tf = tfidf.fit_transform(X_train_cv)\n",
    "X_test_tf = tfidf.transform(X_test_cv)\n",
    "print(X_train_tf.shape, X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154375614552606 0.754619364375462\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_tf, y_train)\n",
    "print(nb_clf.score(X_train_tf, y_train), nb_clf.score(X_test_tf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_token = RegexpTokenizer(\"[\\w']{3,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = reg_token.tokenize(text.lower())\n",
    "    features = list(map(lambda token: WordNetLemmatizer().lemmatize(token), tokens))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, ngram_range=(1, 3), min_df=5, max_df=0.5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9095378564405113 0.7760532150776053\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB(alpha=0.1)\n",
    "nb_clf.fit(X_train_cv, y_train)\n",
    "print(nb_clf.score(X_train_cv, y_train), nb_clf.score(X_test_cv, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 6007)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
