{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification, BertModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"She angered me with her inappropriate comments, rumor-spreading, and disrespectfulness at the formal dinner table\"\n",
    "target_sequence = \"She made me angry when she was rude at dinner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(input_sentence, target_sequence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1153, 22296,  1143,  1114,  1123, 17073,  7640,   117, 24206,\n",
       "           118,  9243,   117,  1105,  4267,  1116,  4894, 26426, 21047,  1120,\n",
       "          1103,  4698,  4014,  1952,   102,  1153,  1189,  1143,  4259,  1165,\n",
       "          1131,  1108, 14708,  1120,  4014,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.1998, 1.0848]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1998, 1.0848]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(**tokens).logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2921, 0.7079]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.2921, 0.7079]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.softmax(logits, dim=-1).tolist()[0]\n",
    "torch.softmax(logits, dim=-1), F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = movie_reviews.fileids()\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids[::2]]\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids[::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'neg':0, 'pos':1}\n",
    "y = np.array([label_dict[c] for c in categories])\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(reviews, y, test_size=0.3, random_state=0)\n",
    "len(X_train_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "y_pred = []\n",
    "num_batch = len(y_test) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_batch):\n",
    "    inputs = tokenizer(X_test[i*batch_size:(i+1)*batch_size], truncation=True, padding=True, return_tensors='pt')\n",
    "    inputs = inputs.to(device)\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.softmax(logits, dim=-1)\n",
    "    results = pred.cpu().detach().numpy().argmax(axis=1)\n",
    "    y_pred += results.tolist()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True,  True, False,  True,  True, False,\n",
       "        True,  True, False, False,  True, False,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test == np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum(y_test == np.array(y_pred)) / len(y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"What a beautiful day!\"\n",
    "sentence2 = \"Nvidia Titan XP has 12GB of VRAM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2054,  1037,  3376,  2154,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1050, 17258,  2401, 16537, 26726,  2038,  2260, 18259,  1997,\n",
       "         27830,  3286,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer([sentence1, sentence2], padding=True, return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2054,  1037,  3376,  2154,   999,   102,  1050, 17258,  2401,\n",
       "         16537, 26726,  2038,  2260, 18259,  1997, 27830,  3286,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2 = tokenizer(sentence1, sentence2, padding=True, return_tensors='pt')\n",
    "tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 140, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=0)\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
    "val_input = tokenizer(X_val, truncation=True, padding=True, return_tensors='pt')\n",
    "test_input = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([560, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).clone().detach().long()\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OurDataset(train_input, y_train)\n",
    "val_dataset = OurDataset(val_input, y_val)\n",
    "test_dataset = OurDataset(test_input, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results', num_train_epochs=5,\n",
    "                                  per_device_train_batch_size=16, per_device_eval_batch_size=16)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 560\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 175\n",
      "  Number of trainable parameters = 109483778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c849e5d48edd44338a6b72787f89cac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28760\\1974908807.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.inputs.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8134.7469, 'train_samples_per_second': 0.344, 'train_steps_per_second': 0.022, 'train_loss': 0.2736242893763951, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=175, training_loss=0.2736242893763951, metrics={'train_runtime': 8134.7469, 'train_samples_per_second': 0.344, 'train_steps_per_second': 0.022, 'train_loss': 0.2736242893763951, 'epoch': 5.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 140\n",
      "  Batch size = 16\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28760\\1974908807.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2b0f7141d649e4bcd285ae73211f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6298284530639648,\n",
       " 'eval_accuracy': 0.8571428571428571,\n",
       " 'eval_runtime': 130.928,\n",
       " 'eval_samples_per_second': 1.069,\n",
       " 'eval_steps_per_second': 0.069,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 300\n",
      "  Batch size = 16\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28760\\1974908807.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f642275b6c8d441cae2cc121d0fdfa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.2036018 ,  3.0777826 ],\n",
       "       [-2.258605  ,  3.0359993 ],\n",
       "       [ 1.723358  , -1.2343254 ],\n",
       "       [-0.61543936,  1.2520275 ],\n",
       "       [-1.7122723 ,  2.5018108 ],\n",
       "       [-2.209709  ,  3.0260465 ],\n",
       "       [ 3.03685   , -3.1605844 ],\n",
       "       [ 3.0342586 , -2.9141135 ],\n",
       "       [ 3.3118036 , -3.2655845 ],\n",
       "       [-2.286319  ,  3.093957  ],\n",
       "       [ 0.0825831 ,  0.48061898],\n",
       "       [-2.226719  ,  3.1229498 ],\n",
       "       [-2.2765694 ,  3.1148481 ],\n",
       "       [ 3.4807668 , -3.4574647 ],\n",
       "       [-2.2608256 ,  3.054328  ],\n",
       "       [ 3.5191972 , -3.5098321 ],\n",
       "       [-2.2009978 ,  2.978777  ],\n",
       "       [ 3.4565313 , -3.3855968 ],\n",
       "       [ 3.3440309 , -3.4467342 ],\n",
       "       [ 0.6027546 , -0.05014998],\n",
       "       [ 3.418641  , -3.4008975 ],\n",
       "       [ 2.8446012 , -2.877937  ],\n",
       "       [ 3.4141092 , -3.4840949 ],\n",
       "       [ 3.3552303 , -3.4452705 ],\n",
       "       [-2.070689  ,  2.924636  ],\n",
       "       [-2.242586  ,  3.0965939 ],\n",
       "       [-2.1123946 ,  2.9173203 ],\n",
       "       [ 3.4261394 , -3.336929  ],\n",
       "       [-2.236465  ,  3.0319448 ],\n",
       "       [ 3.4852753 , -3.4973063 ],\n",
       "       [-2.299193  ,  3.124403  ],\n",
       "       [ 2.6137614 , -2.6351318 ],\n",
       "       [-2.3124275 ,  3.0873766 ],\n",
       "       [-2.1919842 ,  3.0118291 ],\n",
       "       [ 3.5182223 , -3.4737678 ],\n",
       "       [-1.8552514 ,  2.5807207 ],\n",
       "       [-2.2441566 ,  2.9947188 ],\n",
       "       [ 3.0229855 , -2.7918985 ],\n",
       "       [-2.3206892 ,  3.0555243 ],\n",
       "       [ 3.5254989 , -3.4894066 ],\n",
       "       [ 3.2882385 , -3.340599  ],\n",
       "       [-1.3519343 ,  2.2624602 ],\n",
       "       [ 0.7378946 , -0.20135874],\n",
       "       [-2.325861  ,  3.1181233 ],\n",
       "       [ 3.4167295 , -3.3181634 ],\n",
       "       [-2.13894   ,  2.9371953 ],\n",
       "       [-2.1579418 ,  2.9889822 ],\n",
       "       [ 3.1123538 , -3.1164463 ],\n",
       "       [ 3.4625642 , -3.4318366 ],\n",
       "       [-2.180809  ,  3.0397248 ],\n",
       "       [ 3.3500645 , -3.407002  ],\n",
       "       [ 2.8612337 , -2.7544627 ],\n",
       "       [ 1.5397048 , -1.1418779 ],\n",
       "       [ 2.5327463 , -2.45896   ],\n",
       "       [-2.3779418 ,  3.092979  ],\n",
       "       [-2.3187609 ,  3.1003017 ],\n",
       "       [ 3.435463  , -3.4335322 ],\n",
       "       [ 3.3034604 , -3.2319288 ],\n",
       "       [-2.296351  ,  3.0516875 ],\n",
       "       [ 3.339497  , -3.394641  ],\n",
       "       [-2.2681663 ,  3.0733638 ],\n",
       "       [-1.8786074 ,  2.7479987 ],\n",
       "       [-1.0995759 ,  1.9451296 ],\n",
       "       [ 3.5068614 , -3.461388  ],\n",
       "       [-2.227685  ,  3.0615084 ],\n",
       "       [ 2.0245912 , -1.6685745 ],\n",
       "       [ 3.200635  , -3.1874876 ],\n",
       "       [-2.1905644 ,  3.0493898 ],\n",
       "       [ 2.3163557 , -2.0904827 ],\n",
       "       [-2.3034375 ,  3.0610867 ],\n",
       "       [-2.0329013 ,  2.9157279 ],\n",
       "       [ 3.5625217 , -3.4357753 ],\n",
       "       [-2.289607  ,  3.1192527 ],\n",
       "       [-2.154406  ,  3.0169272 ],\n",
       "       [-2.1715698 ,  3.024962  ],\n",
       "       [ 2.8277025 , -2.6314173 ],\n",
       "       [ 3.3025436 , -3.2446232 ],\n",
       "       [-2.2856007 ,  3.1181896 ],\n",
       "       [-2.11794   ,  3.0213437 ],\n",
       "       [-2.3365715 ,  3.0840318 ],\n",
       "       [ 3.2542825 , -3.4871204 ],\n",
       "       [-1.558568  ,  2.2609437 ],\n",
       "       [ 0.8496523 , -0.24683937],\n",
       "       [-2.2854662 ,  3.1120567 ],\n",
       "       [-0.27114955,  1.0028294 ],\n",
       "       [-2.187755  ,  3.0008807 ],\n",
       "       [-2.2704785 ,  3.1161463 ],\n",
       "       [ 3.4615853 , -3.4708838 ],\n",
       "       [ 2.7403498 , -2.6751294 ],\n",
       "       [-1.5106713 ,  2.260212  ],\n",
       "       [ 3.4044876 , -3.4773169 ],\n",
       "       [ 3.5119302 , -3.4991179 ],\n",
       "       [-2.3173285 ,  3.1045427 ],\n",
       "       [ 2.9408965 , -2.9484096 ],\n",
       "       [-2.2840672 ,  3.094295  ],\n",
       "       [ 3.1198528 , -3.0463924 ],\n",
       "       [-2.06114   ,  2.88913   ],\n",
       "       [ 3.4040575 , -3.4438627 ],\n",
       "       [ 3.334482  , -3.4116154 ],\n",
       "       [ 3.4038692 , -3.4207125 ],\n",
       "       [-2.076146  ,  2.9637089 ],\n",
       "       [-2.109747  ,  2.8290114 ],\n",
       "       [ 3.2304344 , -3.2111044 ],\n",
       "       [-2.321238  ,  2.997118  ],\n",
       "       [-2.3088884 ,  3.0635996 ],\n",
       "       [-2.2524827 ,  3.0922737 ],\n",
       "       [-2.252851  ,  3.0579014 ],\n",
       "       [ 0.48418918,  0.10069013],\n",
       "       [-2.3070145 ,  3.0760238 ],\n",
       "       [ 3.3356044 , -3.2439847 ],\n",
       "       [-1.8615775 ,  2.7183456 ],\n",
       "       [-2.2159686 ,  3.0729692 ],\n",
       "       [ 3.5418088 , -3.5271025 ],\n",
       "       [-2.03052   ,  2.8523903 ],\n",
       "       [ 3.5402493 , -3.4779515 ],\n",
       "       [-2.278142  ,  3.0653934 ],\n",
       "       [-2.048706  ,  2.8962636 ],\n",
       "       [ 3.4453952 , -3.4084551 ],\n",
       "       [ 1.0203986 , -0.41612673],\n",
       "       [-2.147275  ,  2.998824  ],\n",
       "       [-2.2701793 ,  3.0688677 ],\n",
       "       [-2.3120875 ,  3.1065433 ],\n",
       "       [-2.0847569 ,  2.9687347 ],\n",
       "       [-2.2353804 ,  3.037382  ],\n",
       "       [-2.0939713 ,  2.9326239 ],\n",
       "       [-2.2421541 ,  3.0874264 ],\n",
       "       [ 3.5123372 , -3.4996097 ],\n",
       "       [-1.8993556 ,  2.6630032 ],\n",
       "       [-2.2363212 ,  3.0988443 ],\n",
       "       [-2.2300482 ,  3.001514  ],\n",
       "       [ 2.9885106 , -2.9755876 ],\n",
       "       [-2.0472083 ,  2.8984537 ],\n",
       "       [-2.302584  ,  3.090776  ],\n",
       "       [-2.2031212 ,  3.0265393 ],\n",
       "       [-2.1834204 ,  3.0158677 ],\n",
       "       [-2.089781  ,  2.8873663 ],\n",
       "       [ 3.4909463 , -3.4819307 ],\n",
       "       [ 3.5366654 , -3.5096157 ],\n",
       "       [ 3.0309796 , -3.1846657 ],\n",
       "       [-2.4036345 ,  3.123183  ],\n",
       "       [ 3.5182562 , -3.507997  ],\n",
       "       [-0.35604453,  1.0738068 ],\n",
       "       [-2.210023  ,  3.0458894 ],\n",
       "       [ 3.5006852 , -3.481384  ],\n",
       "       [ 3.4734468 , -3.4868758 ],\n",
       "       [ 3.4120135 , -3.4504006 ],\n",
       "       [ 3.4716372 , -3.4693263 ],\n",
       "       [ 3.4903564 , -3.4363618 ],\n",
       "       [ 3.503336  , -3.4722552 ],\n",
       "       [ 3.4827647 , -3.4732132 ],\n",
       "       [-2.124636  ,  2.9745455 ],\n",
       "       [-0.45793682,  1.2301222 ],\n",
       "       [ 3.2998266 , -3.4578905 ],\n",
       "       [-2.3123822 ,  3.0594597 ],\n",
       "       [-2.1325793 ,  2.9099133 ],\n",
       "       [-2.276772  ,  3.072113  ],\n",
       "       [ 3.4848065 , -3.4989789 ],\n",
       "       [ 3.4685445 , -3.4896011 ],\n",
       "       [ 2.7769237 , -2.5845275 ],\n",
       "       [ 3.3584857 , -3.4482205 ],\n",
       "       [-2.2200594 ,  2.9738145 ],\n",
       "       [ 3.1606307 , -3.243248  ],\n",
       "       [-2.303783  ,  3.071773  ],\n",
       "       [-2.2482696 ,  3.074968  ],\n",
       "       [-2.300508  ,  3.0627284 ],\n",
       "       [ 3.552847  , -3.504128  ],\n",
       "       [ 2.87001   , -2.5636296 ],\n",
       "       [ 3.2975996 , -3.416039  ],\n",
       "       [ 2.456416  , -2.3366864 ],\n",
       "       [ 3.3536181 , -3.402482  ],\n",
       "       [-2.2798433 ,  3.1095362 ],\n",
       "       [-2.304624  ,  3.1194878 ],\n",
       "       [ 3.4952383 , -3.5031772 ],\n",
       "       [-2.17788   ,  3.0540533 ],\n",
       "       [ 3.3921413 , -3.3756063 ],\n",
       "       [-1.103341  ,  1.8753266 ],\n",
       "       [ 1.5902518 , -1.2780367 ],\n",
       "       [ 3.1768806 , -3.2184327 ],\n",
       "       [-0.4586534 ,  1.0865232 ],\n",
       "       [ 3.40597   , -3.3135333 ],\n",
       "       [ 2.0240269 , -1.630129  ],\n",
       "       [-2.216089  ,  3.0583189 ],\n",
       "       [-0.71627146,  1.4513506 ],\n",
       "       [ 2.7044215 , -2.4707093 ],\n",
       "       [ 3.3281517 , -3.3174713 ],\n",
       "       [-2.146766  ,  2.965513  ],\n",
       "       [-1.4074363 ,  2.2819421 ],\n",
       "       [ 3.5750031 , -3.469511  ],\n",
       "       [-2.3851042 ,  3.1261246 ],\n",
       "       [ 3.5041103 , -3.450336  ],\n",
       "       [-1.040695  ,  1.5892712 ],\n",
       "       [ 1.2660671 , -0.8225738 ],\n",
       "       [ 3.5394306 , -3.4681463 ],\n",
       "       [ 2.8987994 , -2.732967  ],\n",
       "       [-2.1784673 ,  3.0066159 ],\n",
       "       [-2.0198267 ,  2.814317  ],\n",
       "       [-2.2885885 ,  3.1269534 ],\n",
       "       [ 1.7098496 , -1.1487567 ],\n",
       "       [-2.3093262 ,  3.0998497 ],\n",
       "       [ 2.974248  , -2.9688973 ],\n",
       "       [-2.2230988 ,  3.0584254 ],\n",
       "       [ 0.4744922 ,  0.19653434],\n",
       "       [ 3.401556  , -3.4309611 ],\n",
       "       [-2.193801  ,  3.0260046 ],\n",
       "       [ 1.9400486 , -1.7607676 ],\n",
       "       [-2.2629704 ,  3.1010993 ],\n",
       "       [-2.2146118 ,  3.0762641 ],\n",
       "       [-2.2338214 ,  3.0071902 ],\n",
       "       [-2.1706312 ,  2.9915504 ],\n",
       "       [-2.180972  ,  2.9866385 ],\n",
       "       [ 3.5303376 , -3.5033875 ],\n",
       "       [-2.1515398 ,  3.021645  ],\n",
       "       [ 3.5442977 , -3.5357077 ],\n",
       "       [-2.0119603 ,  2.836329  ],\n",
       "       [-2.2526994 ,  2.9455051 ],\n",
       "       [-2.2461653 ,  3.0542855 ],\n",
       "       [-2.2776804 ,  3.0599217 ],\n",
       "       [ 3.5565326 , -3.5109904 ],\n",
       "       [ 3.4739616 , -3.469379  ],\n",
       "       [ 2.0067425 , -1.6572253 ],\n",
       "       [-2.174582  ,  3.0335991 ],\n",
       "       [-2.26809   ,  3.0662773 ],\n",
       "       [-1.7598853 ,  2.5163202 ],\n",
       "       [ 3.4759612 , -3.533352  ],\n",
       "       [ 3.526855  , -3.546883  ],\n",
       "       [ 3.5021162 , -3.5450983 ],\n",
       "       [ 3.226602  , -3.1829348 ],\n",
       "       [-2.289901  ,  3.1072607 ],\n",
       "       [ 3.3249454 , -3.4147766 ],\n",
       "       [ 3.5472689 , -3.4604146 ],\n",
       "       [-1.9802545 ,  2.8635826 ],\n",
       "       [ 3.314839  , -3.2420185 ],\n",
       "       [-2.226131  ,  3.0604687 ],\n",
       "       [-2.1275365 ,  2.9737067 ],\n",
       "       [-1.2496338 ,  1.9247684 ],\n",
       "       [ 3.468587  , -3.4528184 ],\n",
       "       [-2.2814128 ,  3.0846975 ],\n",
       "       [ 3.4639246 , -3.4559941 ],\n",
       "       [-2.2066476 ,  3.0209355 ],\n",
       "       [-1.9274753 ,  2.7063413 ],\n",
       "       [-0.8045402 ,  1.4589177 ],\n",
       "       [ 3.4933903 , -3.4451585 ],\n",
       "       [-2.2564876 ,  3.0710151 ],\n",
       "       [ 3.4569886 , -3.450237  ],\n",
       "       [-2.3369427 ,  3.1251233 ],\n",
       "       [ 3.4575987 , -3.5429525 ],\n",
       "       [-1.4946775 ,  2.2444637 ],\n",
       "       [ 2.9405801 , -2.8305283 ],\n",
       "       [ 3.2828531 , -3.3022544 ],\n",
       "       [-2.280964  ,  2.9886818 ],\n",
       "       [ 2.684915  , -2.5200324 ],\n",
       "       [-2.0190978 ,  2.9378731 ],\n",
       "       [-2.1919606 ,  3.0551186 ],\n",
       "       [-2.3386178 ,  3.0275483 ],\n",
       "       [ 3.5546687 , -3.497834  ],\n",
       "       [-2.2009168 ,  3.025009  ],\n",
       "       [-2.0970256 ,  2.9560728 ],\n",
       "       [ 3.4101224 , -3.4122596 ],\n",
       "       [-2.093541  ,  2.9200268 ],\n",
       "       [ 3.501353  , -3.4363475 ],\n",
       "       [ 1.6023691 , -1.2652173 ],\n",
       "       [-2.2105541 ,  3.0512311 ],\n",
       "       [ 1.7605892 , -1.3907899 ],\n",
       "       [ 3.046024  , -3.0076199 ],\n",
       "       [ 1.0376935 , -0.65635866],\n",
       "       [-2.2998114 ,  3.0057406 ],\n",
       "       [-2.1448445 ,  2.9533334 ],\n",
       "       [ 2.9634695 , -2.77739   ],\n",
       "       [ 3.3041694 , -3.2757587 ],\n",
       "       [ 3.4877758 , -3.5002046 ],\n",
       "       [-2.3890293 ,  3.1239982 ],\n",
       "       [ 1.7234181 , -1.50767   ],\n",
       "       [ 3.471808  , -3.4476376 ],\n",
       "       [ 2.4346824 , -2.233159  ],\n",
       "       [-2.3572426 ,  3.1098309 ],\n",
       "       [-2.1665654 ,  3.008331  ],\n",
       "       [-2.3521729 ,  3.1195042 ],\n",
       "       [-2.298226  ,  3.1064806 ],\n",
       "       [ 3.4920652 , -3.4526577 ],\n",
       "       [ 3.5671468 , -3.4922307 ],\n",
       "       [-2.279159  ,  3.12286   ],\n",
       "       [ 3.5176244 , -3.4837341 ],\n",
       "       [-2.2652397 ,  3.1116555 ],\n",
       "       [-2.2801566 ,  3.1216252 ],\n",
       "       [-2.1724262 ,  3.0466552 ],\n",
       "       [-2.3089395 ,  3.1099844 ],\n",
       "       [ 2.1778817 , -1.8993647 ],\n",
       "       [-2.2076707 ,  3.0423286 ],\n",
       "       [ 3.412291  , -3.3091097 ],\n",
       "       [ 3.304093  , -3.3932877 ],\n",
       "       [ 2.157641  , -1.7984571 ],\n",
       "       [ 3.5400891 , -3.4925096 ],\n",
       "       [-2.266082  ,  3.1045065 ],\n",
       "       [ 1.8243704 , -1.5440977 ],\n",
       "       [ 3.2213216 , -3.2055888 ],\n",
       "       [ 3.5581937 , -3.428575  ],\n",
       "       [-2.2480383 ,  3.0367723 ],\n",
       "       [-2.2320447 ,  3.060049  ],\n",
       "       [ 3.536851  , -3.4814873 ],\n",
       "       [ 3.2047129 , -3.189919  ]], dtype=float32), label_ids=array([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0], dtype=int64), metrics={'test_loss': 0.7164140343666077, 'test_accuracy': 0.84, 'test_runtime': 310.161, 'test_samples_per_second': 0.967, 'test_steps_per_second': 0.061})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = trainer.predict(test_dataset=test_dataset)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0], dtype=int64),\n",
       " (300,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.label_ids, y_pred.label_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum(y_test == np.array(y_pred.predictions.argmax(axis=-1))) / len(y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
