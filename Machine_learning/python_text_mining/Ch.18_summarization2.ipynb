{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Text mining, also referred to as text data mining (abbr.: TDM), similar to text analytics, \n",
    "        is the process of deriving high-quality information from text. It involves \n",
    "        \"the discovery by computer of new, previously unknown information, \n",
    "        by automatically extracting information from different written resources.\" \n",
    "        Written resources may include websites, books, emails, reviews, and articles. \n",
    "        High-quality information is typically obtained by devising patterns and trends \n",
    "        by means such as statistical pattern learning. According to Hotho et al. (2005)\n",
    "        we can distinguish between three different perspectives of text mining: \n",
    "        information extraction, data mining, and a KDD (Knowledge Discovery in Databases) process.''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Text mining involves deriving high-quality information from text . Written resources may include websites, books, emails, reviews, and articles . Text mining is similar to text analytics . It involves the discovery by computer of new, previously unknown information by automatically extracting information from different written resources .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = summarizer(text)\n",
    "result[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-small', model_max_length=512)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.t5.tokenization_t5_fast.T5TokenizerFast,\n",
       " transformers.models.t5.modeling_t5.T5ForConditionalGeneration)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer), type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text = text.strip().replace('\\n', '')\n",
    "input_text = 'summarize: ' + preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "summary_ids = model.generate(tokenized_text, num_beams=4, no_repeat_ngram_size=3,\n",
    "                             min_length=30, max_length=200, early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text data mining is the process of deriving high-quality information from text. it involves the discovery by computer of new, previously unknown information. a KDD (Knowledge Discovery in Databases) process is similar to text analytics.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[21603,    10,  5027,  5558,     6,    92,     3,  4822,    12,    38,\n",
       "           1499,   331,  5558,    41, 12982,    52,     5,    10,   332,  7407,\n",
       "            201,  1126,    12,  1499,  9952,     6,    19,     8,   433,    13,\n",
       "             20,  5927,    53,   306,    18,  4497,   251,    45,  1499,     5,\n",
       "             94,  5806,    96,   532,  9087,    57,  1218,    13,   126,     6,\n",
       "           3150,  7752,   251,     6,    57,  3269,  5819,    53,   251,    45,\n",
       "            315,  1545,  1438,   535, 22812,  1438,   164,   560,  3395,     6,\n",
       "           1335,     6,  7594,     6,  2456,     6,    11,  2984,     5,  1592,\n",
       "             18,  4497,   251,    19,  3115,  5105,    57, 13282,    53,  4264,\n",
       "             11,  5001,    57,   598,   224,    38, 11775,  3275,  1036,     5,\n",
       "           2150,    12,  1546,   189,    32,     3,    15,    17,   491,     5,\n",
       "              3, 29495,    62,    54, 15849,   344,   386,   315, 14013,    13,\n",
       "           1499,  5558,    10,   251, 16629,     6,   331,  5558,     6,    11,\n",
       "              3,     9,   480, 11253,    41,   439,  7651, 13553, 19499,    16,\n",
       "          20230,     7,    61,   433,     5,     1]]),\n",
       " tensor([[    0,  1499,   331,  5558,    19,     8,   433,    13,    20,  5927,\n",
       "             53,   306,    18,  4497,   251,    45,  1499,     3,     5,    34,\n",
       "           5806,     8,  9087,    57,  1218,    13,   126,     6,  3150,  7752,\n",
       "            251,     3,     5,     3,     9,   480, 11253,    41,   439,  7651,\n",
       "          13553, 19499,    16, 20230,     7,    61,   433,    19,  1126,    12,\n",
       "           1499,  9952,     3,     5,     1]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text, summary_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das ist gut.\n"
     ]
    }
   ],
   "source": [
    "input_text = 'translate english to german: That is good'\n",
    "tokenized_text = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "summary_ids = model.generate(tokenized_text, num_beams=4, no_repeat_ngram_size=3,\n",
    "                             max_length=200, early_stopping=True)\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
