# 연습장(Exercise Book) - 머신러닝/딥러닝 관련
- 코딩관련 새로 학습하는 책 내 코드를 일단 따라하고 연습
- 코딩과 관련이 되어있지 않은 책의 학습한 내용을 README에 기록
- 2022년 8월 이후 언제 무슨 공부를 진행했는지 대략적으로 파악 가능


## 이기적 ADsP 데이터분석 준전문가
### 2022년 8월 11일
1. 데이터 이해: 데이터 이해, 데이터의 가치와 미래, 데이터 사이언스와 전략 인사이트

### 2022년 8월 13일
1. 데이터 분석 기획: 데이터 분석의 이해, 분석 마스터 플랜
2. 데이터 수집과 정제: 빅데이터 수집과 정제, 데이터마트, 결측값 처리와 이상값 탐색
3. 통계 분석: 자료 분석, 표본조사, 기술통계, 추리통계
4. 통계 분석: 통계적 추론, 가설, 통계분석 기법
5. 정형 데이터마이닝(지도학습): 다중회귀분석, KNN, 의사결정나무, 랜덤포레스트, SVM, 나이브베이즈분류, 주성분분석, 신경망

### 2022년 8월 14일
1. 정형 데이터마이닝(비지도학습): K-means, K-medoids, SOM, 연관규칙, 순차적 패턴분석, 텍스트마이닝
2. 데이터마이닝 모델 성능평가: 예측모델 성능평가, 분류모델 성능평가(Confusion Matrix)
3. 빅데이터 시각화: 시간/관계/공간/분포 시각화 등
4. ADsP 예상 모의고사 문제풀이를 통한 이해도 강화(1회, 2회, 3회, 4회, 5회)
5. ADsP 최신 기출복원 문제풀이를 통한 이해도 강화(1회, 2회)

### 2022년 8월 15일
1. ADsP 최신 기출복원 문제풀이를 통한 이해도 강화(3회, 4회, 5회)
2. 문제풀이 재검토를 통한 이해도 강화(모의고사 5회, 기출복원 5회)

### 2022년 10월 22일
1. ADsP 예상 모의고사 문제 풀이를 통한 이해도 강화(1회, 2회, 3회)

### 2022년 10월 23일
1. ADsP 예상 모의고사 문제 풀이를 통한 이해도 강화(4회, 5회)
2. ADsP 최신 기출복원 문제풀이를 통한 이해도 강화(1회, 2회, 3회, 4회, 5회)
3. AdsP 각 파트별 예상문제 풀이를 통한 이해도 강화(데이터 이해, 분석기획, 수집과 정제, 통계분석)

### 2022년 10월 24일
1. AdsP 각 파트별 예상문제 풀이를 통한 이해도 강화(정형 데이터마이닝)
2. 데이터 이해: 데이터 이해, 데이터의 가치와 미래, 데이터 사이언스와 전략 인사이트 복습

### 2022년 10월 25일
1. 데이터 분석 기획: 데이터 분석의 이해, 분석 마스터 플랜 복습

### 2022년 10월 26일
1. 데이터 수집과 정제: 빅데이터 수집과 정제, 데이터마트, 결측값 처리와 이상값 탐색 복습
2. 통계 분석: 자료 분석, 표본조사, 기술통계, 추리통계 복습

### 2022년 10월 27일
1. 통계 분석: 통계적 추론, 가설, 통계분석 기법 복습
2. 정형 데이터마이닝(지도학습): 다중회귀분석, KNN, 의사결정나무, 랜덤포레스트, SVM, 나이브베이즈분류, 주성분분석, 신경망 복습
3. 정형 데이터마이닝(비지도학습): K-means, K-medoids, SOM, 연관규칙, 순차적 패턴분석, 텍스트마이닝 복습
4. 데이터마이닝 모델 성능평가: 예측모델 성능평가, 분류모델 성능평가(Confusion Matrix) 복습


## 최단기 빅데이터 분석기사 필기
### 2022년 8월 16일
1. 빅데이터 이해: 빅데이터 개요, 빅데이터 기술, 빅데이터 제도
2. 데이터 분석 계획(~ing): 분석 방안 수립

### 2022년 8월 17일
1. 데이터 분석 계획: 분석 작업 계획
2. 데이터 수집 및 저장 계획(~ing): 데이터 수집 및 전환, 데이터 적재 및 저장
3. 빅데이터 분석 기획 파트 문제 풀이를 통한 이해도 강화

### 2022년 8월 18일
1. 데이터 전처리: 데이터 정제, 분석 변수 처리
2. 데이터 탐색(~ing): 데이터 탐색 기초

### 2022년 8월 19일
1. 데이터 탐색: 고급 데이터 탐색
2. 통계 기법의 이해: 기술통계, 추론통계
3. 빅데이터 탐색 파트 문제 풀이를 통한 이해도 강화

### 2022년 8월 20일
1. 분석 모형 설계: 분석 모형 구축, 분석 환경 구축
2. 분석 기법: 회귀분석, 분류 모형, 군집 분석, 연관규칙 기법
3. 고급 분석 기법: 고급 통계 분석, 딥러닝(합성곱신경망-CNN, 순환신경망-RNN)
4. 빅데이터 모델링 파트 문제 풀이를 통한 이해도 강화
5. 분석모형 평가 개선: 분석 모형 평가, 분석 모형 개선
6. 분석 결과 해석 및 활용: 분석 결과 해석/시각화/활용
7. 빅데이터 분석 결과 해석 파트 문제 풀이를 통한 이해도 강화
8. 각 파트 연습문제 풀이 복습을 통한 이해도 강화

### 2022년 8월 21일
1. 빅데이터 분석 기획 파트 전반 복습
2. 빅데이터 탐색 파트 전반 복습
3. 빅데이터 모델링 파트 전반 복습
4. 빅데이터 분석 결과 해석 파트 전반 복습
5. 빅데이터 분석 기사 기출문제 풀이를 통한 이해도 강화 - 2회 기출

### 2022년 8월 22일
1. 빅데이터 분석 기사 기출문제 풀이를 통한 이해도 강화 - 3회 기출

### 2022년 8월 23일
1. 빅데이터 분석 기사 기출문제 풀이를 통한 이해도 강화 - 4회 기출

### 2022년 9월 8일
1. 빅데이터 분석 기사 기출문제 세부 복습 진행 - 2회 기출

### 2022년 9월 9일
1. 빅데이터 분석 기사 기출문제 세부 복습 진행 - 3회 기출
2. 빅데이터 분석 기사 기출문제 세부 복습 진행 - 4회 기출
3. 각 단원(분석 기획, 탐색, 모델링, 결과 해석) 연습문제 복습 진행

### 2022년 9월 27일
1. 각 단원(분석 기획, 탐색, 모델링, 결과 해석) 연습문제 복습 진행

### 2022년 9월 28일
1. 빅데이터 분석 기획 파트 복습 : 빅데이터 이해, 데이터 분석/수집/저장 계획
2. 빅데이터 탐색 파트 복습 : 데이터 전처리/탐색, 통계기법의 이해
3. 빅데이터 모델링 파트 복습 : 분석 모형 설계, 분석기법
4. 빅데이터 분석 결과 해석 파트 복습 : 모형 평가 개선, 결과 해석 및 활용

### 2022년 9월 29일
1. 빅데이터 분석 기사 기출문제 풀이를 통한 이해도 강화 - 2회 기출
2. 빅데이터 분석 기사 기출문제 풀이를 통한 이해도 강화 - 3회 기출

### 2022년 9월 30일
1. 빅데이터 분석 기사 기출문제 풀이를 통한 이해도 강화 - 4회 기출

### 2022년 12월 1일
1. 빅데이터 분석 기획 파트 전반 복습
2. 빅데이터 탐색 파트 전반 복습(~ing)

### 2022년 12월 2일
1. 빅데이터 탐색 파트 전반 복습
2. 빅데이터 모델링 파트 전반 복습
3. 빅데이터 분석 결과 해석 파트 전반 복습


## 파이썬 라이브러리를 활용한 머신러닝(2판)
### 2022년 9월 24일
1. Chapter1. 소개 - scikit-learn을 위한 필수 라이브러리 개요
2. Chapter1. 소개 - K-NN을 통한 붓꽃 품종 분류 맛보기
3. Chapter2. 지도학습 - 지도학습 알고리즘에 대한 간략 소개
4. Chapter2. 지도학습 - K-NN 알고리즘(분류, 회귀)에 대한 기본 이해
5. Chapter2. 지도학습 - 선형회귀(Ridge, Lasso 포함)에 대한 기본 이해
6. Chapter2. 지도학습 - 로지스틱회귀 및 SVM에 대한 기본 이해

### 2022년 9월 25일
1. Chapter2. 지도학습 - 의사결정나무(결정트리, Decision Tree)에 대한 기본 이해
2. Chapter2. 지도학습 - 결정트리 앙상블(랜덤포레스트, Gradient Boosting) 기본 이해
3. Chapter2. 지도학습 - 기타 결정트리 앙상블(AdaBoost, 히스토그램 기반 부스팅) 기본 이해
4. Chapter2. 지도학습 - SVM(RBF 커널)에 대한 기본 이해
5. Chapter2. 지도학습 - 신경망(solver='adam', 'lbfgs')에 대한 기본 이해

### 2022년 9월 26일
1. Chapter2. 지도학습 - 분류의 불확실성 추정(predict_proba 등)에 대한 기본 이해

### 2022년 10월 1일
1. Chapter3. 비지도학습 - 데이터 스케일 변환에 대한 기본 이해(PowerTransformer 등)
2. Chapter3. 비지도학습 - 주성분분석(PCA) 기본 이해

### 2022년 10월 2일
1. Chapter3. 비지도학습 - 비음수행렬분해(NMF), 매니폴드학습(t-SNE) 기본 이해
2. Chapter3. 비지도학습 - K-means, 병합군집(AgglomerativeClustering) 기본 이해
3. Chapter3. 비지도학습 - DBSCAN(밀도 기반 클러스터링) 기본 이해
4. Chapter3. 비지도학습 - 군집 알고리즘의 비교와 평가 기본 이해
5. Chapter4. 데이터 표현과 특성공학 - 범주형 변수 다루기(원-핫 인코딩, make_column_transformer 등)
6. Chapter4. 데이터 표현과 특성공학 - 구간 분할, 상호작용과 다항식, 일변량 비선형 변환 등 기본 이해

### 2022년 10월 3일
1. Chapter4. 데이터 표현과 특성공학 - 특성 자동선택 기본 이해
2. Chapter4. 데이터 표현과 특성공학 - 전문가 지식(혹은 상식) 활용 기본 이해
3. Chapter5. 모델 평가와 성능 향상 - 여러가지 교차 검증(Cross Validation) 기본 이해
4. Chapter5. 모델 평가와 성능 향상 - 교차 검증을 활용한 그리드 서치 기본 이해
5. Chapter5. 모델 평가와 성능 향상 - 이진 분류의 평가 지표(혼동 행렬 등) 기본 이해

### 2022년 10월 4일
1. Chapter5. 모델 평가와 성능 향상 - 정밀도-재현율 곡선, ROC Curve 기본 이해
2. Chapter5. 모델 평가와 성능 향상 - 다중 분류 및 회귀의 평가 지표 기본 이해

### 2022년 10월 5일
1. Chapter6. 알고리즘 체인과 파이프라인 - 알고리즘 체인 및 정보누설금지의 중요성 기본 이해
2. Chapter6. 알고리즘 체인과 파이프라인 - 파이프라인과 그리드 서치 활용 기본 이해

### 2022년 10월 6일
1. Chapter6. 알고리즘 체인과 파이프라인 - 전처리와 모델 매개변수를 위한 그리드 서치 활용 기본 이해

### 2022년 10월 8일
1. Chapter7. 텍스트 데이터 다루기 - BOW(bag of words, CountVertorizer) 기본 이해
2. Chapter7. 텍스트 데이터 다루기 - TF-IDF 및 BOW_ngram 기본 이해
3. Chapter7. 텍스트 데이터 다루기 - 고급 토큰화 및 표제어 추출(spacy 등) 기본 이해
4. Chapter7. 텍스트 데이터 다루기 - 한글의 형태소 분석(KoNLPy의 okt) 기본 이해
5. Chapter7. 텍스트 데이터 다루기 - 토픽 모델링과 문서 군집화 기본 이해

### 2022년 10월 9일
1. Chapter1. 소개 - 머신러닝 개괄 이해 및 K-NN을 통한 붓꽃 품종 분류 맛보기
2. Chapter2. 지도학습 - 지도학습 개괄 및 K-NN 알고리즘(분류, 회귀)에 대한 기본 이해
3. Chapter2. 지도학습 - 선형회귀(Ridge, Lasso 포함)에 대한 기본 이해
4. Chapter2. 지도학습 - 로지스틱회귀 및 SVM('C' 파라미터)에 대한 기본 이해
5. Chapter2. 지도학습 - 의사결정나무(결정트리, Decision Tree)에 대한 기본 이해
6. Chapter2. 지도학습 - 결정트리 앙상블(랜덤포레스트, Gradient Boosting) 기본 이해
7. Chapter2. 지도학습 - 기타 결정트리 앙상블(AdaBoost, 히스토그램 기반 부스팅) 기본 이해
8. Chapter2. 지도학습 - SVM(RBF 커널)에 대한 기본 이해

### 2022년 10월 10일
1. Chapter2. 지도학습 - 신경망(solver, hidden_layer_sizes 등)에 대한 기본 이해
2. Chapter2. 지도학습 - 분류의 불확실성 추정(predict_proba 등)에 대한 기본 이해
3. Chapter3. 비지도학습 - 데이터 스케일 변환(svm, 신경망 등에 효과)에 대한 기본 이해
4. Chapter3. 비지도학습 - 주성분분석(PCA) 기본 이해
5. Chapter3. 비지도학습 - 비음수행렬분해(NMF), 매니폴드학습(t-SNE) 기본 이해

### 2022년 10월 11일
1. Chapter3. 비지도학습 - K-means, 병합군집(AgglomerativeClustering) 기본 이해

### 2022년 10월 12일
1. Chapter3. 비지도학습 - DBSCAN(밀도 기반 클러스터링) 기본 이해
2. Chapter3. 비지도학습 - 군집 알고리즘의 비교와 평가 기본 이해

### 2022년 10월 13일
1. Chapter4. 데이터 표현과 특성공학 - 범주형 변수 다루기(원-핫 인코딩, make_column_transformer 등)

### 2022년 10월 14일
1. Chapter4. 데이터 표현과 특성공학 - 구간 분할, 상호작용과 다항식 등 기본 이해

### 2022년 10월 15일
1. Chapter4. 데이터 표현과 특성공학 - 일변량 비선형 변환 및 특성 자동선택 기본 이해
2. Chapter4. 데이터 표현과 특성공학 - 전문가 지식(혹은 상식) 활용 기본 이해
3. Chapter5. 모델 평가와 성능 향상 - 여러가지 교차 검증(Cross Validation) 기본 이해
4. Chapter5. 모델 평가와 성능 향상 - 교차 검증을 활용한 그리드 서치 기본 이해
5. Chapter5. 모델 평가와 성능 향상 - 이진 분류의 평가 지표(혼동 행렬 등) 기본 이해

### 2022년 10월 16일
1. Chapter5. 모델 평가와 성능 향상 - 정밀도-재현율 곡선, ROC Curve, 평가 지표 사용 등 기본 이해
2. Chapter6. 알고리즘 체인과 파이프라인 - 알고리즘 체인 및 파이프라인과 그리드 서치 활용 기본 이해
3. Chapter6. 알고리즘 체인과 파이프라인 - 전처리와 모델 매개변수를 위한 그리드 서치 활용 기본 이해
4. Chapter7. 텍스트 데이터 다루기 - BOW(bag of words, CountVertorizer) 기본 이해
5. Chapter7. 텍스트 데이터 다루기 - TF-IDF 및 BOW_ngram 기본 이해

### 2022년 10월 17일
1. Chapter7. 텍스트 데이터 다루기 - 고급 토큰화 및 표제어 추출(spacy 등) 기본 이해
2. Chapter7. 텍스트 데이터 다루기 - 한글의 형태소 분석(KoNLPy의 okt) 기본 이해

### 2022년 10월 18일
1. Chapter7. 텍스트 데이터 다루기 - 토픽 모델링과 문서 군집화(LDA) 기본 이해

### 2022년 10월 19일
1. 지도학습 추정기 파라미터 파악(각 ipynb 파일 내 주석으로 기재, ~ing)

### 2022년 10월 20일
1. 지도학습 추정기 파라미터 파악(각 ipynb 파일 내 주석으로 기재)
2. 비지도학습 추정기 파라미터 파악(각 ipynb 파일 내 주석으로 기재)

### 2022년 10월 22일
1. 데이터 표현과 특성공학 파라미터 파악(각 ipynb 파일 내 주석으로 기재)
2. 모델 평가와 성능 향상 파라미터 파악(각 ipynb 파일 내 주석으로 기재)
3. 텍스트 데이터 다루기 파라미터 파악(각 ipynb 파일 내 주석으로 기재)
4. 퇴직여부확인 데이터 테이블 분석 연습(EDA, 전처리 수행, 추정기 활용 - 회귀, 분류)

### 2022년 11월 18일
1. Chapter3. 비지도학습 - 데이터 스케일 변환(svm, 신경망 등에 효과)에 대한 기본 이해
2. Chapter3. 비지도학습 - 주성분분석(PCA) 기본 이해

### 2022년 11월 19일
1. Chapter3. 비지도학습 - 비음수행렬분해(NMF), 매니폴드학습(t-SNE) 기본 이해
2. Chapter3. 비지도학습 - K-means 기본 이해
3. Chapter3. 비지도학습 - 병합군집(AgglomerativeClustering), DBSCAN(밀도 기반 클러스터링) 기본 이해
4. Chapter4. 데이터 표현과 특성공학 - 범주형 변수 다루기(원-핫 인코딩, make_column_transformer 등)
5. Chapter4. 데이터 표현과 특성공학 - 구간 분할, 상호작용과 다항식 등 기본 이해

### 2022년 11월 20일
1. Chapter4. 데이터 표현과 특성공학 - 일변량 비선형 변환 및 특성 자동선택 기본 이해
2. Chapter4. 데이터 표현과 특성공학 - 전문가 지식(혹은 상식) 활용 기본 이해
3. Chapter5. 모델 평가와 성능 향상 - 여러가지 교차 검증(Cross Validation) 기본 이해
4. Chapter5. 모델 평가와 성능 향상 - 교차 검증을 활용한 그리드 서치 기본 이해
5. Chapter5. 모델 평가와 성능 향상 - 이진 분류의 평가 지표(혼동 행렬 등) 기본 이해
6. Chapter5. 모델 평가와 성능 향상 - 정밀도-재현율 곡선, ROC Curve, 평가 지표 사용 등 기본 이해

### 2022년 11월 21일
1. Chapter6. 알고리즘 체인과 파이프라인 - 알고리즘 체인 및 파이프라인과 그리드 서치 활용(전처리, 모델 매개변수) 기본 이해

### 2022년 11월 25일
1. Chapter7. 텍스트 데이터 다루기 - BOW(bag of words, CountVertorizer) 기본 이해
2. Chapter7. 텍스트 데이터 다루기 - TF-IDF 및 BOW_ngram 기본 이해

### 2022년 11월 26일
1. Chapter7. 텍스트 데이터 다루기 - 고급 토큰화 및 표제어 추출(spacy 등) 및 한글의 형태소 분석(KoNLPy의 okt) 기본 이해
2. Chapter7. 텍스트 데이터 다루기 - 한글 형태소 분석(spacy-korean) 및 토픽 모델링과 문서 군집화(LDA) 기본 이해
3. Chapter7. 텍스트 데이터 다루기 - 간단 코드확인 복습 진행

### 2023년 11월 20일
1. Chapter.1 소개
2. Chapter.2 지도 학습
    1. Section 2-1. 분류, 회귀, 일반화, 과대적합, 과소적합
    2. Section 2-3. 지도 학습 알고리즘
    3. Section 2-4. 분류 예측의 불확실성 추정

### 2023년 11월 21일
1. Chapter.3 비지도 학습과 데이터 전처리
    1. Section 3-1. 비지도 학습의 종류와 도전 과제
    2. Section 3-3. 데이터 전처리와 스케일 조정
    3. Section 3-4. 차원 축소, 특성 추출, 매니폴드 학습
    4. Section 3-5. 군집

### 2023년 11월 22일
1. Chapter.4 데이터 표현과 특성 공학
    1. Section 4-1. 범주형 변수
    2. Section 4-4. 구간 분할과 이산화
    3. Section 4-5. 상호작용과 다항식
    4. Section 4-6. 일변량 비선형 변환
    5. Section 4-8. 전문가 지식 활용
2. Chapter.5 모델 평가와 성능 향상
    1. Section 5-1. 교차 검증
    2. Section 5-2. 그리드 서치

### 2023년 11월 23일
1. Chapter.5 모델 평가와 성능 향상
    1. Section 5-3. 평가 지표와 측정
2. Chapter.6 알고리즘 체인과 파이프라인
    1. Section 6-2. 파이프라인 구축하기
    2. Section 6-3. 그리드 서치에 파이프라인 적용하기
    3. Section 6-4. 파이프라인 인터페이스
    4. Section 6-5. 전처리와 모델의 매개변수를 위한 그리드 서치

### 2023년 11월 24일
1. Chapter.etc 통계 분석(~ing)

### 2023년 11월 26일
1. Chapter.etc 통계 분석


## ADP, 빅분기 대비 파이썬 끝내기
### 2022년 10월 28일
1. Chapter2. 데이터 핸들링(~ing)

### 2022년 10월 29일
1. Chapter2. 데이터 핸들링_책 보다는 개인 코드 중심으로 학습
2. Chapter3. EDA와 시각화_책 보다는 개인 코드 중심으로 학습
3. Chapter4. 데이터 전처리_책 보다는 개인 코드 중심으로 학습
4. Chapter5. 머신러닝 프로세스_책 보다는 개인 코드 중심으로 학습(~ing)

### 2022년 10월 30일
1. Chapter5. 머신러닝 프로세스_책 보다는 개인 코드 중심으로 학습
2. Chapter6. 머신러닝-지도학습_책 보다는 개인 코드 중심으로 학습(~ing)

### 2022년 10월 31일
1. Chapter6. 머신러닝-지도학습_책 보다는 개인 코드 중심으로 학습(~ing)

### 2022년 11월 1일
1. Chapter6. 머신러닝-지도학습_책 보다는 개인 코드 중심으로 학습(~ing)

### 2022년 11월 2일
1. Chapter6. 머신러닝-지도학습_책 보다는 개인 코드 중심으로 학습

### 2022년 11월 3일
1. Chapter7. 통계분석_책 코드 중심 학습(~ing)

### 2022년 11월 5일
1. Chapter7. 통계분석_책 코드 중심 학습

### 2022년 11월 6일
1. Chapter7. 통계분석-복습 진행_책 코드 중심 학습(~ing)

### 2022년 11월 7일
1. Chapter7. 통계분석-복습 진행_책 코드 중심 학습

### 2022년 11월 8일
1. Chapter2. 데이터 핸들링-복습 진행_책 보다는 개인 코드 중심으로 학습

### 2022년 11월 9일
1. Chapter3. EDA와 시각화-복습 진행_책 보다는 개인 코드 중심으로 학습

### 2022년 11월 10일
1. Chapter4. 데이터 전처리-복습 진행_책 보다는 개인 코드 중심으로 학습

### 2022년 11월 12일
1. Chapter6. 머신러닝 프로세스-복습 진행_책 보다는 개인 코드 중심으로 학습(~ing)

### 2022년 11월 13일
1. Chapter6. 머신러닝 프로세스-복습 진행_책 보다는 개인 코드 중심으로 학습

### 2022년 11월 14일
1. Chapter7. 통계분석-복습 진행_책 코드 중심 학습(~ing)

### 2022년 11월 15일
1. Chapter7. 통계분석-복습 진행_책 코드 중심 학습(~ing)

### 2022년 11월 16일
1. Chapter7. 통계분석-복습 진행_책 코드 중심 학습(~ing)

### 2022년 11월 17일
1. Chapter7. 통계분석-복습 진행_책 코드 중심 학습

### 2022년 11월 22일
1. Chapter7. 통계분석-간단 복습 진행_책 코드 중심 학습

### 2022년 11월 26일
1. Chapter7. 통계분석-간단 복습 진행_책 코드 중심 학습

### 2022년 11월 27일
1. 빅분기 실기 연습 - 빅데이터분석기사 4회 시험 작업형2 구현 연습
2. 빅분기 실기 연습 - 빅데이터분석기사 3회 시험(심화변형) 작업형2 구현 연습
3. 빅분기 실기 연습 - 빅데이터분석기사 심화 문제(전처리 ~ 모델, RandomForest_3) 구현 연습

### 2022년 11월 28일
1. 빅분기 실기 연습 - 빅데이터분석기사 2, 3, 4회 시험 작업형1_4 구현 연습

### 2022년 11월 29일
1. 빅분기 실기 연습 - 빅데이터분석기사 작업형2(서비스 이탈 예측 데이터_5) 구현 연습
2. 빅분기 실기 연습 - 빅데이터분석기사 작업형2(정시 배송 여부 판단 데이터_6) 구현 연습

### 2022년 11월 30일
1. 빅분기 실기 연습 - 빅데이터분석기사 작업형2(성인 건강검진 데이터_7) 구현 연습
2. 빅분기 실기 연습 - 빅데이터분석기사 작업형1(유튜브 인기 동영상 데이터_8) 구현 연습

### 2022년 12월 2일
1. 빅분기 실기 연습 - 빅데이터분석기사 작업형1(유튜브 콘텐츠 동영상 데이터_9) 구현 연습
2. 빅분기 실기 연습 - 시험환경 예제문제(작업형1, 작업형2) 연습


## 김기현의 딥러닝 부트캠프 with 파이토치
### 2023년 3월 12일
1. Chapter 2.1 - 딥러닝이란?
2. Chapter 2.2 - 좋은 인공지능이란?
3. Chapter 2.3 - 머신러닝 프로젝트 워크플로
4. Chapter 3.1 - 왜 파이토치인가? 및 파이토치 설치
5. Chapter 3.3 - 텐서란?
6. Chapter 3.4 - 텐서 기본 연산
7. Chapter 3.5 - 텐서 형태 변환
8. Chapter 3.6 - 텐서 자르기 및 붙이기
9. Chapter 3.7 - 유용한 함수들
10. Chapter 4.1 - 행렬 곱
11. Chapter 4.3 - 선형 계층
12. Chapter 5.1 - 평균제곱오차 및 MSE Loss
13. Chapter 6.1 - 미분이란? 및 편미분

### 2023년 3월 13일
1. Chapter 6.3 - 경사하강법
2. Chapter 6.4 - 학습률에 따른 성질
3. Chapter 6.5 - 경사하강법 구현
4. Chapter 6.6 - 파이토치 오토그래드 소개

### 2023년 3월 14일
1. Chapter 7.1 - 선형 회귀란?
2. Chapter 7.2 - 선형 회귀의 수식
3. Chapter 7.3 - 선형 회귀
4. Chapter 8.1 - 활성 함수
5. Chapter 8.2 - 로지스틱 회귀 및 로지스틱 회귀의 손실 함수
6. Chapter 8.4 - 로지스틱 회귀의 수식

### 2023년 3월 15일
1. Chapter 8.5 - 로지스틱 회귀

### 2023년 3월 17일
1. Chapter 9.1 - 심층신경망 및 심층신경망의 학습
2. Chapter 9.3 - 역전파 알고리즘의 수식
3. Chapter 9.4 - 그래디언트 소실과 ReLU
4. Chapter 9.6 - Deep Regression

### 2023년 3월 18일
1. Chapter 10.1 - 확률적 경사하강법(Stochastic Gradient Descent)이란?
2. Chapter 10.4 - SGD 적용하기
3. Chapter 11.1 - 하이퍼파라미터란?
4. Chapter 11.3 - 적응형 학습률 및 그 수식
5. Chapter 11.5 - 아담 옵티마이저 적용하기
6. Chapter 12.1 - 모델 평가하기와 오버피팅
7. Chapter 12.4 - 데이터 나누기
8. Chapter 13.1 - 이진 분류와 평가 지표

### 2023년 3월 19일
1. Chapter 13.3 - Deep Binary Classification
2. Chapter 13.4 - 심층신경망을 활용한 분류
3. Chapter 13.5 - 소프트맥스 함수와 Cross-Entropy 손실 함수
4. Chapter 13.6 - 다중 클래스 분류 결과 분석하기
5. Chapter 13.7 - Deep Classification
6. Chapter 14.1 - 정규화의 개요
7. Chapter 14.2 - Weight decay
8. Chapter 14.3 - Data Augmentation
9. Chapter 14.4 - Dropout
10. Chapter 14.5 - Batch Normalization
11. Chapter 14.6 - Regularization

### 2023년 3월 21일
1. Chapter 15.1 - 실무를 진행하듯 실습하기
2. Chapter 15.4 - 분류기 모델 구현하기
3. Chapter 15.5 - 데이터 로딩 구현하기
4. Chapter 15.6 - 트레이너 클래스 구현하기

### 2023년 3월 22일
1. Chapter 15.7 - train.py 구현하기
2. Chapter 15.8 - predict.ipynb 구현하기
3. Chapter 16.1 - 특성(Feature)이란?
4. Chapter 16.2 - One-Hot Encoding
5. Chapter 16.3 - 차원 축소: PCA와 Auto Encoder
6. Chapter 17.2 - 기본 확률 통계
7. Chapter 17.4 - 신경망과 MLE
8. Chapter 18.2 - 합성곱 연산
9. Chapter 18.4 - max-pooling 및 stride 기법
10. Chapter 18.6 - CNN으로 MNIST 분류 구현하기
11. Chapter 19.2 - RNN 들여다보기

### 2023년 3월 23일
1. Chapter 19.3 - RNN 활용 사례
2. Chapter 19.4 - LSTM
3. Chapter 19.5 - 그래디언트 클리핑
4. Chapter 19.6 - LSTM으로 MNIST 분류 구현하기

### 2023년 3월 24일
1. Chapter 15.4 - 분류기 모델 구현하기
2. Chapter 15.5 - 데이터 로딩 구현하기
3. Chapter 15.6 - 트레이너 클래스 구현하기
4. Chapter 15.7 - train.py 구현하기
5. Chapter 15.8 - predict.ipynb 구현하기
6. Chapter 18.6 - CNN으로 MNIST 분류 구현하기

### 2023년 3월 25일
1. Chapter 19.6 - LSTM으로 MNIST 분류 구현하기
2. Chapter 2. 딥러닝 소개
3. Chapter 3. 파이토치 튜토리얼
4. Chapter 4. 선형 계층
5. Chapter 5. 손실 함수
6. Chapter 6. 경사하강법
7. Chapter 7. 선형 회귀
8. Chapter 8. 로지스틱 회귀

### 2023년 3월 26일
1. Chapter 9. 심층신경망
2. Chapter 10. 확률적 경사하강법
3. Chapter 11. 최적화
4. Chapter 12. 오버피팅을 방지하는 방법
5. Chapter 13. 심층신경망 II
6. Chapter 14. 정규화(~ing)

### 2023년 3월 27일
1. Chapter 14. 정규화

### 2023년 3월 28일
1. Chapter 15. 실무 환경에서의 프로젝트 연습

### 2023년 3월 29일
1. Chapter 16. 표현 학습
2. Chapter 17. 확률론적 관점

### 2023년 3월 30일
1. Chapter 18. CNN(합성곱신경망)

### 2023년 3월 31일
1. Chapter 19. RNN(순환신경망)

### 2023년 4월 1일
1. Chapter 15. 실무 환경에서의 프로젝트 연습 실습
2. Chapter 18. CNN(합성곱신경망) 실습
3. Chapter 19. RNN(순환신경망) 실습

### 2023년 11월 27일
1. Chapter 2. 딥러닝 소개
2. Chapter 3. 파이토치 튜토리얼
3. Chapter 4. 선형 계층
4. Chapter 5. 손실 함수

### 2023년 11월 28일
1. Chapter 6. 경사하강법
2. Chapter 7. 선형 회귀
3. Chapter 8. 로지스틱 회귀
4. Chapter 9. 심층신경망
5. Chapter 10. 확률적 경사하강법
6. Chapter 11. 최적화
7. Chapter 12. 오버피팅을 방지하는 방법

### 2023년 11월 29일
1. Chapter 13. 심층신경망 II
2. Chapter 14. 정규화(Regularization)
3. Chapter 15. 실무 환경에서의 프로젝트 연습 실습(~ing)

### 2023년 11월 30일
1. Chapter 15. 실무 환경에서의 프로젝트 연습 실습
2. Chapter 16. 표현 학습
3. Chapter 17. 확률론적 관점
4. Chapter 18. CNN(합성곱신경망)

### 2023년 12월 1일
1. Chapter 19. RNN(순환신경망)


## 파이토치로 배우는 자연어 처리 - 이후 부분 추후 진행 예정
### 2023년 4월 2일
1. Chapter 1.1 - 지도학습, 샘플과 타깃의 인코딩, 계산 그래프 등
2. Chapter 1.4 - 파이토치 기초
3. Chapter 2. - NLP기술 빠르게 훑어보기
4. Chapter 3.1 - 퍼셉트론: 가장 간단한 신경망
5. Chapter 3.2 - 활성화 함수
6. Chapter 3.3 - 손실 함수
7. Chapter 3.4 - 지도학습 훈련 알아보기, 부가적인 훈련 개념
8. Chapter 3.6 - 예제: 레스토랑 리뷰 감성 분류하기(~ing)

### 2023년 4월 3일
1. Chapter 3.6 - 예제: 레스토랑 리뷰 감성 분류하기(~ing)

### 2023년 4월 4일
1. Chapter 3.6 - 예제: 레스토랑 리뷰 감성 분류하기

### 2023년 4월 5일
1. Chapter 3.6 - 예제: 레스토랑 리뷰 감성 분류하기 복습(~ing)

### 2023년 4월 6일
1. Chapter 3.6 - 예제: 레스토랑 리뷰 감성 분류하기 복습(~ing)

### 2023년 4월 7일
1. Chapter 3.7 - 예제: 레스토랑 리뷰 감성 분류하기 복습


## The Elements of Statistical Learning 2/e 번역본
### 2023년 7월 27일
1. Chapter.1 - 소개
2. Chapter.2 - 지도학습(supervised learning)의 개요
    1. Section 2-1. 소개
    2. Section 2-2. 변수 타입과 용어
    3. Section 2-3. 예측을 위한 단순한 두 접근: 최소제곱과 최근접이웃
    4. Section 2-4. 통계적 결정 이론
    5. Section 2-5. 고차원에서의 국소적 방법
    6. Section 2-6. 통계적 모델, 지도학습 및 함수 근사
    7. Section 2-7. 구조화된 회귀 모델
    8. Section 2-8. 제한된 추정량의 종류
    9. Section 2-9. 모델 선택과 편향-분산 상반관계
3. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-1. 소개
    2. Section 3-2. 선형회귀모델과 최소제곱
    3. Section 3-3. 부분집합 선택
    4. Section 3-4. 수축법(Ridge, Lasso, etc)

### 2023년 7월 28일
1. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-5. 유도된 입력 방향을 사용하는 방법들
    2. Section 3-6. 논의: 선택법과 수축법 비교
    3. Section 3-8. 라쏘 및 관련된 경로 알고리즘에 관한 내용(~ing)
2. Chapter.4 - 분류를 위한 선형법
    1. Section 4-1. 소개
    2. Section 4-2. 지시행렬의 선형회귀
    3. Section 4-3. 선형판별분석
    4. Section 4-4. 로지스틱회귀
    5. Section 4-5. 분리초평면(Seperating Hyperplanes)
3. Chapter.1 - 소개 복습
4. Chapter.2 - 지도학습(supervised learning)의 개요 복습

### 2023년 7월 29일
1. Chapter.3 - 회귀를 위한 선형법 복습
2. Chapter.4 - 분류를 위한 선형법 복습

### 2023년 7월 30일
1. Chapter.5 - 기저전개와 정칙화
    1. Section 5.1 - 소개
    2. Section 5.2 - 조각별 다항식과 스플라인
    3. Section 5.3 - 필터링과 특성 추출
    4. Section 5.4 - 평활 스플라인
    5. Section 5.5 - 평활화 매개변수의 자동적 선택
    6. Section 5.6 - 비모수적 로지스틱회귀
    7. Section 5.7 - 다차원 스플라인
    8. Section 5.9 - 웨이블릿 평활화
2. Chapter.6 - 커널평활법
    1. Section 6.1 - 1차원 커널 평활자
    2. Section 6.2 - 커널의 너비 선택하기

### 2023년 7월 31일
1. Chapter.6 - 커널평활법
    1. Section 6.3 - R^p에서의 국소 회귀
    2. Section 6.4 - R^p에서의 구조적 국소 회귀모델
    3. Section 6.5 - 국소 가능도 및 다른 모델
    4. Section 6.6 - 커널 밀도 추정 및 분류
    5. Section 6.7 - 방사기저함수와 커널
    6. Section 6.8 - 밀도 추정과 분류를 위한 혼합 모델
2. Chapter.7 - 모델 평가 및 선택
    1. Section 7.1 - 소개
    2. Section 7.2 - 편향, 분산, 모델 복잡도
    3. Section 7.3 - 편향-분산 분해
    4. Section 7.4 - 훈련 오류율에 관한 낙관도
    5. Section 7.5 - 표본 내 예측오차의 추정값
    6. Section 7.6 - 매개변수의 유효 개수
    7. Section 7.7 - 베이즈 접근법과 BIC
    8. Section 7.8 - 최소 설명 길이
    9. Section 7.10 - 교차 검증
    10. Section 7.11 - 부트스트랩법
3. Chapter.8 - 모델 추론과 평균화
    1. Section 8.1 - 소개
    2. Section 8.2 - 부트스트랩과 최대가능도 방법

### 2023년 8월 1일
1. Chapter.8 - 모델 추론과 평균화
    1. Section 8.3 - 베이즈 방법
    2. Section 8.5 - EM 알고리즘
    3. Section 8.6 - 사후분포로부터 표본 추출을 위한 MCMC
    4. Section 8.7 - 배깅
    5. Section 8.8 - 모델 평균화와 스태킹
    6. Section 8.9 - 확률적 검색: 범핑
2. Chapter.5 - 기저전개와 정칙화 복습
3. Chapter.6 - 커널평활법 복습

### 2023년 8월 2일
1. Chapter.7 - 모델 평가 및 선택 복습
2. Chapter.8 - 모델 추론과 평균화 복습
3. Chapter.9 - 가법 모델, 트리 및 관련 방법들
    1. Section 9.1 - 일반화 가법 모델
    2. Section 9.2 - 트리 기반 방법
    3. Section 9.3 - PRIM: 범프 헌팅
    4. Section 9.4 - MARS: 다변량 적응적 회귀 스플라인
    5. Section 9.5 - 전문가 계층 혼합
    6. Section 9.6 - 결측 데이터

### 2023년 8월 3일
1. Chapter.10 - 부스팅과 가법 트리
    1. Section 10.1 - 부스팅법
    2. Section 10.2 - 부스팅 적합과 가법 모델
    3. Section 10.3 - 전진 스테이지별 가법 모델링
    4. Section 10.4 - 지수손실과 에이다부스트
    5. Section 10.5 - 왜 지수손실인가?
    6. Section 10.6 - 손실함수와 로버스트성
    7. Section 10.7 - 데이터마이닝을 위한 기성품 같은 과정
    8. Section 10.8 - 예제: 스팸 데이터
    9. Section 10.9 - 부스팅 트리
    10. Section 10.10 - 경사 부스팅(Gradient Boosting)을 통한 수치적 최적화
    11. Section 10.11 - 부스팅을 위한 적절한 크기의 트리
    12. Section 10.12 - 정칙화
    13. Section 10.13 - 해석
    14. Section 10.14 - 예시 삽화
2. Chapter.11 - 신경망
    1. Section 11.1 - 소개
    2. Section 11.2 - 사영추적회귀
    3. Section 11.3 - 신경망
    4. Section 11.4 - 신경망 적합시키기
    5. Section 11.5 - 신경망을 훈련시킬 때의 문제
    6. Section 11.6 - 예제: 시뮬레이션 데이터/우편번호 데이터
    7. Section 11.8 - 논의
    8. Section 11.9 - 베이즈 신경망과 NIPS 2003 챌린지

### 2023년 8월 4일
1. Chapter.12 - 서포트벡터머신과 유연한 판별식
    1. Section 12.1 - 소개
    2. Section 12.2 - 서포트벡터분류기
    3. Section 12.3 - 서포트벡터머신과 커널
    4. Section 12.4 - 선형판별분석 일반화
    5. Section 12.5 - 유연한 판별분석
    6. Section 12.6 - 벌점화 판별분석
    7. Section 12.7 - 혼합판별분석
2. Chapter.9 - 가법 모델, 트리 및 관련 방법들 복습
3. Chapter.10 - 부스팅과 가법 트리 복습

### 2023년 8월 5일
1. Chapter.11 - 신경망 복습
2. Chapter.12 - 서포트벡터머신과 유연한 판별식 복습
3. Chapter.13 - 프로토타입 방법과 최근접이웃법
    1. Section 13.1 - 소개
    2. Section 13.2 - 프로토타입법
    3. Section 13.3 - K-최근접이웃 분류기
    4. Section 13.4 - 적응적 최근접이웃법

### 2023년 8월 6일
1. Chapter.14 - 비지도 학습
    1. Section 14.1 - 개요
    2. Section 14.2 - 연관성 규칙
    3. Section 14.3 - 군집분석
    4. Section 14.4 - 자기 조직화 맵

### 2023년 8월 7일
1. Chapter.14 - 비지도 학습
    1. Section 14.5 - 주성분, 주곡선과 주표면
    2. Section 14.6 - 비음수 행렬 분해
    3. Section 14.7 - 독립성분분석과 탐색적 사영추적
    4. Section 14.8 - 다차원 척도화
    5. Section 14.9 - 비선형 차원 축소와 국소 다차원 척도화
    6. Section 14.10 - 구글 페이지랭크 알고리즘
2. Chapter.15 - 랜덤 포레스트
    1. Section 15.1 - 소개
    2. Section 15.2 - 랜덤포레스트의 정의
    3. Section 15.3 - 랜덤포레스트의 세부 사항
3. Chapter.16 - 앙상블 학습
    1. Section 16.1 - 소개
    2. Section 16.2 - 부스팅과 정칙화 경로
    3. Section 16.3 - 학습 앙상블

### 2023년 8월 8일
1. Chapter.18 - 고차원 문제: p>>N
    1. Section 18.1 - p가 N보다 훨씬 클 때
    2. Section 18.2 - 대각 선형판별분석과 최근접 수축 중심점
    3. Section 18.3 - 이차 정칙화 선형 분류기
    4. Section 18.4 - L1 정칙화 선형 분류기
    5. Section 18.5 - 특성을 쓸 수 없을 때의 분류
    6. Section 18.6 - 고차원 회귀: 지도 주성분
    7. Section 18.7 - 특성 평가와 다중검정 문제
2. Chapter.13 - 프로토타입 방법과 최근접이웃법 복습
3. Chapter.14 - 비지도 학습 복습(~ing)

### 2023년 8월 9일
1. Chapter.14 - 비지도 학습 복습
2. Chapter.15 - 랜덤 포레스트 복습
3. Chapter.16 - 앙상블 학습 복습
4. Chapter.18 - 고차원 문제: p>>N 복습
5. 기타: Survival Analysis(생존 분석)(~ing)

### 2023년 8월 10일
1. 기타: Survival Analysis(생존 분석)
2. Chapter.1 - 소개
3. Chapter.2 - 지도학습(supervised learning)의 개요
    1. Section 2-1. 소개
    2. Section 2-2. 변수 타입과 용어
    3. Section 2-3. 예측을 위한 단순한 두 접근: 최소제곱과 최근접이웃
    4. Section 2-4. 통계적 결정 이론
    5. Section 2-5. 고차원에서의 국소적 방법
    6. Section 2-6. 통계적 모델, 지도학습 및 함수 근사
    7. Section 2-7. 구조화된 회귀 모델
    8. Section 2-8. 제한된 추정량의 종류
    9. Section 2-9. 모델 선택과 편향-분산 상반관계
4. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-1. 소개
    2. Section 3-2. 선형회귀모델과 최소제곱(~ing)

### 2023년 8월 11일
1. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-2. 선형회귀모델과 최소제곱
    2. Section 3-3. 부분집합 선택
    3. Section 3-4. 수축법(Ridge, Lasso, etc)
    4. Section 3-5. 유도된 입력 방향을 사용하는 방법들
    5. Section 3-6. 논의: 선택법과 수축법 비교
    6. Section 3-8. 라쏘 및 관련된 경로 알고리즘에 관한 내용
2. Chapter.4 - 분류를 위한 선형법
    1. Section 4-1. 소개
    2. Section 4-2. 지시행렬의 선형회귀
    3. Section 4-3. 선형판별분석
    4. Section 4-4. 로지스틱회귀
    5. Section 4-5. 분리초평면(Seperating Hyperplanes)

### 2023년 8월 12일
1. Chapter.5 - 기저전개와 정칙화
    1. Section 5.1 - 소개
    2. Section 5.2 - 조각별 다항식과 스플라인
    3. Section 5.3 - 필터링과 특성 추출
    4. Section 5.4 - 평활 스플라인
    5. Section 5.5 - 평활화 매개변수의 자동적 선택
    6. Section 5.6 - 비모수적 로지스틱회귀
    7. Section 5.7 - 다차원 스플라인
    8. Section 5.9 - 웨이블릿 평활화

### 2023년 8월 13일
1. Chapter.6 - 커널평활법
    1. Section 6.1 - 1차원 커널 평활자
    2. Section 6.2 - 커널의 너비 선택하기
    3. Section 6.3 - R^p에서의 국소 회귀
    4. Section 6.4 - R^p에서의 구조적 국소 회귀모델
    5. Section 6.5 - 국소 가능도 및 다른 모델
    6. Section 6.6 - 커널 밀도 추정 및 분류
    7. Section 6.7 - 방사기저함수와 커널
    8. Section 6.8 - 밀도 추정과 분류를 위한 혼합 모델
2. Chapter.2 - 지도학습(supervised learning)의 개요 복습
3. Chapter.3 - 회귀를 위한 선형법 복습(~ing)

### 2023년 8월 14일
1. Chapter.3 - 회귀를 위한 선형법 복습
2. Chapter.4 - 분류를 위한 선형법 복습
3. Chapter.5 - 기저전개와 정칙화 복습
4. Chapter.6 - 커널평활법 복습

### 2023년 8월 15일
1. Chapter.7 - 모델 평가 및 선택
    1. Section 7.1 - 소개
    2. Section 7.2 - 편향, 분산, 모델 복잡도
    3. Section 7.3 - 편향-분산 분해
    4. Section 7.4 - 훈련 오류율에 관한 낙관도
    5. Section 7.5 - 표본 내 예측오차의 추정값
    6. Section 7.6 - 매개변수의 유효 개수
    7. Section 7.7 - 베이즈 접근법과 BIC
    8. Section 7.8 - 최소 설명 길이
    9. Section 7.10 - 교차 검증
    10. Section 7.11 - 부트스트랩법
2. Chapter.8 - 모델 추론과 평균화
    1. Section 8.1 - 소개
    2. Section 8.2 - 부트스트랩과 최대가능도 방법
    3. Section 8.3 - 베이즈 방법
    4. Section 8.5 - EM 알고리즘
    5. Section 8.6 - 사후분포로부터 표본 추출을 위한 MCMC
    6. Section 8.7 - 배깅
3. Chapter.9 - 가법 모델, 트리 및 관련 방법들
    1. Section 9.1 - 일반화 가법 모델
    2. Section 9.2 - 트리 기반 방법

### 2023년 8월 16일
1. Chapter.9 - 가법 모델, 트리 및 관련 방법들
    1. Section 9.3 - PRIM: 범프 헌팅
    2. Section 9.4 - MARS: 다변량 적응적 회귀 스플라인
    3. Section 9.5 - 전문가 계층 혼합
    4. Section 9.6 - 결측 데이터
2. Chapter.10 - 부스팅과 가법 트리
    1. Section 10.1 - 부스팅법
    2. Section 10.2 - 부스팅 적합과 가법 모델
    3. Section 10.3 - 전진 스테이지별 가법 모델링
    4. Section 10.4 - 지수손실과 에이다부스트
    5. Section 10.5 - 왜 지수손실인가?
    6. Section 10.6 - 손실함수와 로버스트성
    7. Section 10.7 - 데이터마이닝을 위한 기성품 같은 과정
    8. Section 10.8 - 예제: 스팸 데이터
    9. Section 10.9 - 부스팅 트리
    10. Section 10.10 - 경사 부스팅(Gradient Boosting)을 통한 수치적 최적화
    11. Section 10.11 - 부스팅을 위한 적절한 크기의 트리
    12. Section 10.12 - 정칙화
    13. Section 10.13 - 해석
    14. Section 10.14 - 예시 삽화
3. Chapter.11 - 신경망
    1. Section 11.1 - 소개
    2. Section 11.2 - 사영추적회귀
    3. Section 11.3 - 신경망
    4. Section 11.4 - 신경망 적합시키기
    5. Section 11.5 - 신경망을 훈련시킬 때의 문제
    6. Section 11.6 - 예제: 시뮬레이션 데이터/우편번호 데이터
    7. Section 11.8 - 논의
    8. Section 11.9 - 베이즈 신경망과 NIPS 2003 챌린지

### 2023년 8월 17일
1. Chapter.12 - 서포트벡터머신과 유연한 판별식
    1. Section 12.1 - 소개
    2. Section 12.2 - 서포트벡터분류기
    3. Section 12.3 - 서포트벡터머신과 커널
    4. Section 12.4 - 선형판별분석 일반화
    5. Section 12.5 - 유연한 판별분석
    6. Section 12.6 - 벌점화 판별분석
    7. Section 12.7 - 혼합판별분석
2. Chapter.13 - 프로토타입 방법과 최근접이웃법
    1. Section 13.1 - 소개
    2. Section 13.2 - 프로토타입법
    3. Section 13.3 - K-최근접이웃 분류기
    4. Section 13.4 - 적응적 최근접이웃법
3. Chapter.7 - 모델 평가 및 선택 복습
4. Chapter.8 - 모델 추론과 평균화 복습

### 2023년 8월 18일
1. Chapter.9 - 가법 모델, 트리 및 관련 방법들 복습
2. Chapter.10 - 부스팅과 가법 트리 복습
3. Chapter.11 - 신경망 복습
4. Chapter.12 - 서포트벡터머신과 유연한 판별식 복습
5. Chapter.13 - 프로토타입 방법과 최근접이웃법 복습

### 2023년 8월 19일
1. Chpater.14 - 비지도학습
    1. Section 14.1 - 개요
    2. Section 14.2 - 연관성 규칙
    3. Section 14.3 - 군집분석
    4. Section 14.4 - 자기 조직화 맵

### 2023년 8월 20일
1. Chapter.14 - 비지도학습
    1. Section 14.5 - 주성분, 주곡선과 주표면
    2. Section 14.6 - 비음수 행렬 분해
    3. Section 14.7 - 독립성분분석과 탐색적 사영추적
    4. Section 14.8 - 다차원 척도화
    5. Section 14.9 - 비선형 차원 축소와 국소 다차원 척도화
    6. Section 14.10 - 구글 페이지랭크 알고리즘
2. Chapter.15 - 랜덤 포레스트
    1. Section 15.1 - 소개
    2. Section 15.2 - 랜덤포레스트의 정의
    3. Section 15.3 - 랜덤포레스트의 세부 사항

### 2023년 8월 21일
1. Chapter.16 - 앙상블 학습
    1. Section 16.1 - 소개
    2. Section 16.2 - 부스팅과 정칙화 경로
    3. Section 16.3 - 학습 앙상블
2. Chapter.18 - 고차원 문제: p>>N
    1. Section 18.1 - p가 N보다 훨씬 클 때
    2. Section 18.2 - 대각 선형판별분석과 최근접 수축 중심점
    3. Section 18.3 - 이차 정칙화 선형 분류기
    4. Section 18.4 - L1 정칙화 선형 분류기
    5. Section 18.5 - 특성을 쓸 수 없을 때의 분류
    6. Section 18.6 - 고차원 회귀: 지도 주성분
    7. Section 18.7 - 특성 평가와 다중검정 문제
3. Chapter.14 - 비지도학습 복습(~ing)

### 2023년 8월 22일
1. Chapter.14 - 비지도학습 복습
2. Chapter.15 - 랜덤 포레스트 복습
3. Chapter.16 - 앙상블 학습 복습
4. Chapter.18 - 고차원 문제: p>>N 복습

### 2023년 8월 23일
1. 기타: Survival Analysis(생존 분석)

### 2023년 9월 30일
1. Chapter.1 - 소개
2. Chapter.2 - 지도학습(supervised learning)의 개요
    1. Section 2-1. 소개
    2. Section 2-2. 변수 타입과 용어
    3. Section 2-3. 예측을 위한 단순한 두 접근: 최소제곱과 최근접이웃

### 2023년 10월 1일
1. Chapter.2 - 지도학습(supervised learning)의 개요
    1. Section 2-4. 통계적 결정 이론
    2. Section 2-5. 고차원에서의 국소적 방법
    3. Section 2-6. 통계적 모델, 지도학습 및 함수 근사
    4. Section 2-7. 구조화된 회귀 모델
    5. Section 2-8. 제한된 추정량의 종류
    6. Section 2-9. 모델 선택과 편향-분산 상반관계
2. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-1. 소개
    2. Section 3-2. 선형회귀모델과 최소제곱
    3. Section 3-3. 부분집합 선택
    4. Section 3-4. 수축법(Ridge, Lasso, etc) (~ing)

### 2023년 10월 2일
1. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-4. 수축법(Ridge, Lasso, etc)
    2. Section 3-5. 유도된 입력 방향을 사용하는 방법들
    3. Section 3-6. 논의: 선택법과 수축법 비교
    6. Section 3-8. 라쏘 및 관련된 경로 알고리즘에 관한 내용
2. Chapter.4 - 분류를 위한 선형법
    1. Section 4-1. 소개
    2. Section 4-2. 지시행렬의 선형회귀
    3. Section 4-3. 선형판별분석
    4. Section 4-4. 로지스틱회귀
    5. Section 4-5. 분리초평면(Seperating Hyperplanes)
3. Chapter.5 - 기저전개와 정칙화
    1. Section 5.1 - 소개
    2. Section 5.2 - 조각별 다항식과 스플라인
    3. Section 5.3 - 필터링과 특성 추출
    4. Section 5.4 - 평활 스플라인
    5. Section 5.5 - 평활화 매개변수의 자동적 선택
    6. Section 5.6 - 비모수적 로지스틱회귀
    7. Section 5.7 - 다차원 스플라인
    8. Section 5.9 - 웨이블릿 평활화

### 2023년 10월 3일
1. Chapter.6 - 커널평활법
    1. Section 6.1 - 1차원 커널 평활자
    2. Section 6.2 - 커널의 너비 선택하기
    3. Section 6.3 - R^p에서의 국소 회귀
    4. Section 6.4 - R^p에서의 구조적 국소 회귀모델
    5. Section 6.5 - 국소 가능도 및 다른 모델
    6. Section 6.6 - 커널 밀도 추정 및 분류
    7. Section 6.7 - 방사기저함수와 커널
    8. Section 6.8 - 밀도 추정과 분류를 위한 혼합 모델
2. Chapter.7 - 모델 평가 및 선택
    1. Section 7.1 - 소개
    2. Section 7.2 - 편향, 분산, 모델 복잡도
    3. Section 7.3 - 편향-분산 분해
    4. Section 7.4 - 훈련 오류율에 관한 낙관도
    5. Section 7.5 - 표본 내 예측오차의 추정값
    6. Section 7.6 - 매개변수의 유효 개수
    7. Section 7.7 - 베이즈 접근법과 BIC
    8. Section 7.8 - 최소 설명 길이
    9. Section 7.10 - 교차 검증
    10. Section 7.11 - 부트스트랩법

### 2023년 10월 4일
1. Chapter.8 - 모델 추론과 평균화
    1. Section 8.1 - 소개
    2. Section 8.2 - 부트스트랩과 최대가능도 방법
    3. Section 8.3 - 베이즈 방법
    4. Section 8.5 - EM 알고리즘
    5. Section 8.6 - 사후분포로부터 표본 추출을 위한 MCMC
    6. Section 8.7 - 배깅
    7. Section 8.8 - 모델 평균화와 스태킹
    8. Section 8.9 - 확률적 검색: 범핑
2. Chapter.9 - 가법 모델, 트리 및 관련 방법들
    1. Section 9.1 - 일반화 가법 모델
    2. Section 9.2 - 트리 기반 방법
    3. Section 9.3 - PRIM: 범프 헌팅
    4. Section 9.4 - MARS: 다변량 적응적 회귀 스플라인
    5. Section 9.5 - 전문가 계층 혼합
    6. Section 9.6 - 결측 데이터

### 2023년 10월 5일
1. Chapter.10 - 부스팅과 가법 트리
    1. Section 10.1 - 부스팅법
    2. Section 10.2 - 부스팅 적합과 가법 모델
    3. Section 10.3 - 전진 스테이지별 가법 모델링
    4. Section 10.4 - 지수손실과 에이다부스트
    5. Section 10.5 - 왜 지수손실인가?
    6. Section 10.6 - 손실함수와 로버스트성
    7. Section 10.7 - 데이터마이닝을 위한 기성품 같은 과정
    8. Section 10.8 - 예제: 스팸 데이터
    9. Section 10.9 - 부스팅 트리
    10. Section 10.10 - 경사 부스팅(Gradient Boosting)을 통한 수치적 최적화
    11. Section 10.11 - 부스팅을 위한 적절한 크기의 트리
    12. Section 10.12 - 정칙화
    13. Section 10.13 - 해석
    14. Section 10.14 - 예시 삽화
2. Chapter.11 - 신경망
    1. Section 11.1 - 소개
    2. Section 11.2 - 사영추적회귀
    3. Section 11.3 - 신경망
    4. Section 11.4 - 신경망 적합시키기
    5. Section 11.5 - 신경망을 훈련시킬 때의 문제
    6. Section 11.6 - 예제: 시뮬레이션 데이터/우편번호 데이터
    7. Section 11.8 - 논의
    8. Section 11.9 - 베이즈 신경망과 NIPS 2003 챌린지
3. Chapter.12 - 서포트벡터머신과 유연한 판별식
    1. Section 12.1 - 소개
    2. Section 12.2 - 서포트벡터분류기
    3. Section 12.3 - 서포트벡터머신과 커널
    4. Section 12.4 - 선형판별분석 일반화
    5. Section 12.5 - 유연한 판별분석
    6. Section 12.6 - 벌점화 판별분석
    7. Section 12.7 - 혼합판별분석

### 2023년 10월 6일
1. Chapter.13 - 프로토타입 방법과 최근접이웃법
    1. Section 13.1 - 소개
    2. Section 13.2 - 프로토타입법
    3. Section 13.3 - K-최근접이웃 분류기
    4. Section 13.4 - 적응적 최근접이웃법
2. Chapter.14 - 비지도학습
    1. Section 14.1 - 개요
    2. Section 14.2 - 연관성 규칙
    3. Section 14.3 - 군집분석
    4. Section 14.4 - 자기 조직화 맵
    5. Section 14.5 - 주성분, 주곡선과 주표면
    6. Section 14.6 - 비음수 행렬 분해
    7. Section 14.7 - 독립성분분석과 탐색적 사영추적
    8. Section 14.8 - 다차원 척도화

### 2023년 10월 7일
1. Chapter.14 - 비지도학습
    1. Section 14.9 - 비선형 차원 축소와 국소 다차원 척도화
    2. Section 14.10 - 구글 페이지랭크 알고리즘
2. Chapter.15 - 랜덤 포레스트
    1. Section 15.1 - 소개
    2. Section 15.2 - 랜덤포레스트의 정의
    3. Section 15.3 - 랜덤포레스트의 세부 사항
3. Chapter.16 - 앙상블 학습
    1. Section 16.1 - 소개
    2. Section 16.2 - 부스팅과 정칙화 경로
    3. Section 16.3 - 학습 앙상블

### 2023년 10월 8일
1. Chapter.18 - 고차원 문제: p>>N
    1. Section 18.1 - p가 N보다 훨씬 클 때
    2. Section 18.2 - 대각 선형판별분석과 최근접 수축 중심점
    3. Section 18.3 - 이차 정칙화 선형 분류기
    4. Section 18.4 - L1 정칙화 선형 분류기
    5. Section 18.5 - 특성을 쓸 수 없을 때의 분류
    6. Section 18.6 - 고차원 회귀: 지도 주성분
    7. Section 18.7 - 특성 평가와 다중검정 문제

### 2023년 10월 12일
1. Chapter.2 - 지도학습(supervised learning)의 개요 복습
2. Chapter.3 - 회귀를 위한 선형법 복습
3. Chapter.4 - 분류를 위한 선형법 복습
4. Chapter.5 - 기저전개와 정칙화 복습(~ing)

### 2023년 10월 13일
1. Chapter.5 - 기저전개와 정칙화 복습
2. Chapter.6 - 커널평활법 복습
3. Chapter.7 - 모델 평가 및 선택 복습
4. Chapter.8 - 모델 추론과 평균화 복습

### 2023년 10월 14일
1. Chapter.9 - 가법 모델, 트리 및 관련 방법들 복습
2. Chapter.10 - 부스팅과 가법 트리 복습
3. Chapter.11 - 신경망 복습

### 2023년 10월 15일
1. Chapter.12 - 서포트벡터머신과 유연한 판별식 복습
2. Chapter.13 - 프로토타입 방법과 최근접이웃법

### 2023년 10월 17일
1. Chapter.14 - 비지도학습 복습
    1. Section 14.1 - 개요
    2. Section 14.2 - 연관성 규칙
    3. Section 14.3 - 군집분석
    4. Section 14.4 - 자기 조직화 맵
    5. Section 14.5 - 주성분, 주곡선과 주표면
    6. Section 14.6 - 비음수 행렬 분해
    7. Section 14.7 - 독립성분분석과 탐색적 사영추적
    8. Section 14.8 - 다차원 척도화
    9. Section 14.9 - 비선형 차원 축소와 국소 다차원 척도화
    10. Section 14.10 - 구글 페이지랭크 알고리즘

### 2023년 10월 18일
1. Chapter.15 - 랜덤 포레스트 복습
2. Chapter.16 - 앙상블 학습 복습
3. Chapter.18 - 고차원 문제: p>>N 복습
4. Chapter.etc - Survival Analysis 복습

### 2024년 3월 2일
1. Chapter.1 - 소개
2. Chapter.2 - 지도학습(supervised learning)의 개요
    1. Section 2-1. 소개
    2. Section 2-2. 변수 타입과 용어
    3. Section 2-3. 예측을 위한 단순한 두 접근: 최소제곱과 최근접이웃
    4. Section 2-4. 통계적 결정 이론
    5. Section 2-5. 고차원에서의 국소적 방법
    6. Section 2-6. 통계적 모델, 지도학습 및 함수 근사
    7. Section 2-7. 구조화된 회귀 모델
    8. Section 2-8. 제한된 추정량의 종류
    9. Section 2-9. 모델 선택과 편향-분산 상반관계
3. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-1. 소개
    2. Section 3-2. 선형회귀모델과 최소제곱

### 2024년 3월 3일
1. Chapter.3 - 회귀를 위한 선형법
    1. Section 3-3. 부분집합 선택
    2. Section 3-4. 수축법(Ridge, Lasso, etc)
    3. Section 3-5. 유도된 입력 방향을 사용하는 방법들
    4. Section 3-5. 유도된 입력 방향을 사용하는 방법들
    5. Section 3-6. 논의: 선택법과 수축법 비교
    6. Section 3-8. 라쏘 및 관련된 경로 알고리즘에 관한 내용
2. Chapter.4 - 분류를 위한 선형법
    1. Section 4-1. 소개
    2. Section 4-2. 지시행렬의 선형회귀
    3. Section 4-3. 선형판별분석
    4. Section 4-4. 로지스틱회귀
    5. Section 4-5. 분리초평면(Seperating Hyperplanes)
3. Chapter.5 - 기저전개와 정칙화
    1. Section 5.1 - 소개
    2. Section 5.2 - 조각별 다항식과 스플라인
    3. Section 5.3 - 필터링과 특성 추출
    4. Section 5.4 - 평활 스플라인
    5. Section 5.5 - 평활화 매개변수의 자동적 선택
    6. Section 5.6 - 비모수적 로지스틱회귀
    7. Section 5.7 - 다차원 스플라인
    8. Section 5.9 - 웨이블릿 평활화

### 2024년 3월 4일
1. Chapter.6 - 커널평활법
    1. Section 6.1 - 1차원 커널 평활자
    2. Section 6.2 - 커널의 너비 선택하기
    3. Section 6.3 - R^p에서의 국소 회귀
    4. Section 6.4 - R^p에서의 구조적 국소 회귀모델

### 2024년 3월 5일
1. Chapter.6 - 커널평활법
    1. Section 6.5 - 국소 가능도 및 다른 모델
    2. Section 6.6 - 커널 밀도 추정 및 분류
    3. Section 6.7 - 방사기저함수와 커널
    4. Section 6.8 - 밀도 추정과 분류를 위한 혼합 모델

### 2024년 3월 7일
1. Chapter.7 - 모델 평가 및 선택
    1. Section 7.1 - 소개
    2. Section 7.2 - 편향, 분산, 모델 복잡도
    3. Section 7.3 - 편향-분산 분해
    4. Section 7.4 - 훈련 오류율에 관한 낙관도
    5. Section 7.5 - 표본 내 예측오차의 추정값
    6. Section 7.6 - 매개변수의 유효 개수
    7. Section 7.7 - 베이즈 접근법과 BIC
    8. Section 7.8 - 최소 설명 길이
    9. Section 7.10 - 교차 검증
    10. Section 7.11 - 부트스트랩법
2. Chapter.8 - 모델 추론과 평균화
    1. Section 8.1 - 소개
    2. Section 8.2 - 부트스트랩과 최대가능도 방법
    3. Section 8.3 - 베이즈 방법

### 2024년 3월 8일
1. Chapter.8 - 모델 추론과 평균화
    1. Section 8.5 - EM 알고리즘
    2. Section 8.6 - 사후분포로부터 표본 추출을 위한 MCMC
    3. Section 8.7 - 배깅
    4. Section 8.8 - 모델 평균화와 스태킹
    5. Section 8.9 - 확률적 검색: 범핑
2. Chapter.9 - 가법 모델, 트리 및 관련 방법들
    1. Section 9.1 - 일반화 가법 모델
    2. Section 9.2 - 트리 기반 방법
    3. Section 9.3 - PRIM: 범프 헌팅

### 2024년 3월 9일
1. Chapter.9 - 가법 모델, 트리 및 관련 방법들
    1. Section 9.4 - MARS: 다변량 적응적 회귀 스플라인
    2. Section 9.5 - 전문가 계층 혼합
    3. Section 9.6 - 결측 데이터
2. Chapter.10 - 부스팅과 가법 트리
    1. Section 10.1 - 부스팅법
    2. Section 10.2 - 부스팅 적합과 가법 모델
    3. Section 10.3 - 전진 스테이지별 가법 모델링
    4. Section 10.4 - 지수손실과 에이다부스트
    5. Section 10.5 - 왜 지수손실인가?
    6. Section 10.6 - 손실함수와 로버스트성
    7. Section 10.7 - 데이터마이닝을 위한 기성품 같은 과정
    8. Section 10.8 - 예제: 스팸 데이터
    9. Section 10.9 - 부스팅 트리
    10. Section 10.10 - 경사 부스팅(Gradient Boosting)을 통한 수치적 최적화
    11. Section 10.11 - 부스팅을 위한 적절한 크기의 트리
    12. Section 10.12 - 정칙화
    13. Section 10.13 - 해석
    14. Section 10.14 - 예시 삽화

### 2024년 3월 10일
1. Chapter.11 - 신경망
    1. Section 11.1 - 소개
    2. Section 11.2 - 사영추적회귀
    3. Section 11.3 - 신경망
    4. Section 11.4 - 신경망 적합시키기
    5. Section 11.5 - 신경망을 훈련시킬 때의 문제
    6. Section 11.6 - 예제: 시뮬레이션 데이터/우편번호 데이터
    7. Section 11.8 - 논의
    8. Section 11.9 - 베이즈 신경망과 NIPS 2003 챌린지
2. Chapter.12 - 서포트벡터머신과 유연한 판별식
    1. Section 12.1 - 소개
    2. Section 12.2 - 서포트벡터분류기
    3. Section 12.3 - 서포트벡터머신과 커널
    4. Section 12.4 - 선형판별분석 일반화
    5. Section 12.5 - 유연한 판별분석
    6. Section 12.6 - 벌점화 판별분석
    7. Section 12.7 - 혼합판별분석
3. Chapter.13 - 프로토타입 방법과 최근접이웃법
    1. Section 13.1 - 소개
    2. Section 13.2 - 프로토타입법
    3. Section 13.3 - K-최근접이웃 분류기
    4. Section 13.4 - 적응적 최근접이웃법

### 2024년 3월 11일
1. Chapter.14 - 비지도학습
    1. Section 14.1 - 개요
    2. Section 14.2 - 연관성 규칙
    3. Section 14.3 - 군집분석(~ing)

### 2024년 3월 12일
1. Chapter.14 - 비지도학습
    1. Section 14.3 - 군집분석
    2. Section 14.4 - 자기 조직화 맵

### 2024년 3월 13일
1. Chapter.14 - 비지도학습
    1. Section 14.5 - 주성분, 주곡선과 주표면
    2. Section 14.6 - 비음수 행렬 분해

### 2024년 3월 14일
1. Chapter.14 - 비지도학습
    1. Section 14.7 - 독립성분분석과 탐색적 사영추적
    2. Section 14.8 - 다차원 척도화
    3. Section 14.9 - 비선형 차원 축소와 국소 다차원 척도화
    4. Section 14.10 - 구글 페이지랭크 알고리즘

### 2024년 3월 15일
1. Chapter.15 - 랜덤 포레스트
    1. Section 15.1 - 소개
    2. Section 15.2 - 랜덤포레스트의 정의
    3. Section 15.3 - 랜덤포레스트의 세부 사항
2. Chapter.16 - 앙상블 학습
    1. Section 16.1 - 소개
    2. Section 16.2 - 부스팅과 정칙화 경로
    3. Section 16.3 - 학습 앙상블

### 2024년 3월 16일
1. Chapter.18 - 고차원 문제: p>>N
    1. Section 18.1 - p가 N보다 훨씬 클 때
    2. Section 18.2 - 대각 선형판별분석과 최근접 수축 중심점
    3. Section 18.3 - 이차 정칙화 선형 분류기
    4. Section 18.4 - L1 정칙화 선형 분류기
    5. Section 18.5 - 특성을 쓸 수 없을 때의 분류
    6. Section 18.6 - 고차원 회귀: 지도 주성분


## 파이썬 텍스트 마이닝 완벽 가이드
### 2023년 10월 30일
1. Chapter.1 - 텍스트 마이닝 기초
    1. Section 1.1 - 텍스트 마이닝의 정의
    2. Section 1.2 - 텍스트 마이닝 패러다임의 변화
    3. Section 1.3 - 텍스트 마이닝에 필요한 지식과 도구
    4. Section 1.4 - 텍스트 마이닝의 주요 적용 분야
2. Chapter.2 - 텍스트 전처리
    1. Section 2.1 - 텍스트 전처리의 개념
    2. Section 2.2 - 토큰화
    3. Section 2.3 - 정규화
    4. Section 2.4 - 품사 태깅
3. Chapter.3 - 그래프와 워드 클라우드
    1. Section 3.1 - 단어 빈도 그래프
    2. Section 3.2 - 워드 클라우드로 내용 한 눈에 보기
4. Chapter.4 - 카운트 기반의 문서 표현
    1. Section 4.1 - 카운트 기반 문서 표현의 개념
    2. Section 4.2 - BOW 기반의 카운트 벡터 생성
    3. Section 4.3 - 사이킷런으로 카운트 벡터 생성
    4. Section 4.4 - 한국어 텍스트의 카운트 벡터 변환
    5. Section 4.5 - 카운트 벡터의 활용
    6. Section 4.6 - TF-IDF로 성능 높이기

### 2023년 10월 31일
1. Chapter.5 - BOW 기반의 문서 분류
    1. Section 5.1 - 뉴스그룹 데이터 준비 및 특성 추출
    2. Section 5.2 - 머신러닝과 문서 분류 과정에 대한 이해
    3. Section 5.3 - 나이브 베이즈 분류기를 이용한 문서 분류
    4. Section 5.4 - 로지스텍 회귀를 이용한 문서 분류
    5. Section 5.5 - 결정트리 등을 이용한 문서 분류
    6. Section 5.6 - 성능을 높이는 방법
    7. Section 5.7 - 카운트 기반의 문제점과 N-gram을 이용한 보완
    8. Section 5.8 - 한국어 문서의 분류
2. Chapter.6 - 차원 축소
    1. Section 6.1 - 차원의 저주와 차원 축소의 이유
    2. Section 6.2 - PCA를 이용한 차원 축소
    3. Section 6.3 - LSA를 이용한 차원 축소와 의미 파악
    4. Section 6.4 - tSNE를 이용한 시각화와 차원 축소의 효과
3. Chapter.7 - 토픽 모델링으로 주제 찾기
    1. Section 7.1 - 토픽 모델링과 LDA의 이해
    2. Section 7.2 - 사이킷런을 이용한 토픽 모델링
    3. Section 7.3 - Gensim을 이용한 토픽 모델링

### 2023년 11월 1일
1. Chapter.7 - 토픽 모델링으로 주제 찾기
    1. Section 7.4 - 토픽 트렌드로 시간에 따른 주제 변화 알아내기
    2. Section 7.5 - 동적 토픽 모델링
2. Chapter.8 - 감성 분석
    1. Section 8.1 - 감성 분석의 이해
    2. Section 8.2 - 감성 사전을 이용한 영화 리뷰 감성 분석
    3. Section 8.3 - 학습을 통한 머신러닝 기반의 감성 분석
3. Chapter.9 - 인공신경망과 딥러닝의 이해
    1. Section 9.1 - 인공신경망의 이해
    2. Section 9.2 - 딥러닝의 이해
4. Chapter.10 - RNN, 딥러닝을 이용한 문서 분류
    1. Section 10.1 - 왜 RNN일까?
    2. Section 10.2 - 워드 임베딩의 이해
    3. Section 10.3 - RNN을 이용한 문서 분류
    4. Section 10.4 - LSTM 등을 이용한 성능 개선
5. Chapter.11 - Word2Vec, ELMo, Doc2Vec의 이해
    1. Section 11.1 - Word2Vec - 대표적인 워드 임베딩 기법

### 2023년 11월 2일
1. Chapter.11 - Word2Vec, ELMo, Doc2Vec의 이해
    1. Section 11.2 - ELMo - 문맥에 따른 단어 의미의 구분
    2. Section 11.3 - Doc2Vec - 문맥을 고려한 문서 임베딩
2. Chapter.12 - 이미지 분류를 응용한 문서 분류
    1. Section 12.1 - CNN의 등장과 작동 원리
    2. Section 12.2 - CNN을 이용한 문서 분류
3. Chapter.13 - 어텐션(Attention)과 트랜스포머
    1. Section 13.1 - Seq2Seq - 번역에서 시작된 딥러닝 기법
    2. Section 13.2 - 어텐션을 이용한 성능의 향상
    3. Section 13.3 - 셀프 어텐션과 트랜스포머
4. Chapter.14 - BERT의 이해와 간단한 활용
    1. Section 14.1 - 왜 언어 모델이 중요한가?
    2. Section 14.2 - 사전학습 언어모델의 이론적 이해
    3. Section 14.3 - BERT의 구조
    4. Section 14.4 - 언어모델을 이용한 사전학습과 미세조정학습
    5. Section 14.5 - 사전학습된 BERT 모형의 직접 사용 방법
    6. Section 14.6 - 자동 클래스를 이용한 토크나이저와 모형의 사용
5. Chapter.15 - BERT 사전학습 모형에 대한 미세조정 학습
    1. Section 15.1 - BERT 학습을 위한 전처리
    2. Section 15.2 - 트랜스포머의 트레이너를 이용한 미세조정 학습
    3. Section 15.3 - 파이토치를 활용한 미세조정 학습
6. Chapter.16 - 한국어 문서에 대한 BERT 활용
    1. Section 16.1 - 다중 언어 BERT 사전학습 모형의 미세조정 학습

### 2023년 11월 3일
1. Chapter.16 - 한국어 문서에 대한 BERT 활용
    1. Section 16.2 - KoBERT 사전학습 모형에 대한 파이토치 미세조정 학습
2. Chapter.17 - 트랜스포머 변형 모형의 현황
    1. Section 17.1 - 트랜스포머 변형 모형의 다양한 토크나이저
    2. Section 17.2 - GPT 기반 트랜스포머 변형 모형
    3. Section 17.3 - BERT 기반 트랜스포머 변형 모형
    4. Section 17.4 - 인코더와 디코더를 모두 사용하는 트랜스포머 변형 모형
3. Chapter.18 - 트랜스포머 모형을 이용한 문서 요약
    1. Section 18.1 - 문서 요약의 이해
    2. Section 18.2 - 파이프라인을 이용한 문서 요약
    3. Section 18.3 - T5 모형과 자동 클래스를 이용한 문서 요약
    4. Section 18.4 - T5 모형과 트레이너를 이용한 미세조정 학습
    5. Section 18.5 - 한글 문서 요약
4. Chapter.19 - 트랜스포머 모형을 이용한 질의 응답
    1. Section 19.1 - 질의 응답 시스템의 이해
    2. Section 19.2 - 파이프라인을 이용한 질의 응답
    3. Section 19.3 - 자동 클래스를 이용한 질의 응답
    4. Section 19.4 - 트레이너를 이용한 질의 응답 미세조정 학습
    5. Section 19.5 - 한글 질의 응답

### 2023년 11월 4일
1. Chapter.1 - 텍스트 마이닝 기초
    1. Section 1.1 - 텍스트 마이닝의 정의
    2. Section 1.2 - 텍스트 마이닝 패러다임의 변화
    3. Section 1.3 - 텍스트 마이닝에 필요한 지식과 도구
    4. Section 1.4 - 텍스트 마이닝의 주요 적용 분야
2. Chapter.2 - 텍스트 전처리
    1. Section 2.1 - 텍스트 전처리의 개념
    2. Section 2.2 - 토큰화
    3. Section 2.3 - 정규화
    4. Section 2.4 - 품사 태깅
3. Chapter.3 - 그래프와 워드 클라우드
    1. Section 3.1 - 단어 빈도 그래프
    2. Section 3.2 - 워드 클라우드로 내용 한 눈에 보기
    3. Section 3.3 - 한국어 문서에 대한 그래프와 워드 클라우드
4. Chapter.4 - 카운트 기반의 문서 표현
    1. Section 4.1 - 카운트 기반 문서 표현의 개념
    2. Section 4.2 - BOW 기반의 카운트 벡터 생성
    3. Section 4.3 - 사이킷런으로 카운트 벡터 생성
    4. Section 4.4 - 한국어 텍스트의 카운트 벡터 변환

### 2023년 11월 5일
1. Chapter.4 - 카운트 기반의 문서 표현
    1. Section 4.5 - 카운트 벡터의 활용
    2. Section 4.6 - TF-IDF로 성능 높이기
2. Chapter.5 - BOW 기반의 문서 분류
    1. Section 5.1 - 뉴스그룹 데이터 준비 및 특성 추출
    2. Section 5.2 - 머신러닝과 문서 분류 과정에 대한 이해
    3. Section 5.3 - 나이브 베이즈 분류기를 이용한 문서 분류
    4. Section 5.4 - 로지스텍 회귀를 이용한 문서 분류
    5. Section 5.5 - 결정트리 등을 이용한 문서 분류
    6. Section 5.6 - 성능을 높이는 방법
    7. Section 5.7 - 카운트 기반의 문제점과 N-gram을 이용한 보완
    8. Section 5.8 - 한국어 문서의 분류
3. Chapter.6 - 차원 축소
    1. Section 6.1 - 차원의 저주와 차원 축소의 이유
    2. Section 6.2 - PCA를 이용한 차원 축소
    3. Section 6.3 - LSA를 이용한 차원 축소와 의미 파악
    4. Section 6.4 - tSNE를 이용한 시각화와 차원 축소의 효과

### 2023년 11월 6일
1. Chapter.7 - 토픽 모델링으로 주제 찾기
    1. Section 7.1 - 토픽 모델링과 LDA의 이해
    2. Section 7.2 - 사이킷런을 이용한 토픽 모델링
    3. Section 7.3 - Gensim을 이용한 토픽 모델링
    4. Section 7.4 - 토픽 트렌드로 시간에 따른 주제 변화 알아내기
    5. Section 7.5 - 동적 토픽 모델링
2. Chapter.8 - 감성 분석
    1. Section 8.1 - 감성 분석의 이해
    2. Section 8.2 - 감성 사전을 이용한 영화 리뷰 감성 분석
    3. Section 8.3 - 학습을 통한 머신러닝 기반의 감성 분석
3. Chapter.9 - 인공신경망과 딥러닝의 이해
    1. Section 9.1 - 인공신경망의 이해
    2. Section 9.2 - 딥러닝의 이해
4. Chapter.10 - RNN, 딥러닝을 이용한 문서 분류
    1. Section 10.1 - 왜 RNN일까?
    2. Section 10.2 - 워드 임베딩의 이해

### 2023년 11월 7일
1. Chapter.10 - RNN, 딥러닝을 이용한 문서 분류
    1. Section 10.3 - RNN을 이용한 문서 분류
2. Chapter.11 - Word2Vec, ELMo, Doc2Vec의 이해
    1. Section 11.1 - Word2Vec - 대표적인 워드 임베딩 기법
    2. Section 11.2 - ELMo - 문맥에 따른 단어 의미의 구분
    3. Section 11.3 - Doc2Vec - 문맥을 고려한 문서 임베딩
3. Chapter.12 - 이미지 분류를 응용한 문서 분류
    1. Section 12.1 - CNN의 등장과 작동 원리
    2. Section 12.2 - CNN을 이용한 문서 분류
4. Chapter.13 - 어텐션(Attention)과 트랜스포머
    1. Section 13.1 - Seq2Seq - 번역에서 시작된 딥러닝 기법
    2. Section 13.2 - 어텐션을 이용한 성능의 향상
    3. Section 13.3 - 셀프 어텐션과 트랜스포머
5. Chapter.14 - BERT의 이해와 간단한 활용
    1. Section 14.1 - 왜 언어 모델이 중요한가?
    2. Section 14.2 - 사전학습 언어모델의 이론적 이해
    3. Section 14.3 - BERT의 구조
    4. Section 14.4 - 언어모델을 이용한 사전학습과 미세조정학습
    5. Section 14.5 - 사전학습된 BERT 모형의 직접 사용 방법
    6. Section 14.6 - 자동 클래스를 이용한 토크나이저와 모형의 사용
5. Chapter.15 - BERT 사전학습 모형에 대한 미세조정 학습
    1. Section 15.1 - BERT 학습을 위한 전처리
    2. Section 15.2 - 트랜스포머의 트레이너를 이용한 미세조정 학습
    3. Section 15.3 - 파이토치를 활용한 미세조정 학습

### 2023년 11월 8일
1. Chapter.16 - 한국어 문서에 대한 BERT 활용
    1. Section 16.1 - 다중 언어 BERT 사전학습 모형의 미세조정 학습
    2. Section 16.2 - KoBERT 사전학습 모형에 대한 파이토치 미세조정 학습
2. Chapter.17 - 트랜스포머 변형 모형의 현황
    1. Section 17.1 - 트랜스포머 변형 모형의 다양한 토크나이저
    2. Section 17.2 - GPT 기반 트랜스포머 변형 모형
    3. Section 17.3 - BERT 기반 트랜스포머 변형 모형
    4. Section 17.4 - 인코더와 디코더를 모두 사용하는 트랜스포머 변형 모형
3. Chapter.18 - 트랜스포머 모형을 이용한 문서 요약
    1. Section 18.1 - 문서 요약의 이해
    2. Section 18.2 - 파이프라인을 이용한 문서 요약
    3. Section 18.3 - T5 모형과 자동 클래스를 이용한 문서 요약
    4. Section 18.4 - T5 모형과 트레이너를 이용한 미세조정 학습
    5. Section 18.5 - 한글 문서 요약
4. Chapter.19 - 트랜스포머 모형을 이용한 질의 응답
    1. Section 19.1 - 질의 응답 시스템의 이해

### 2023년 11월 9일
1. Chapter.19 - 트랜스포머 모형을 이용한 질의 응답
    1. Section 19.2 - 파이프라인을 이용한 질의 응답
    2. Section 19.3 - 자동 클래스를 이용한 질의 응답
    3. Section 19.4 - 트레이너를 이용한 질의 응답 미세조정 학습
    4. Section 19.5 - 한글 질의 응답
2. Chapter.11 - Word2Vec, ELMo, Doc2Vec의 이해
    1. Section 11.1 - Word2Vec - 대표적인 워드 임베딩 기법
    2. Section 11.2 - ELMo - 문맥에 따른 단어 의미의 구분
    3. Section 11.3 - Doc2Vec - 문맥을 고려한 문서 임베딩
3. Chapter.13 - 어텐션(Attention)과 트랜스포머
    1. Section 13.1 - Seq2Seq - 번역에서 시작된 딥러닝 기법
    2. Section 13.2 - 어텐션을 이용한 성능의 향상
    3. Section 13.3 - 셀프 어텐션과 트랜스포머
4. Chapter.14 - BERT의 이해와 간단한 활용
    1. Section 14.1 - 왜 언어 모델이 중요한가?
    2. Section 14.2 - 사전학습 언어모델의 이론적 이해
    3. Section 14.3 - BERT의 구조
    4. Section 14.4 - 언어모델을 이용한 사전학습과 미세조정학습
5. Chapter.17 - 트랜스포머 변형 모형의 현황
    1. Section 17.1 - 트랜스포머 변형 모형의 다양한 토크나이저
    2. Section 17.2 - GPT 기반 트랜스포머 변형 모형
    3. Section 17.3 - BERT 기반 트랜스포머 변형 모형
    4. Section 17.4 - 인코더와 디코더를 모두 사용하는 트랜스포머 변형 모형

### 2023년 11월 10일
1. Chapter.14 - BERT의 이해와 간단한 활용 - 연습을 통한 이해
    1. Section 14.5 - 사전학습된 BERT 모형의 직접 사용 방법
    2. Section 14.6 - 자동 클래스를 이용한 토크나이저와 모형의 사용
2. Chapter.15 - BERT 사전학습 모형에 대한 미세조정 학습 - 연습을 통한 이해
    1. Section 15.1 - BERT 학습을 위한 전처리
    2. Section 15.2 - 트랜스포머의 트레이너를 이용한 미세조정 학습
    3. Section 15.3 - 파이토치를 활용한 미세조정 학습
3. Chapter.16 - 한국어 문서에 대한 BERT 활용 - 연습을 통한 이해
    1. Section 16.1 - 다중 언어 BERT 사전학습 모형의 미세조정 학습
    2. Section 16.2 - KoBERT 사전학습 모형에 대한 파이토치 미세조정 학습

### 2024년 1월 28일
1. Chapter.1 - 텍스트 마이닝 기초 복습
2. Chapter.2 - 텍스트 전처리 복습
3. Chapter.3 - 그래프와 워드 클라우드
4. Chapter.4 - 카운트 기반의 문서 표현
5. Chapter.5 - BOW 기반의 문서 분류

### 2024년 1월 29일
1. Chapter.6 - 차원 축소
2. Chapter.7 - 토픽 모델링으로 주제 찾기(~ing)

### 2024년 1월 30일
1. Chapter.7 - 토픽 모델링으로 주제 찾기
2. Chapter.8 - 감성 분석

### 2024년 1월 31일
1. Chapter.9 - 인공신경망과 딥러닝의 이해
2. Chapter.10 - RNN, 딥러닝을 이용한 문서 분류

### 2024년 2월 1일
1. Chapter.11 - Word2Vec, ELMo, Doc2Vec의 이해
2. Chapter.12 - 이미지 분류를 응용한 문서 분류
3. Chapter.13 - 어텐션(Attention)과 트랜스포머

### 2024년 2월 2일
1. Chapter.14 - BERT의 이해와 간단한 활용
2. Chapter.15 - BERT 사전학습 모형에 대한 미세조정 학습

### 2024년 2월 3일
1. Chapter.16 - 한국어 문서에 대한 BERT 활용
2. Chapter.17 - 트랜스포머 변형 모형의 현황
3. Chapter.18 - 트랜스포머 모형을 이용한 문서 요약
4. Chapter.19 - 트랜스포머 모형을 이용한 질의 응답

### 2024년 2월 4일
1. Chapter.14 - BERT의 이해와 간단한 활용 - 연습을 통한 이해
2. Chapter.15 - BERT 사전학습 모형에 대한 미세조정 학습 - 연습을 통한 이해
3. Chapter.16 - 한국어 문서에 대한 BERT 활용 - 연습을 통한 이해


## An Introduction to Statistical Learning with Applications in Python (원서)
### 2025년 1월 21일
1. Chapter.1 - Introduction

### 2025년 1월 22일
1. Chapter.2 - Statistical Learning(~ing)
    1. Section 2.1 - What is Statistical Learning?

### 2025년 1월 23일
1. Chapter.2 - Statistical Learning(~ing)
    1. Section 2.2 - Assessing Model Accuracy

### 2025년 1월 24일
1. Chapter.2 - Statistical Learning(~ing)
    1. Section 2.3 - Lab: Introduction to Python(~ing)

### 2025년 1월 25일
1. Chapter.2 - Statistical Learning
    1. Section 2.3 - Lab: Introduction to Python

### 2025년 1월 26일
1. Chapter.3 - Linear Regression(~ing)
    1. Section 3.1 - Simple Linear Regression
        - Estimating the Coefficients
        - Assessing the Accuracy of the Coefficients Estimates
        - Assessing the Accuracy of the Model
    2. Section 3.2 - Multiple Linear Regression
        - Estimating the Regression Coefficients
        - Some Important Questions

### 2025년 1월 27일
1. Chapter.3 - Linear Regression(~ing)
    1. Section 3.3 - Other Considerations in the Regression Model
        - Qualitative Predictors
        - Extensions of the Linear Model
        - Potential Problems
    2. Section 3.4 - The Marketing Plan
    3. Section 3.5 - Comparison of Linear Regression with K-Nearest Neighbors

### 2025년 1월 28일
1. Chapter.3 - Linear Regression
    1. Section 3.6 - Lab: Linear Regression
        - Importing Packages
        - Simple Linear Regression
        - Multiple Linear Regression
        - Multivariate Goodness of Fit
        - Interaction Terms
        - Non-Linear Transformation of the Predictors
        - Qualitative Predictors

### 2025년 2월 1일
1. Chapter.4 - Classification(~ing)
    1. Section 4.1 - An Overview of Classification
    2. Section 4.2 - Why Not Linear Regression?

### 2025년 2월 2일
1. Chapter.4 - Classification(~ing)
    1. Section 4.3 - Logistic Regression
        - The Logistic Model
        - Estimating the Regression Coefficients
        - Making Predictions
        - Multiple Logistic Regression
        - Multinomial Logistic Regression
    2. Section 4.4 - Generative Models for Classification(~ing)
        - Linear Discriminant Analysis for p = 1

### 2025년 2월 3일
1. Chapter.4 - Classification(~ing)
    1. Section 4.4 - Generative Models for Classification
        - Linear Discriminant Analysis for p > 1
        - Quadratic Discriminant Analysis
        - Naive Bayes
    
### 2025년 2월 4일
1. Chapter.4 - Classification(~ing)
    1. Section 4.5 - A Comparison of Classification Methods(~ing)
        - An Analytical Comparison

### 2025년 2월 5일
1. Chapter.4 - Classification(~ing)
    1. Section 4.5 - A Comparison of Classification Methods
        - An Empirical Comparison
    2. Section 4.6 - Generalized Linear Models
        - Linear Regression on the Bikeshare Data
        - Poisson Regression on the Bikeshare Data
        - Generalized Linear Model in Greater Generality
    3. Section 4.7 - Lab: Logistic Regression, LDA, QDA and KNN(~ing)
        - The Stock Market Data
        - Logistic Regression

### 2025년 2월 6일
1. Chapter.4 - Classification(~ing)
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA and KNN(~ing)
        - Linear Discriminant Analysis

### 2025년 2월 7일
1. Chapter.4 - Classification(~ing)
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA and KNN
        - Quadratic Discriminant Analysis
        - Naive Bayes
        - K-Nearest Neighbors

### 2025년 2월 8일
1. Chapter.4 - Classification
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA ann KNN
        - Linear and Poisson Regression on the Bikeshare Data
2. Chapter.5 - Resampling Methods(~ing)
    1. Section 5.1 - Cross-Validation
        - The Validation Set Approach
        - Leave-One-Out Cross-Validation
        - k-Fold Cross-Validation
        - Bias-Variance Trade-Off for k-Fold Cross-Validation
        - Cross-Validation on Classification Problems

### 2025년 2월 9일
1. Chapter.5 - Resampling Methods
    1. Section 5.2 - The Bootstrap
    2. Section 5.3 - Lab: Cross-Validation and the Bootstrap
        - The Validation Set Approach
        - Cross-Validation
        - The Bootstrap

### 2025년 2월 10일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.1 - Subset Selection(~ing)
        - Best Subset Selection

### 2025년 2월 11일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.1 - Subset Selection(~ing)
        - Stepwise Selection

### 2025년 2월 12일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.1 - Subset Selection
        - Choosing the Optimal Model

### 2025년 2월 13일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.2 - Shrinkage Methods(~ing)
        - Ridge Regression

### 2025년 2월 14일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.2 - Shrinkage Methods
        - The Lasso
        - Selecting the Tuning Parameter

### 2025년 2월 15일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.3 - Dimension Reduction Methods
        - Principal Components Regression
        - Partial Least Squares
    2. Section 6.4 - Considerations in High Dimensions
        - High-Dimensional Data
        - What Goes Wrong in High Dimensions?
        - Regression in High Dimensions
        - Interpreting Results in High Dimensions

### 2025년 2월 16일
1. Chapter.6 - Linear Model Selection and Regularization
    1. Section 6.5 - Lab: Linear Models and Regularization Methods
        - Subset Selection Methods
        - Ridge Regression and the Lasso
        - PCR and PLS Regression

### 2025년 2월 17일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.1 - Polynomial Regression
    2. Section 7.2 - Step Functions
    3. Section 7.3 - Basis Functions

### 2025년 2월 18일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.4 - Regression Splines(~ing)
        - Piecewise Polynomials
        - Constraints and Splines

### 2025년 2월 19일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.4 - Regression Splines
        - The Spline Basis Representation
        - Choosing the Numbers and Locations of the Knots
        - Comparison to Polynomial Regression

### 2025년 2월 20일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.5 - Smoothing Splines
        - An Overview of Smoothing Splines
        - Choosing the Smoothing Parameter Lambda
    2. Section 7.6 - Local Regression

### 2025년 2월 21일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.7 - Generalized Additive Models
        - GAMs for Regression Problems
        - GAMs for Classification Problems
    2. Section 7.8 - Lab: Non-Linear Modeling(~ing)
        - Polynomial Regression and Step Functions

### 2025년 2월 22일
1. Chapter.7 - Moving Beyond Linearity
    1. Section 7.8 - Lab: Non-Linear Modeling
        - Splines
        - Smoothing Splines and GAMs
        - Local Regression

### 2025년 2월 23일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.1 - The Basics of Decision Trees
        - Regression Trees
        - Classification Trees
        - Trees Versus Linear Models
        - Advantages and Disadvantages of Trees

### 2025년 2월 24일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.2 - Bagging, Random Forests, Boosting, etc(~ing)
        - Bagging
        - Random Forests

### 2025년 2월 25일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.2 - Bagging, Random Forests, Boosting, etc
        - Boosting
        - Bayesian Additive Regression Trees
        - Summary of Tree Ensembel Methods

### 2025년 2월 26일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.3 - Lab: Tree-Based Methods(~ing)
        - Fitting Classification Trees

### 2025년 2월 27일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.3 - Lab: Tree-Based Methods(~ing)
        - Fitting Regression Trees
        - Bagging and Random Forests

### 2025년 2월 28일
1. Chapter.8 - Tree-Based Methods
    1. Section 8.3 - Lab: Tree-Based Methods
        - Boosting
        - Bayesian Additive Regression Trees

### 2025년 3월 1일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.1 - Maximal Margin Classifier(~ing)
        - What Is a Hyperplane?
        - Classification Using a Seperating Hyperplane

### 2025년 3월 2일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.1 - Maximal Margin Classifier
        - The Maximal Margin Classifier
        - Construction of the Maximal Margin Classifier
        - The Non-Separable Case

### 2025년 3월 9일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.2 - Support Vector Classifier
        - Overview of the Support Vector Classifier
        - Details of the Support Vector Classifier

### 2025년 3월 11일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.3 - Support Vector Machines(~ing)
        - Classification with Non-Linear Decision Boundaries

### 2025년 3월 12일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.3 - Support Vector Machines
        - The Support Vector Machines
        - An Application to the Heart Disease Data

### 2025년 3월 14일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.4 - SVMs with More Than Two Classes
        - One-Versus-One Classification
        - One-Versus-All Classification
    2. Section 9.5 - Relationship to Logistic Regression

### 2025년 3월 22일
1. Chapter.9 - Support Vector Machines
    1. Section 9.6 - Lab: Support Vector Machines
        - Support Vector Classifier
        - Support Vector Machine
        - ROC Curves
        - SVM with Multiple Classes
        - Application to Gene Expression Data

### 2025년 3월 23일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.1 - Single Layer Neural Networks
    2. Section 10.2 - Multi-Layer Neural Networks
    3. Section 10.3 - Convolutional Neural Networks(~ing)

### 2025년 3월 24일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.3 - Convolutional Neural Networks(~ing)
        - Convolution Layers
        - Pooling Layers

### 2025년 3월 25일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.3 - Convolutional Neural Networks
        - Architecture of a Convolutional Neural Network
        - Data Augmentation
        - Results Using a Pretrained Classifier

### 2025년 3월 26일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.4 - Document Classification

### 2025년 3월 27일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.5 - Recurrent Neural Networks(~ing)

### 2025년 3월 29일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.5 - Recurrent Neural Networks(~ing)
        - Sequential Models for Document Classification

### 2025년 3월 30일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.5 - Recurrent Neural Networks
        - Time Series Forecasting
        - Summary of RNNs

### 2025년 3월 31일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.6 - When to Use Deep Learning

### 2025년 4월 1일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.7 - Fitting a Neural Network
        - Backpropagation
        - Regularization and Stochastic Gradient Descent
        - Dropout Learning
        - Network Tuning

### 2025년 4월 3일
1. Chapter.10 - Deep Learning
    1. Section 10.8 - Interpolation and Double Descent

### 2025년 4월 4일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.1 - Survival and Censoring Times
    2. Section 11.2 - A Closer Look at Censoring
    3. Section 11.3 - The Kaplan-Meier Survival Curve
    4. Section 11.4 - The Log-Rank Test
    5. Section 11.5 - Regression Models With a Survival Response
        - The Hazard Function
        - Proportional Hazards
        - Example: Brain Cancer Data
        - Example: Publication Data

### 2025년 4월 5일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.6 - Shrinkage for the Cox Model
    2. Section 11.7 - Additional Topics
        - Area Under the Curve for Survival Analysis
        - Choice of Time Scale
        - Time Dependent Covariates
        - Checking the Proportional Hazards Assumption
        - Survival Trees

### 2025년 4월 15일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.8 - Lab: Survival Analysis(~ing)
        - Brain Cancer Data

### 2025년 4월 16일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.8 - Lab: Survival Analysis(~ing)
        - Publication Data

### 2025년 4월 17일
1. Chapter.11 - Survival Analysis and Censored Data
    1. Section 11.8 - Lab: Survival Analysis
        - Call Center Data

### 2025년 4월 18일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.1 - The Challenge of Unsupervised Learning
    2. Section 12.2 - Principal Components Analysis(~ing)
        - What Are Principal Components

### 2025년 4월 22일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.2 - Principal Components Analysis(~ing)
        - Another Interpretation of Principal Components
        - The Proportion of Variance Explained

### 2025년 4월 23일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.2 - Principal Components Analysis
        - More on PCA
        - Other Uses for Principal Components

### 2025년 4월 24일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.3 - Missing Values and Matrix Completion
        - Principal Components with Missing Values
        - Recommender Systems
    2. Section 12.4 - Clustering Methods(~ing)
        - K-Means Clustering
        - Hierarchical Clustering

### 2025년 4월 25일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.4 - Clustering Methods(~ing)
        - Practical Issues in Clustering

### 2025년 4월 26일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.5 - Lab: Unsupervised Learning(~ing)
        - Principal Component Analysis
        - Matrix Completion
        - Clustering(~ing)

### 2025년 4월 27일
1. Chapter.12 - Unsupervised Learning
    1. Section 12.5 - Lab: Unsupervised Learning
        - Clustering
        - NCI60 Data Example

### 2025년 4월 28일
1. Chapter.2 - Statistical Learning(~ing)
    1. Section 2.1 - What Is Statistical Learning(~ing)
        - Why Estimate f?

### 2025년 4월 30일
1. Chapter.2 - Statistical Learning(~ing)
    1. Section 2.1 - What Is Statistical Learning
        - How Do We Estimate f?
        - The Trade-Off between Prediction Accuracy and Model Interpretability
        - Supervised Versus Unsupervised Learning
        - Regression Versus Classification Problems
    2. Section 2.2 - Assessing Model Accuracy(~ing)
        - Measuring the Quality of Fit

### 2025년 5월 1일
1. Chapter.2 - Statistical Learning
    1. Section 2.2 - Assessing Model Accuracy
        - The Bias-Variance Trade-Off
        - The Classification Setting

### 2025년 5월 2일
1. Chatper.3 - Linear Regression(~ing)
    1. Section 3.1 - Simple Linear Regression(~ing)
        - Estimating the Coefficients

### 2025년 5월 3일
1. Chapter.3 - Linear Regression(~ing)
    1. Section 3.1 - Simple Linear Regression
        - Assessing the Accuracy of the Coefficient Estimates
        - Assessing the Accuracy of the Model
    2. Section 3.2 - Multiple Linear Regression(~ing)
        - Estimating the Regression Coefficients
        - Some Important Questions(~ing)

### 2025년 5월 4일
1. Chapter.3 - Linear Regression(~ing)
    1. Section 3.2 - Multiple Linear Regression
        - Some Important Questions
    2. Section 3.3 - Other Considerations in the Regression Model(~ing)
        - Qualitative Predictors
        - Extensions of the Linear Model

### 2025년 5월 5일
1. Chapter.3 - Linear Regression(~ing)
    1. Section 3.3 - Other Considerations in the Regression Model
        - Potential Problems
    2. Section 3.4 - The Marketing Plan
    3. Section 3.5 - Comparison of Linear Regression with K-Nearest Neighbors

### 2025년 5월 6일
1. Chapter.3 - Linear Regression(~ing)
    1. Section 3.6 - Lab: Linear Regression(~ing)
        - Importing Packages
        - Simple Linear Regression
        - Multiple Linear Regression
        - Multivariate Goodness of Fit

### 2025년 5월 7일
1. Chapter.3 - Linear Regression
    1. Section 3.6 - Lab: Linear Regression
        - Interaction Terms
        - Non-Linear Transformations of the Predictors
        - Qualitative Predictors

### 2025년 5월 8일
1. Chapter.4 - Classification(~ing)
    1. Section 4.1 - An Overview of Classification
    2. Section 4.2 - Why Not Linear Regression?
    3. Section 4.3 - Logistic Regression
        - The Logistic Model
        - Estimating the Regression Coefficients
        - Making Predictions
        - Multiple Logistic Regression
        - Multinomial Logistic Regression

### 2025년 5월 10일
1. Chapter.4 - Classification(~ing)
    1. Section 4.4 - Generative Models for Classification(~ing)
        - Linear Discriminant Analysis for p = 1
        - Linear Discriminant Analysis for p > 1
        - Quadratic Discriminant Analysis

### 2025년 5월 11일
1. Chapter.4 - Classification(~ing)
    1. Section 4.4 - Generative Models for Classification
        - Naive Bayes

### 2025년 5월 12일
1. Chapter.4 - Classification(~ing)
    1. Section 4.5 - A Comparison of Classification Methods
        - An Analytical Comparison
        - An Empirical Comparison

### 2025년 5월 13일
1. Chapter.4 - Classification(~ing)
    1. Section 4.6 - Generalized Linear Models
        - Linear Regression on the Bikeshare Data
        - Poisson Regression on the Bikeshare Data
        - Generalized Linear Models in Greater Generality

### 2025년 5월 14일
1. Chapter.4 - Classification(~ing)
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA, and KNN(~ing)
        - The Stock Market Data
        - Logistic Regression

### 2025년 5월 16일
1. Chapter.4 - Classification(~ing)
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA, and KNN(~ing)
        - Linear Discriminant Analysis

### 2025년 5월 17일
1. Chapter.4 - Classification(~ing)
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA, and KNN(~ing)
        - Quadratic Discriminant Analysis
        - Naive Bayes

### 2025년 5월 19일
1. Chapter.4 - Classification(~ing)
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA, and KNN(~ing)
        - K-Nearest Neighbors(~ing)

### 2025년 5월 20일
1. Chapter.4 - Classification(~ing)
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA, and KNN(~ing)
        - K-Nearest Neighbors

### 2025년 5월 21일
1. Chapter.4 - Classification
    1. Section 4.7 - Lab: Logistic Regression, LDA, QDA, and KNN
        - Linear and Poisson Regression on the Bikeshare Data

### 2025년 5월 22일
1. Chapter.5 - Resampling Methods(~ing)
    1. Section 5.1 - Cross-Validation(~ing)
        - The Validation Set Approach

### 2025년 5월 23일
1. Chapter.5 - Resampling Methods(~ing)
    1. Section 5.1 - Cross-Validation(~ing)
        - Leave-One-Out Cross-Validation
        - K-Fold Cross-Validation

### 2025년 5월 24일
1. Chapter.5 - Resampling Methods(~ing)
    1. Section 5.1 - Cross-Validation
        - Bias-Variance Trade-Off for K-Fold Cross-Validation
        - Cross-Validation on Classification Problems
    2. Section 5.2 - The Bootstrap

### 2025년 5월 25일
1. Chapter.5 - Resampling Methods(~ing)
    1. Section 5.3 - Lab: Cross-Validation and the Bootstrap(~ing)
        - The Validation Set Approach

### 2025년 5월 26일
1. Chapter.5 - Resampling Methods(~ing)
    1. Section 5.3 - Lab: Cross-Validation and the Bootstrap(~ing)
        - Cross-Validation

### 2025년 5월 27일
1. Chapter.5 - Resampling Methods
    1. Section 5.3 - Lab: Cross-Validation and the Bootstrap
        - The Bootstrap

### 2025년 5월 28일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.1 - Subset Selection
        - Best Subset Selection
        - Stepwise Selection
        - Choosing the Optimal Model

### 2025년 5월 31일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.2 - Shrinkage Methods(~ing)
        - Ridge Regression

### 2025년 6월 1일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.2 - Shrinkage Methods
        - The Lasso
        - Selecting the Tuning Parameter

### 2025년 6월 2일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.3 - Dimension Reduction Methods(~ing)
        - Principal Components Regression

### 2025년 6월 3일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.3 - Dimension Reduction Methods
        - Partial Least Squares
    2. Section 6.4 - Considerations in High Dimensions
        - High-Dimensional Data
        - What Goes Wrong in High Dimensions
        - Regression in High Dimensions
        - Interpreting Results in High Dimensions

### 2025년 6월 4일
1. Chapter.6 - Linear Model Selection and Regularization(~ing)
    1. Section 6.5 - Lab: Linear Models and Regularization Methods(~ing)
        - Subset Selection Methods

### 2025년 6월 8일
1. Chapter.6 - Linear Model Selection and Regularization
    1. Section 6.5 - Lab: Linear Models and Regularization Methods
        - Ridge Regression and the Lasso
        - PCR and PLS Regression

### 2025년 6월 9일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.1 - Polynomial Regression

### 2025년 6월 10일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.2 - Step Functions
    2. Section 7.3 - Basis Functions
    3. Section 7.4 - Regression Splines(~ing)
        - Piecewise Polynomials

### 2025년 6월 11일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.4 - Regression Splines
        - Constraints and Splines
        - The Spline Basis Representation
        - Choosing the Number and Locations of the Knots
        - Comparison to Polynomial Regression

### 2025년 6월 12일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.5 - Smoothing Splines
        - An Overview of Smoothing Splines
        - Choosing the Smoothing Parameter Lambda
    2. Section 7.6 - Local Regression
    3. Section 7.7 - Generalized Additive Models
        - GAMs for Regression Problems
        - GAMs for Classification Problems

### 2025년 6월 13일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.8 - Lab: Non-Linear Modeling(~ing)
        - Polynomial Regression and Step Functions(~ing)

### 2025년 6월 14일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.8 - Lab: Non-Linear Modeling(~ing)
        - Polynomial Regression and Step Functions

### 2025년 6월 17일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.8 - Lab: Non-Linear Modeling(~ing)
        - Splines

### 2025년 6월 18일
1. Chapter.7 - Moving Beyond Linearity(~ing)
    1. Section 7.8 - Lab: Non-Linear Modeling(~ing)
        - Smoothing Splines and GAMs(~ing)

### 2025년 6월 20일
1. Chapter.7 - Moving Beyond Linearity
    1. Section 7.8 - Lab: Non-Linear Modeling
        - Smoothing Splines and GAMs
        - Local Regression

### 2025년 6월 23일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.1 - The Basics of Decision Trees(~ing)
        - Regression Trees(~ing)

### 2025년 6월 24일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.1 - The Basics of Decision Trees
        - Regression Trees
        - Classification Trees
        - Trees Versus Linear Models
        - Advantages and Disadvantages of Trees
    2. Section 8.2 - Bagging, Random Forests, Boosting, and Bayesian Additive Regression Trees(~ing)
        - Bagging
        - Random Forests

### 2025년 6월 25일
1. Chapter.8 - Tree-Based Methods(~ing)
    1. Section 8.2 - Bagging, Random Forests, Boosting, and Bayesian Additive Regression Trees
        - Boosting
        - Bayesian Additive Regression Trees
        - Summary of Tree Ensemble Methods

### 2025년 6월 28일
1. Chapter.8 - Tree-Based Methods
    1. Section 8.3 - Lab: Tree-Based Methods
        - Fitting Classification Trees
        - Fitting Regression Trees
        - Bagging and Random Forests
        - Boosting
        - Bayesian Additive Regression Trees

### 2025년 6월 29일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.1 - Maximal Margin Classifier
        - What is a Hyperplane?
        - Classification Using a Seperating Hyperplane
        - The Maximal Margin Classifier
        - Construction of the Maximal Margin Classifier
        - The Non-Seperable Case
    2. Section 9.2 - Support Vector Classifier
        - Overview of the Support Vector Classifier
        - Details of the Support Vector Classifier

### 2025년 6월 30일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.3 - Support Vector Machines
        - Classification with Non-Linear Decision Boundaries
        - The Support Vector Machine
        - An Application to the Heart Disease Data
    2. Section 9.4 - SVMs with More Than Two Classes
        - One-Versus-One Classification
        - One-Versus-All Classification
    3. Section 9.5 - Relationship to Logistic Regression

### 2025년 7월 1일
1. Chapter.9 - Support Vector Machines(~ing)
    1. Section 9.6 - Lab: Support Vector Machines(~ing)
        - Support Vector Classifier

### 2025년 7월 2일
1. Chapter.9 - Support Vector Machines
    1. Section 9.6 - Lab: Support Vector Machines
        - Support Vector Machines
        - ROC Curves
        - SVM with Multiple Classes
        - Application to Gene Expression Data

### 2025년 7월 3일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.1 - Single Layer Neural Networks

### 2025년 7월 4일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.2 - Multilayer Neural Networks

### 2025년 7월 5일
1. Chapter.10 - Deep Learning(~ing)
    1. Section 10.3 - Convolutional Neural Networks
        - Convolution Layers
        - Pooling Layers
        - Architecture of a Convolutional Neural Network
        - Data Augmentation
        - Results Using a Pretrained Classifier
    2. Section 10.4 - Document Classification
    3. Section 10.5 - Recurrent Neural Networks(~ing)
        - Sequential Models for Document Classification

### 2025년 7월 6일
1. Chapter.10 - Deep Learning
    1. Section 10.5 - Recurrent Neural Networks
        - Time Series Forecasting
        - Summary of RNNs
    2. Section 10.6 - When to Use Deep Learning
    3. Section 10.7 - Fitting a Neural Network
        - Backpropagation
        - Regularization and Stochastic Gradient Descent
        - Dropout Learning
        - Network Tuning
    4. Section 10.8 - Interpolation and Double Descent

### 2025년 7월 7일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.1 - Survival and Censoring Times
    2. Section 11.2 - A Closer Look at Censoring
    3. Section 11.3 - The Kaplan-Meier Survival Curve

### 2025년 7월 8일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.4 - The Log-Rank Test
    2. Section 11.5 - Regression Models with a Survival Response(~ing)
        - The Hazard Function

### 2025년 7월 9일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.5 - Regression Models with a Survival Response
        - Proportional Hazards
        - Example: Brain Cancer Data
        - Example: Publication Data

### 2025년 7월 10일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.6 - Shrinkage for the Cox Model

### 2025년 7월 11일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.7 - Additional Topics
        - Area Under the Cruve for Survival Analysis
        - Choice of Time Scale
        - Time-Dependent Covariates
        - Checking the Proportional Hazards Assumption
        - Survival Trees

### 2025년 7월 12일
1. Chapter.11 - Survival Analysis and Censored Data(~ing)
    1. Section 11.8 - Lab: Survival Analysis(~ing)
        - Brain Cancer Data
        - Publication Data

### 2025년 7월 13일
1. Chapter.11 - Survival Analysis and Censored Data
    1. Section 11.9 - Lab: Survival Analysis
        - Call Center Data

### 2025년 7월 14일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.1 - The Challenge of Unsupervised Learning
    2. Section 12.2 - Principal Components Analysis(~ing)
        - What are Principal Components?

### 2025년 7월 16일
1. Chapter.12 - Unsupervised Learning(~ing)
    1. Section 12.2 - Principal Components Analysis
        - Another Interpretation of Principal Components
        - The Proportion of Variance Explained
        - More on PCA
        - Other Uses for Principal Components